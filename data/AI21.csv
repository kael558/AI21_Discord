paragraphs,link
"AI21 Studio is a platform for building AI applications that comprehend and generate natural language, powered by AI21 Labs' cutting-edge language models (LMs).",https://docs.ai21.com/docs/overview
AI21 Studio allows users to generate text completions for an input prompt using Jurassic-1 Language models. This is realized using either of the following interfaces:,https://docs.ai21.com/docs/overview
You can also use one of our specialized APIs and integrate in your system for:,https://docs.ai21.com/docs/overview
AI21 Studio offers flexible pay-as-you-go plans as well as a free trial with a generous amount of free credits to get you started. Create your account here.,https://docs.ai21.com/docs/overview
"Start building with our comprehensive guides, recipes and API references.",https://docs.ai21.com#content
"AI21 Studio is a platform for building AI applications that comprehend and generate natural language, powered by AI21 Labs' cutting-edge language models (LMs).",https://docs.ai21.com/docs/overview
AI21 Studio allows users to generate text completions for an input prompt using Jurassic-1 Language models. This is realized using either of the following interfaces:,https://docs.ai21.com/docs/overview
You can also use one of our specialized APIs and integrate in your system for:,https://docs.ai21.com/docs/overview
AI21 Studio offers flexible pay-as-you-go plans as well as a free trial with a generous amount of free credits to get you started. Create your account here.,https://docs.ai21.com/docs/overview
"Using AI21 Studio, you can solve challenging text understanding and generation tasks. Its straightforward API and interactive playground allows you to get started in minutes, without any prior knowledge in Natural Language Processing (NLP).",https://docs.ai21.com/docs/quickstart
"Below is a quickstart guide to cover all the basics you need in order to start building your solution. After that, you should feel comfortable using our large language models to start and solve your own use-case.",https://docs.ai21.com/docs/quickstart
A language model takes some text as input and produces a likely continuation. You can think of it as an exceptional student that can follow instructions and imitate examples.,https://docs.ai21.com/docs/quickstart
Here are two words you should know:,https://docs.ai21.com/docs/quickstart
Prompt - the input you provide to the model.,https://docs.ai21.com/docs/quickstart
Completion - the output text the model returns.,https://docs.ai21.com/docs/quickstart
You slept in and missed a crucial phone call? Here's how AI21 Studio can help you out of a bind: let's build an excuse generator.,https://docs.ai21.com/docs/quickstart
The most naive thing to do is simply provide the model a prompt which is a simple instruction. This is what it looks like:,https://docs.ai21.com/docs/quickstart
"This is called Zero-shot, because we are giving the model zero examples. Occasionally this may work, but you may receive various types of completions. The structure and tone of the completion may differ from your expectation, for example a short excuse when expected something elaborated.",https://docs.ai21.com/docs/quickstart
"If you want to get the most benefit out of large language models, it is recommended to insert a prompt that includes several examples (similarly to teaching a student).",https://docs.ai21.com/docs/quickstart
"The previous excuse was too generic and could have been used for anything. By providing the model with examples, just as a human would, it could produce completions that are more aligned with your intentions. In order to help the model distinguish between each example, we use a stop sequence. The stop sequence itself should be immediately recognizeable when you look at the text as a whole. In this example, the stop sequence is ##:",https://docs.ai21.com/docs/quickstart
"This is called Few-shot, because we are inserting a prompt which includes a few examples.",https://docs.ai21.com/docs/quickstart
"The previous results were rather serious and not the most original. If you‚Äôre looking for some more creative excuses, it should be reflected in your examples:",https://docs.ai21.com/docs/quickstart
Surely this will work on even the most skeptical boss.,https://docs.ai21.com/docs/quickstart
"Another way to affect the completion is to adjust some of the model parameters. A useful parameter is the temperature. You can increase creativity by tweaking the temperature. With temperature 0, the model will always choose the most probable completion, so it will always be the same. Increasing the temperature will provide variable completions, where the completion may be different for every generation:",https://docs.ai21.com/docs/quickstart
"A task that requires accurate results (such as classification) is best performed with low temperature, whereas a task that requires more creativity should be conducted with high temperature (0.7 is a reasonable starting point).",https://docs.ai21.com/docs/quickstart
Want to explore the various excuses the model can think of? Try it yourself!,https://docs.ai21.com/docs/quickstart
"We encourage you to play with our models in the AI21 Studio. Take inspiration from other examples in the playground, such as Twitter agent, Ads copywriter, Outline creator and more. Finished playing? Learn more about our completion API.",https://docs.ai21.com/docs/quickstart
You have a mission and want the best that Studio has to offer? Optimal results are achieved by training a custom model.,https://docs.ai21.com/docs/quickstart
Have any questions? Talk to us.,https://docs.ai21.com/docs/quickstart
"Now that you know what large language models are, you must be wondering: ‚ÄúHow does a neural network use text as input and output?‚Äù.",https://docs.ai21.com/docs/tokenizer-tokenization
The answer is: Tokenization üß©,https://docs.ai21.com/docs/tokenizer-tokenization
"Any language can be broken down into basic pieces (in our case, tokens). Each of those pieces is translated into its own vector representation, which is eventually fed into the model. For example:",https://docs.ai21.com/docs/tokenizer-tokenization
"Each model has its own dictionary of tokens, which determines the language it ""speaks"". Each text in the input will be decomposed into these tokens, and every text generated by the model will be composed of them.",https://docs.ai21.com/docs/tokenizer-tokenization
But how do we break down a language? Which pieces are we choosing as our tokens? There are several approaches to solve this:,https://docs.ai21.com/docs/tokenizer-tokenization
"As a simple solution, each character can be treated as its own token. By doing so, we can represent the entire English language with just 26 characters (okay, double it for capital letters and add some punctuation). This would give us a small token dictionary, thereby reducing the width we need for those vectors and saving us some valuable memory. However, those tokens don‚Äôt have any inherent meaning - we all know what the meaning of ‚ÄúCat‚Äù is, but what is the meaning of ‚ÄúC‚Äù? The key to understanding language is context. Although it is clear to us readers that a ""Cat"" and a ""Cradle"" have different meanings, for a language model with this tokenizer - the ""C"" is the same.",https://docs.ai21.com/docs/tokenizer-tokenization
"Another approach we can try is breaking our text into words, just like in the example above (""I want to break free"").",https://docs.ai21.com/docs/tokenizer-tokenization
"Now, every token has a meaning that the model can learn and use. We are gaining meaning, but that requires a much larger dictionary. Also, it raises another question: what about words stemming from the same root-word like ‚Äùhelped‚Äù, ‚Äúhelping‚Äù, and ‚Äúhelpful‚Äù? In this approach each of these words will get a different token with no inherent relation between them, whereas for us readers it's clear that they all have a similar meaning.",https://docs.ai21.com/docs/tokenizer-tokenization
"Furthermore, words may have fundamentally different meanings when strung together - for instance, my run-down car isn't running anywhere. What if we went a step further?",https://docs.ai21.com/docs/tokenizer-tokenization
"In this approach we break our text into sentences. This will capture meaningful phrases! However, this would result in an absurdly large dictionary, with some tokens being so rare that we would require an enormous amount of data to teach the model the meaning of each token.",https://docs.ai21.com/docs/tokenizer-tokenization
"Each method has pros and cons, and like any real-life problem, the best solution involves a number of compromises. AI21 Studio uses a large token dictionary (250K), which contains some from every method: separate characters, words, word parts such as prefixes and suffixes, and many multi-word tokens.",https://docs.ai21.com/docs/tokenizer-tokenization
Two new features are now available:,https://docs.ai21.com/changelog
"We are pleased to announce the availability of the Python Software Development Kit (SDK) for AI21 Studio's state-of-the-art natural language processing models, including the Jurassic-1 series and all specialized models.",https://docs.ai21.com/changelog
"The new documentation platform introduces more information on the use of our large language models, how to use our APIs, example recipes, and more!",https://docs.ai21.com/changelog
"Jurassic-1 Instruct, our instruction-following language model, is now available in open beta! ü¶ñ",https://docs.ai21.com/changelog
Two new features are included in this update: custom presets can be deleted and uploaded datasets can be deleted. Both of these features are extremely useful for anyone who has a large number of assets and wishes to organize them as well as remove older assets from their collections.,https://docs.ai21.com/changelog
"We are excited to announce the launch of two specialized APIs from AI21 Studio: Rewrite API and Summarize API. Developed by our experts, these top-notch NLP models are designed to handle the complex tasks of paraphrasing and summarization accurately. All that‚Äôs left is to integrate them into your product and let the magic happen üîÆ‚ú®üí´",https://docs.ai21.com/changelog
"We have created a new Overview page to be the entry gate to our platform. With easy access to a set of premade examples (presets), API documentation and custom models, it should be a breeze to start working with our technology right away.",https://docs.ai21.com/changelog
"AI21 Labs is on a mission to make reading and writing AI-first experiences, with machines working alongside humans as thought partners, thereby promoting human welfare and prosperity. To deliver its promise, this technology must be deployed and used in a responsible and sustainable way, taking into consideration potential risks, including malicious use by bad actors, accidental misuse and broader societal harms. We take these risks extremely seriously and put measures in place to mitigate them.",https://docs.ai21.com/docs/safety-research
"AI safety is an important challenge with a large surface area, which we believe can be addressed most effectively by working together. We invite anyone interested in conducting research or otherwise promoting AI safety to contact us at [email protected] and explore opportunities for collaboration. We encourage members of the community to contact us at the same address to report bad experiences, vulnerabilities and suspected misuse of our products or to voice any other safety-related concerns.",https://docs.ai21.com/docs/safety-research
"Natural language processing (NLP) has seen rapid growth in the last few years since large language models (LLMs) were introduced. Those huge models are based on the Transformers architecture, which allowed for the training of much larger and more powerful language models.",https://docs.ai21.com/docs/large-language-models
"We divide LLMs into two main categories, Autoregressive and Masked LM (language model). In this page we will focus on Autoregressive LLMs, as our language models, Jurassic-1 series, belongs to this category.",https://docs.ai21.com/docs/large-language-models
"Autoregressive LLM is a neural network model composed from billions of parameters. It was trained on a massive amount of texts with one goal: to predict the next word, based on the given text. By repeating this action several times, every time adding the prediction word to the provided text, you will end up with a complete text (e.g. full sentences, paragraphs, articles, books, and more). In terms of terminology, the textual output (the complete text) is called a completion while the input (the given, original text) is called prompt.",https://docs.ai21.com/docs/large-language-models
"Imagine you had to read all of Shakespeare's works repeatedly to learn a language. Eventually, you would be able to not only memorize all of his plays and poems, but also imitate his writing style.",https://docs.ai21.com/docs/large-language-models
"In similar fashion, we trained the LLMs by supplying them with many textual sources. This enabled them to gain an in-depth understanding of English as well as general knowledge.",https://docs.ai21.com/docs/large-language-models
"The LLMs are queried using natural language, also known as prompt engineering.",https://docs.ai21.com/docs/large-language-models
"Rather than writing lines of code and loading a model, you write a natural language prompt and pass it to the model as the input. For example:",https://docs.ai21.com/docs/large-language-models
"Data, computation, and engineering resources are required for training and deploying large language models. LLMs, such as our Jurassic-1 models, play an important role here, providing access to this type of technology to academic researchers and developers.",https://docs.ai21.com/docs/large-language-models
Only you and members of your organization will be able to send requests to your custom models. Other AI21 Studio users don‚Äôt have access.,https://docs.ai21.com/docs/training-custom-models-1
"Once trained, you'll be able to query your custom model in the playground by selecting it from the model dropdown. You can also query the model via the API by posting a complete request with the model name in the URL corresponding to your custom model:",https://docs.ai21.com/docs/training-custom-models-1
"When querying the trained model with new examples, you should use exactly the same structure you used in the training data. Stop sequence is not needed.",https://docs.ai21.com/docs/training-custom-models-1
"For example, to query a model trained on ad generation as in this example, your prompt text should be:",https://docs.ai21.com/docs/training-custom-models-1
"When you use AI21 Studio via the API or the interactive web environment, your usage is metered for billing. You can track your usage and expected payments in the account page. Two types of activity are metered:",https://docs.ai21.com/docs/calculating-usage
Requests - Every time you generate a completion in our website or post a complete request via the API.,https://docs.ai21.com/docs/calculating-usage
"Generated tokens - The total number of all completion tokens you generate. For example, assume you post a complete request for J1-Jumbo with a prompt consisting of 10 tokens and requiring 3 completions, i.e. numResults = 3, and the model generates completions with 5, 15, and 20 tokens. In total this request will consume 5+15+20=40 generated tokens.",https://docs.ai21.com/docs/calculating-usage
You are encouraged to use the maxTokens and stopSequences parameters to avoid generating unnecessary tokens and make your usage as efficient as possible.,https://docs.ai21.com/docs/calculating-usage
"The Summarize API of AI21 Studio provides you access to our state-of-the-art summarization engine. It was designed specifically for summary purposes and has been fine-tuned for that task. Consequently, it's easier to integrate into your systems, and since it's optimized for this objective - it's also more efficient (and therefore cheaper) than building it from scratch.",https://docs.ai21.com/docs/summarization-summarize
"This API takes a long piece of text and returns a summary of the text. It supports input text up to 10,000 characters long. For longer texts, you can combine it with our Slice API to summarize the text slice-by-slice.",https://docs.ai21.com/docs/summarization-summarize
"AI21 Studio‚Äôs Slice API divides a piece of text into slices. Slices focus on distinct topics and are typically a few hundred characters long, similar to a paragraph. Therefore, slices make good inputs for Summarize API, allowing you to summarize long texts slice-by-slice.",https://docs.ai21.com/docs/summarization-summarize
"The example below shows a typical flow for summarizing texts longer than Summarize APIs 10,000 character limit. First, we call Slice and get a list of slices. Second, we iterate through the list and perform a Summarize call to summarize each slice. We print the summaries in order to form a summary of the entire document.",https://docs.ai21.com/docs/summarization-summarize
"AI21 Studio provides open access to state-of-the-art language models that can be used to power a large variety of useful applications. We believe it is important to ensure that this technology is used in a responsible way, while allowing developers the freedom they need to experiment rapidly and deploy solutions at scale.",https://docs.ai21.com/docs/responsible-use
"In order to use AI21 Studio, you are required to comply with our Terms of Use and with the following usage guidelines. Provided you comply with these requirements, you may use AI21 Studio to power applications with live users without any additional approval. We reserve the right to limit or suspend your access to AI21 Studio at any time where we believe these terms or guidelines are violated.",https://docs.ai21.com/docs/responsible-use
"Please check these usage guidelines periodically, as they may be updated from time to time. For any questions, clarifications or concerns, please contact [email protected].",https://docs.ai21.com/docs/responsible-use
AI21 Studio must not be used for any of the following activities:,https://docs.ai21.com/docs/responsible-use
"Your application may present content generated by AI21 Studio directly to humans (e.g., chatbots, content generation tools, etc). In this case, you are required to ensure the following:",https://docs.ai21.com/docs/responsible-use
No content generated by AI21 Studio will be posted automatically (without human intervention) to any public website or platform where it may be viewed by an audience greater than 100 people.,https://docs.ai21.com/docs/responsible-use
"This means that you can use AI21 Studio to build a bot for your team‚Äôs 7-person Slack channel. In contrast, you are not allowed to build a Twitter bot, unless each tweet is checked by a human before it is posted. You can build a customer service bot that interacts with any number of customers, assuming it's chatting with each human separately in a 1:1 conversation.",https://docs.ai21.com/docs/responsible-use
"The Rewrite API of AI21 Studio provides you access to our state-of-the-art paraphrasing engine. It was designed specifically for paraphrasing purposes and has been fine-tuned for that task. Consequently, it's easier to integrate into your systems, and since it's optimized for this objective - it's also more efficient (and therefore cheaper) than building it from scratch.",https://docs.ai21.com/docs/paraphrasing-rewrite
"This API takes a piece of text and returns a list of paraphrases that convey the same meaning using different words. As a specialized API for paraphrasing, it contains features to enable you more control over the output: adjust the tone and rewrite only parts of a text (while keeping the whole context).",https://docs.ai21.com/docs/paraphrasing-rewrite
"By specifying an (optional) intent, you can generate paraphrases that are longer, shorter, more formal or more casual than the original text. You can rewrite a specific span while keeping the surrounding text unchanged by passing spanStart and spanEnd (also optional).",https://docs.ai21.com/docs/paraphrasing-rewrite
Spans are expected to align with full words. Paraphrasing spans that start or end in the middle of a word will result in unexpected behavior (usually - no suggestions returned).,https://docs.ai21.com/docs/paraphrasing-rewrite
The Rewrite API aims to rewrite exactly the requested span while avoiding disfluent suggestions. Satisfying both requirements is not always possible.,https://docs.ai21.com/docs/paraphrasing-rewrite
"If you don‚Äôt have enough pre-existing training data, you can use prompt engineering on top of J1 models to efficiently generate more data. Assuming you‚Äôve already created a prompt with just a few examples that works well for your task, you can leverage it in one of two ways:",https://docs.ai21.com/docs/collecting-data
"If you have examples of inputs that represent your use-case, feed them to J1 with your prompt, and collect the outputs generated by the model. The pairs of inputs and generated outputs will be your training set. Note that you can often collect relevant input examples relatively easily, either from public sources on the web or from your own data.",https://docs.ai21.com/docs/collecting-data
"If you don‚Äôt have access to relevant input examples, you can let J1 generate both the inputs and the outputs. Feed J1 with a sequence of examples (input #1, output #1, input #2, output #2 and so on) and let it generate more examples. This tends to work well for short inputs, up to a few sentences long, but may result in a higher rate of bad examples for longer inputs (e.g. whole articles).",https://docs.ai21.com/docs/collecting-data
"In any case, the first human to view text generated by AI21 Studio must not be led to believe that it was written by a human.",https://docs.ai21.com/docs/responsible-use
"If you‚Äôre building a copywriting tool for marketing professionals, your users must be informed that the text proposed to them is machine generated. They are then free to use and present it as their own, at their discretion. As another example, if you‚Äôre building a chatbot, it must be clear to your users that they are corresponding with a machine rather than a live human.",https://docs.ai21.com/docs/responsible-use
"Language models such as those accessible via AI21 Studio may generate inappropriate, biased, offensive or otherwise harmful content (see our technical paper for an evaluation of bias in our models). If your application is used by more than 100 people per month, you must provide a method for users to report generated text as harmful. You should monitor these reports and respond to them appropriately.",https://docs.ai21.com/docs/responsible-use
"You can build a demo, launch a closed beta, etc. without any special requirements, as long as it is accessed by fewer than 100 users per month. Once you exceed 100 monthly users, you must implement a ‚Äúflag as inappropriate‚Äù button or some similar functionality to collect negative feedback.",https://docs.ai21.com/docs/responsible-use
"Except when using custom models, the prompt text for any completion request must contain at least 60 characters of text (about 10 words) not written by your users. This text should be crafted by you to produce the desired functionality for the user.",https://docs.ai21.com/docs/responsible-use
"Language models such as those accessible via AI21 Studio can generate content that is biased against particular groups of people. You may not use AI21 Studio to power automated decision making where individuals may be denied benefits, refused access to a service or otherwise have their wellbeing substantially harmed based on protected characteristics.",https://docs.ai21.com/docs/responsible-use
"AI21 Studio must not be used to classify or profile people based on protected characteristics (like racial or ethnic background, religion, political views, or private health data).",https://docs.ai21.com/docs/responsible-use
"For example, consider the sentence ‚ÄúThis is a flat out bad example‚Äù. Paraphrasing the word ‚Äúflat‚Äù alone in this sentence without violating fluency is not possible, because ‚Äúflat‚Äù is part of the term ‚Äúflat out‚Äù. Paraphrasing ‚Äúflat‚Äù alone is kind of like trying to paraphrase half a word. Cases like this usually return few or no suggestions.",https://docs.ai21.com/docs/paraphrasing-rewrite
Consider the following example:,https://docs.ai21.com/docs/paraphrasing-rewrite
You can see that the part until spanStart remains the same.,https://docs.ai21.com/docs/paraphrasing-rewrite
"The spanStart can be either the character you wish to paraphrase from, or a whitespace before it (in this case, it would have worked with spanStart=115 as well).",https://docs.ai21.com/docs/paraphrasing-rewrite
"The process above is illustrated step-by-step in our blog post. Using J1-Jumbo or J1-Grande rather than J1-Large is recommended for generating synthetic training data, since it typically produces higher quality results with prompt engineering.",https://docs.ai21.com/docs/collecting-data
"We recommend you review and validate the generated content (or at least a sample from it) before training a custom model, to make sure the data properly captures the desired behavior. Watch out for incorrect, corrupted or toxic generations, as including these in the training data will negatively affect the resulting custom model. If you find such bad examples, amend them manually or simply exclude them from the training data.",https://docs.ai21.com/docs/collecting-data
"To train a new model, simply follow these steps:",https://docs.ai21.com/docs/training-custom-models
"Your new model will now begin training. You'll see that it's added to the table under the Models tab with its status indicating ""Training"". Once the model is trained, it is immediately deployed and available for you to use.",https://docs.ai21.com/docs/training-custom-models
"You can generate a text completion for a given text prompt by posting an HTTP request to the complete endpoint corresponding to the desired language model to use. The request contains the input text, called a prompt and various parameters controlling the generation. For authentication, you must include your API key in the request headers. A complete response contains the tokenized prompt, the generated text(s), called completion(s), and various metadata.",https://docs.ai21.com/reference/completion
"The response is a nested data structure as described below. At its top level, the response has the following fields:",https://docs.ai21.com/reference/completion
A unique string id for the processed request. Repeated identical requests get different ids.,https://docs.ai21.com/reference/completion
"The prompt, including the raw text, the tokens with their logprobs and the top-K alternative tokens at each position, if requested.",https://docs.ai21.com/reference/completion
Has two nested fields:,https://docs.ai21.com/reference/completion
"List of completions, including raw text, tokens and logprobs. The number of completions corresponds to requested numResults.",https://docs.ai21.com/reference/completion
Each completions has two nested fields:,https://docs.ai21.com/reference/completion
"Both the prompt and each of the completions provide lists of TokenData, where each entry describes a token and, if requested, its top-K alternatives. An instance of TokenData contains the following fields:",https://docs.ai21.com/reference/completion
Has two nested fields:,https://docs.ai21.com/reference/completion
"A list of the top K alternative tokens for this position, sorted by probability, according to the topKReturn request parameter, or null if topKReturn=0.",https://docs.ai21.com/reference/completion
Each token in the list has a token (string) field and a logprob (float) field.,https://docs.ai21.com/reference/completion
The start and end offsets of this token in the decoded text string.,https://docs.ai21.com/reference/completion
"Based on the 17B parameter model Jurassic-1 Grande, Jurassic-1 Instruct was trained specifically to handle instructions-only prompts (""zero-shot"") without examples (""few-shot""). It is the most natural way to interact with large language models, and it is the best way to get a sense of the optimal output for your task without any examples.",https://docs.ai21.com/docs/jurassic-1-instruct-beta
"Below is an example of the difference between Jurassic-1 Instruct and Jurassic-1 Grande to a zero-shot prompt. While instruct provides a natural answer, non-instruct Grande starts with a relevant answer, but doesn't stop in time.",https://docs.ai21.com/docs/jurassic-1-instruct-beta
"There is really only one tip: make sure the instruction ends in a clear way, whether with a punctuation mark (such as ""."", "":"", ""?"" or a newline) or through clear wording.",https://docs.ai21.com/docs/jurassic-1-instruct-beta
A few good prompt examples for inspiration are provided below.,https://docs.ai21.com/docs/jurassic-1-instruct-beta
"As the beta tag suggests, we are constantly working on improving this model, and better versions will be updated in the near future.",https://docs.ai21.com/docs/jurassic-1-instruct-beta
"Using AI21 Studio, you can train and query your own custom versions of J1 models. Custom models are fine-tuned for optimal performance on a training set of examples representing a specific task.",https://docs.ai21.com/docs/custom-models
"Custom models can be trained to perform virtually any language task. Use-cases include generating marketing copy, powering chatbots and assisting creative writing.",https://docs.ai21.com/docs/custom-models
"You can train custom models based on either J1-Large, J1-Grande or J1-Jumbo and pick your desired cost/quality trade-off.",https://docs.ai21.com/docs/custom-models
"Given a sufficient number of training examples, custom J1 models exceed the quality attainable with general purpose models and prompt engineering. For many use-cases, you can expect custom models to begin outperforming prompt engineering with as few as 50-100 examples. To learn more, read our case study blog post, where we address a specific language task, using both general-purpose models and custom models.",https://docs.ai21.com/docs/custom-models
"Furthermore, custom models derive their quality from the training data you provide; adding more, higher quality examples will improve results. This means you can continuously refine your custom model by curating high quality data for your task.",https://docs.ai21.com/docs/custom-models
"The training process bakes the task-specific behavior into the custom model. This means your prompts no longer need to include elaborate instructions and examples designed to guide a general purpose model to perform the desired task. Instead, your prompts only needs to include the specific input you'd like to handle, reducing the amount of text that gets processed and decreasing latency.",https://docs.ai21.com/docs/custom-models
"One potential safety risk of large language models is deliberate misuse by malicious users of your application, exploiting its access to Jurassic-1 to generate text for their malicious purposes. Adversaries may attempt to achieve this via ‚Äúprompt injection‚Äù, where the end-user‚Äôs input text is crafted to alter the normal behavior of the model. Custom models are less susceptible to such attacks than general-purpose models, offering a significant safety advantage when deployed in production. For more information, read our case study blog post.",https://docs.ai21.com/docs/custom-models
There are two parts to the training process:,https://docs.ai21.com/docs/custom-models
"Jurassic-1 (J1) is the first generation in a series of large language models trained and made widely accessible by AI21 Labs. There are three versions of Jurassic-1, differing by size:",https://docs.ai21.com/docs/complete-api
"A complete description of Jurassic-1, including benchmarks and quantitative comparisons with other models, can be found in our technical paper.",https://docs.ai21.com/docs/complete-api
"All J1 models were trained on a massive corpus of English text, making them highly versatile general purpose text-generators, capable of composing human-like text and solving complex tasks such as question answering, text classification and many others.",https://docs.ai21.com/docs/complete-api
"J1 can be applied to virtually any language task by crafting a suitable prompt, containing a description of the task and/or a few examples, a process commonly known as ‚Äúprompt engineering‚Äù. If you‚Äôre looking for inspiration, you can find example use-cases implemented with prompt engineering in our blog post. Popular use-cases include generating marketing copy, powering chatbots and assisting creative writing.",https://docs.ai21.com/docs/complete-api
"With trial and error, you should be able to bootstrap a prompt that produces good results for your use-case. However, to achieve even better quality and scale-up your app, we recommend that you train a custom model.",https://docs.ai21.com/docs/complete-api
"You can generate a text completion for a given text prompt by posting an HTTP request to the complete endpoint corresponding to the desired language model to use. The request contains the input text, called a prompt and various parameters controlling the generation. For authentication, you must include your API key in the request headers. A complete response contains the tokenized prompt, the generated text(s), called completion(s), and various metadata.",https://docs.ai21.com/docs/complete-api
The request and response specifications are documented in full here. See the following example for a complete request to j1-large and corresponding response:,https://docs.ai21.com/docs/complete-api
"The simplest way to structure the training data is where the prompt for each individual training example contains only the text input for that example. Note that this is different from a few-shot prompt engineering for a general purpose model, where the prompt contains a sequence of examples of valid inputs and outputs.",https://docs.ai21.com/docs/best-practices
"In any case, the combined length of the prompt and completion must not exceed 2047 tokens or approximately 6000 characters of English text. If you include longer examples, you will encounter an error after uploading the file.",https://docs.ai21.com/docs/best-practices
"For best results, we recommend implementing the following guidelines for the prompt and completion. All the snippets below assume jsonl format, but the same guidelines are applicable to csv.",https://docs.ai21.com/docs/best-practices
Either of these helps avoid complications due to tokenization. Don‚Äôt mix and match; pick one and stick with it for all examples in the training set. See examples below:,https://docs.ai21.com/docs/best-practices
"You should clearly mark the boundary between the prompt and the completion. A minimal way to do this is to insert a separator at the end of each prompt. You can use any simple, distinct sequence, such as ## on a new line.",https://docs.ai21.com/docs/best-practices
"It is often a good idea to take this a step further by using titles. You can append a title that describes the input to the beginning of the prompt, and another title that describes the output to the end of the prompt (in place of the separator). The titles can be short, but it usually helps to pick straightforward titles that are not generic and relate to the content of the input and output.",https://docs.ai21.com/docs/best-practices
"Again, it‚Äôs important to be consistent. Pick one style and stick with it. If you use titles, they should be the same in all training examples. In any case, keep in mind the first guideline and either end the prompt with a newline or start the completion with a whitespace.",https://docs.ai21.com/docs/best-practices
See a few examples below:,https://docs.ai21.com/docs/best-practices
"Adding a short instruction that explains the task to each prompt often improves results. As before, stay consistent and use the same instruction in all examples.",https://docs.ai21.com/docs/best-practices
"Duplicate entries are detrimental to the training, so we recommend removing them.",https://docs.ai21.com/docs/best-practices
Don't have enough examples?,https://docs.ai21.com/docs/best-practices
"Make sure you don't duplicate existing examples to reach 50 examples. If you do not have more examples, you can use AI21 Studio to generate some based on the ones you do have.",https://docs.ai21.com/docs/best-practices
"You can also train a custom model to perform tasks that have more than one input. Simply combine all the inputs into the prompt, with an appropriate title for each input. For example, consider a model trained to generate short ads for cars from a list of technical specifications. The different fields can be organized in a template as in the following example:",https://docs.ai21.com/docs/best-practices
"To train a custom model, you will need to collect a dataset of training examples. Each example consists of a prompt, which is a valid input text, and a completion, which is a correct output for that specific prompt.",https://docs.ai21.com/docs/training-data
"At least 50 training examples are required to train a custom model. If you upload a file that contains fewer than 50 examples, you will encounter an error. More is better - so provide as many examples as you can.",https://docs.ai21.com/docs/training-data
"No! Data quality and diversity matter as well, so it‚Äôs a good idea to go over your examples manually and make sure they accurately capture various aspects of your task. It's critical that your examples reflect the real-world distribution of your problem.",https://docs.ai21.com/docs/training-data
The dataset must be submitted in a single csv or jsonl file. We recommend using jsonl due to better handling of line breaks.,https://docs.ai21.com/docs/training-data
"If you are submitting a csv file, it should have two columns labeled ""prompt"" and ""completion"". Each row should contain a single training example, with no empty rows in between.",https://docs.ai21.com/docs/training-data
"If you are submitting a jsonl file, each line in the file should be a json dictionary with two fields, ""prompt"" and ""completion"".",https://docs.ai21.com/docs/training-data
Below is a simple example for both csv and jsonl formats:,https://docs.ai21.com/docs/training-data
Uploading a file with fewer than 2 columns or with inconsistent columns in different lines will result in an error.,https://docs.ai21.com/docs/training-data
"You may upload files with different column names, in which case you will be prompted to identify the desired prompt column and the desired completion column.",https://docs.ai21.com/docs/training-data
prompts can be empty.,https://docs.ai21.com/docs/training-data
"Logit biases can be used to promote or suppress the generation of specific tokens. This is accomplished by adding a bias term to each token's respective logits, where a positive bias increases generation probability a negative bias decreases it.",https://docs.ai21.com/docs/logit-bias
"Note that logit bias operates at the token level, so you must refer to valid tokens in the Jurassic-1 vocabulary, otherwise the API returns an error. Watch out for whitespaces which are replaced with a special underscore character in our string representation of tokens (see here).",https://docs.ai21.com/docs/logit-bias
"The following example introduces a large negative bias to avoid generating the expected continuation ""a box of"":",https://docs.ai21.com/docs/logit-bias
An appropriate dataset for training such model would look like the following:,https://docs.ai21.com/docs/best-practices
"The ‚ñÅ or \u2581 character in the tokens is used by our tokenizer to substitute a single whitespace or tab symbol. Sequences of 2 and 4 consecutive spaces (either regular whitespaces or tabs) have their own tokens, ‚ñÅ‚ñÅ and ‚ñÅ‚ñÅ‚ñÅ‚ñÅ respectively.",https://docs.ai21.com/docs/special-tokens-and-whitespaces
"Note that since tokenization adds a dummy space at the start of each line for consistency, the result text is not simply a concatenation of all tokens with ‚ñÅ replaced with a space. For example:",https://docs.ai21.com/docs/special-tokens-and-whitespaces
"Each token's textRange field can be used to map it to its corresponding span in the result text. Note that the text field of the prompt in the response may differ from the text sent in the request, if it contains special symbols which behave differently after tokenization. In this case the textRange fields always refer to the text in the response.",https://docs.ai21.com/docs/special-tokens-and-whitespaces
"Repetition penalties can be used to counteract the model's tendency to repeat prompt text verbatim and/or get stuck in a loop. This is accomplished by adjusting the token probabilities at each generation step, such that tokens that already appeared in the text (either in the prompt or in the completion) are less likely to be generated again.",https://docs.ai21.com/docs/repetition-penalties
"There are three kinds of repetition penalties: presencePenalty, countPenalty and frequencyPenalty. One or more penalty can be used, and the magnitude of each can be controlled independently via their respective API parameters (not available in the web playground yet). Reasonable scale values to explore are 0-5 for the presence and count penalties, and 0-500 for the frequency penalty.",https://docs.ai21.com/docs/repetition-penalties
The following example introduces all three penalties simultaneously (though each individually would have sufficed to prevent repetition):,https://docs.ai21.com/docs/repetition-penalties
"In addition to controlling the penalty scale, the API allows toggling penalties on and off for five special categories of tokens: whitespaces (including newlines), punctuations, numbers, stopwords (including multi-word combinations of stopwords) and emojis. For example:",https://docs.ai21.com/docs/repetition-penalties
Each repetition penalty is characterized by a PenaltyData data structure containing the following fields:,https://docs.ai21.com/docs/repetition-penalties
Controls the magnitude of the penalty. Required.,https://docs.ai21.com/docs/repetition-penalties
A positive penalty value implies reducing the probability of repetition. Larger values correspond to a stronger bias against repetition.,https://docs.ai21.com/docs/repetition-penalties
"Apply the penalty whitespaces and newlines. Optional, default=True.",https://docs.ai21.com/docs/repetition-penalties
Determines whether the penalty is applied to the following tokens:,https://docs.ai21.com/docs/repetition-penalties
"'‚ñÅ', '‚ñÅ‚ñÅ', '‚ñÅ‚ñÅ‚ñÅ‚ñÅ', '<|newline|>'",https://docs.ai21.com/docs/repetition-penalties
"Apply the penalty to punctuations. Optional, default=True.",https://docs.ai21.com/docs/repetition-penalties
"Determines whether the penalty is applied to tokens containing punctuation characters and whitespaces, such as ; , !!! or ‚ñÅ\[[@.",https://docs.ai21.com/docs/repetition-penalties
"Apply the penalty to numbers. Optional, default=True.",https://docs.ai21.com/docs/repetition-penalties
"Determines whether the penalty is applied to purely-numeric tokens, such as 2022 or 123. Tokens that contain numbers and letters, such as 20th, are not affected by this parameter.",https://docs.ai21.com/docs/repetition-penalties
"Apply the penalty to stop words. Optional, default=True.",https://docs.ai21.com/docs/repetition-penalties
"Determines whether the penalty is applied to tokens that are NLTK English stopwords or multi-word combinations of these words, such as are , nor and ‚ñÅWe‚ñÅhave.",https://docs.ai21.com/docs/repetition-penalties
"Exclude emojis from the penalty. Optional, default=True.",https://docs.ai21.com/docs/repetition-penalties
Determines whether the penalty is applied to any of approximately 650 common emojis in the Jurassic-1 vocabulary.,https://docs.ai21.com/docs/repetition-penalties
"For specific needs and use cases, the Advanced section contains information about practices and features that are less common and not needed to get started. This is similar to a car manual, where the basic information is needed to get started, but the advanced section contains information about less common practices and features.",https://docs.ai21.com/docs/advanced
"AI21 Studio is a platform for building AI applications that comprehend and generate natural language, powered by AI21 Labs' cutting-edge language models (LMs).",https://docs.ai21.com/docs
AI21 Studio allows users to generate text completions for an input prompt using Jurassic-1 Language models. This is realized using either of the following interfaces:,https://docs.ai21.com/docs
You can also use one of our specialized APIs and integrate in your system for:,https://docs.ai21.com/docs
AI21 Studio offers flexible pay-as-you-go plans as well as a free trial with a generous amount of free credits to get you started. Create your account here.,https://docs.ai21.com/docs
"Language models are great for generating text. However, we‚Äôd like to make sure the text adheres to our needs as developers. In many use cases, we‚Äôd like to feed the model with some input text and get an output text which satisfies the product need. To do so, you need to engineer the perfect prompt.",https://docs.ai21.com/docs/prompt-engineering
"To be more concrete, imagine you're building a writing platform that helps your users to write easier in their own voice. One of the main features is paraphrasing: given a sentence, your app should automatically suggest paraphrases of the same sentence which are more fluent and customized to the writer's voice (BTW, if you do happen to build this kind of app and need such a feature - head on to our Rewrite API).",https://docs.ai21.com/docs/prompt-engineering
"You‚Äôd like to use AI21 Studio language models to automatically generate the paraphrased suggestions. You can think of the models as smart autocompletion machinery: you feed in text, and the model will generate text that seems like a natural continuation. Your job is to make sure that the desired output (paraphrases in this example) would be the most natural continuation. In other words, you need to create the perfect input to the model, also known as a prompt. What are your tools to make it happen?",https://docs.ai21.com/docs/prompt-engineering
This is the simplest approach. Simply format your input prompt into a template that screams out what the completion should be:,https://docs.ai21.com/docs/prompt-engineering
Let's put a sentence (by Oscar Wilde) in the template and see what we get:,https://docs.ai21.com/docs/prompt-engineering
"Feeding this text into the model, you‚Äôll get a nice completion:",https://docs.ai21.com/docs/prompt-engineering
"Look at the output we got earlier. Maybe the new sentence doesn't fit exactly to what you imagined, and you want a different one. This can be challenging to specify in the prompt.. or maybe it‚Äôs easy, but the model doesn't exactly meet your requirements. Suppose your user requires a formal tone. Simply adjusting the instruction to reflect this may not be enough, and the definition of formal may vary.",https://docs.ai21.com/docs/prompt-engineering
"A powerful solution would be to use the few-shot approach. Here you‚Äôll need to gather a few examples of <input text, output text> pairs that adhere to your product needs. You should format the pairs into a template such that the desired output would be the most natural continuation. In our case, a suitable template would look like this (assuming you have two example pairs):",https://docs.ai21.com/docs/prompt-engineering
"To be more concrete, let's get examples of <input text, output text> that look like what we want, and format it into the template. Notice that we also add the input text provided by the user, but without a matching output text. We‚Äôll get this text that we‚Äôll feed into the model:",https://docs.ai21.com/docs/prompt-engineering
And here‚Äôs the generated result:,https://docs.ai21.com/docs/prompt-engineering
"Language models were trained to generate text token by token and produce text completion in a scope that fits the prompt. Just like it learned how to generate text, it also trained to know when to stop. Jurassic-1 tokenizers have a special token that signals when a reasonable generation end by default. During pre-training, models were trained on text items containing stop sequence suffixes, and by doing so, they were adjusted to end sequences appropriately. However, there are times when the user will benefit from controlling the scope of the generated text, so how can you control the length of the sequence the models generate?",https://docs.ai21.com/docs/when-the-generation-stops
"You can set a lower and upper bound for the amount of tokens the model will generate (minTokens and maxTokens, respectfully). Note that this is very artificial and may cause texts to be cut-off in the middle of a sentence.",https://docs.ai21.com/docs/when-the-generation-stops
"You can set a stop sequence that tell the model to stop generating text. When the model will generate this sequence, we will make it stop generating more text afterwards. A simple example: in order to generate a single sentence, you can set the character ""."" as a stop sequence, which will signal the model to stop once it is generated.",https://docs.ai21.com/docs/when-the-generation-stops
"This is very handy when using a few-shot prompt: where we feed the model with a prompt containing a few examples. A few shot prompt contains one or more completion examples preceding the actual text to complete. Upon generating the completion, the model may repeat the few shot structures and generate additional examples unless otherwise instructed. Therefore, it is recommended to separate the examples by a custom sequence such as ‚Äú==‚Äù, and set it as a stop sequence. Once the text is generated, the model repeats the pattern and generates the separator, which indicates that text generation has been completed. See the example below:",https://docs.ai21.com/docs/when-the-generation-stops
Seems that the model has captured the tone from the examples we provided. You can try it yourself in the playground.,https://docs.ai21.com/docs/prompt-engineering
Another advantage of the few-shot approach is that we can tell the model when to stop. Did you notice the ### at the end of every rewrite? Besides being a separator between the examples - helping the model to distinguish between them - it also helps us in knowing when the model should stop generating more text. You can read more about stop sequences here.,https://docs.ai21.com/docs/prompt-engineering
Want to dive deeper to prompt engineering? Read our blog post.,https://docs.ai21.com/docs/prompt-engineering
"A language model knows how to complete texts token by token. But how does it choose the next token? Will it always choose the same token for a given sequence, or will it choose something different every time?",https://docs.ai21.com/docs/sampling-from-language-models
"Given a prompt (the input to the model), the model generates a distribution over all possible completions (output from the model). It does that by calculating the probability of every token in the dictionary to appear next. Then the model samples a completion according to the distribution.",https://docs.ai21.com/docs/sampling-from-language-models
"Let's understand it using a simple example. Suppose the prompt is the phrase ""I will"". Here is the distribution over all possible tokens (assuming a very small dictionary just for the demonstration):",https://docs.ai21.com/docs/sampling-from-language-models
"There is a 55% chance for the model to choose the completion ""survive"", a 25% chance for the completion ""always love you"", etc. In simple words, it means that if we give the model this prompt 100 times, we'll likely get ‚Äúsurvive‚Äù 55 times, ""always love you"" 25 times, etc.",https://docs.ai21.com/docs/sampling-from-language-models
"As users, we want to have some control on the output, so we can get the most out of it. The key is to somehow change the distribution the model samples from, without changing anything in the model. Here are 3 ways to adjust the sampling of language models using sampling parameters. Each of them has its own benefits, and it is also possible to combine them - in the end, it all comes down to what you need.",https://docs.ai21.com/docs/sampling-from-language-models
"The most popular sampling parameter to play with is the temperature. Inspired by thermodynamics, low temperature means stagnation and high temperature means movement. The temperature value affects the distribution: for a low temperature, we get a higher weight for the most probable token. At 0 temperature we always get the maximum token and the distribution looks like this:",https://docs.ai21.com/docs/sampling-from-language-models
"Namely, the model will always sample the same token at every call.",https://docs.ai21.com/docs/sampling-from-language-models
"A high temperature does the exact opposite: the distribution tends to be as uniform as possible, meaning all tokens have about the same probability. I will look something like this:",https://docs.ai21.com/docs/sampling-from-language-models
"So if you care about consistency and you always want to get the most likely completion (for example in classification tasks), go for temperature=0. If you want more creativity (usually useful in text generation tasks) - try a higher temperature (we recommend to start with 0.7).",https://docs.ai21.com/docs/sampling-from-language-models
"We have created a new Overview page to be the entry gate to our platform. With easy access to a set of premade examples (presets), API documentation and custom models, it should be a breeze to start working with our technology right away.",https://docs.ai21.com/changelog/new-overview-page-1
Here is a link to the Overview page.,https://docs.ai21.com/changelog/new-overview-page-1
"We are excited to announce the launch of two specialized APIs from AI21 Studio: Rewrite API and Summarize API. Developed by our experts, these top-notch NLP models are designed to handle the complex tasks of paraphrasing and summarization accurately. All that‚Äôs left is to integrate them into your product and let the magic happen üîÆ‚ú®üí´",https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
"With Rewrite API, you can paraphrase text to use different wording, style and tone. Give your users superpowers by integrating an AI co-writer into your app.",https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
See it in action:,https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
"With Summarize API, you can compress documents into short summaries. Extract insights from social media discourse, online reviews, organizational knowledge bases and more.",https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
"The current pricing model for Rewrite API is available here. While we finalize the Summarize API pricing, you can use it for free (knock yourself out üòâ).",https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
There's never been an easier way to use NLP! We can't wait to see what you'll build ü§ì,https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
"Another sampling parameter that helps adjusting the model‚Äôs sampling is TopK. It‚Äôs pretty simple: instead of using the full distribution, the model only samples from the K most probable tokens. For K=1 we basically get the same situation as temp 0. In our example, for K=2 the distribution looks like this:",https://docs.ai21.com/docs/sampling-from-language-models
"The third parameter is TopP. This is similar to TopK, but instead of limiting the number of tokens, we limit the total cumulative probability from which to sample. It works like this: we take the most likely token, add it to the pool, and its probability to the amount. We continue adding tokens this way until the sum of probabilities reaches TopP. What happens here is effectively similar to TopK: we remove the ""tail"" of the tokens with the lowest probabilities, except that TopP is more flexible for the number of tokens. In our example for TopP=0.95 we sample from the following distribution:",https://docs.ai21.com/docs/sampling-from-language-models
The website from which you got to this page is protected by Cloudflare. Email addresses on that page have been hidden in order to keep them from being accessed by malicious bots. You must enable Javascript in your browser in order to decode the e-mail address.,https://docs.ai21.com/cdn-cgi/l/email-protection#087b696e6d7c714869613a39266b6765
"If you have a website and are interested in protecting it in a similar way, you can sign up for Cloudflare.",https://docs.ai21.com/cdn-cgi/l/email-protection#087b696e6d7c714869613a39266b6765
"The new documentation platform introduces more information on the use of our large language models, how to use our APIs, example recipes, and more!",https://docs.ai21.com/changelog/a-new-version-of-ai21s-documentation-platform-has-been-released
"By having all the information gathered in one place, you should be able to gain a comprehensive understanding of our platform. It is our hope that it will make the process of utilizing our technology easier for you.",https://docs.ai21.com/changelog/a-new-version-of-ai21s-documentation-platform-has-been-released
"As a result of having a robust but flexible documentation platform, we are able to keep up and continue to update our guides and API references with each new feature and capability we introduce.",https://docs.ai21.com/changelog/a-new-version-of-ai21s-documentation-platform-has-been-released
Two new features are included in this update: custom presets can be deleted and uploaded datasets can be deleted. Both of these features are extremely useful for anyone who has a large number of assets and wishes to organize them as well as remove older assets from their collections.,https://docs.ai21.com/changelog/new-delete-preset
"To delete a preset, go to the Playground page and click the ""Presets"" dropdown. You will see a ""Delete"" button next to each custom preset, grouped under ""My Presets"".",https://docs.ai21.com/changelog/new-delete-preset
"To delete a dataset, go to the Datasets page and click the ""Delete"" button next to the dataset.",https://docs.ai21.com/changelog/new-delete-preset
"Jurassic-1 Instruct, our instruction-following language model, is now available in open beta! ü¶ñ",https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
"Based on the Jurassic-1 Grande, Jurassic-1 Instruct was trained specifically to handle instructions-only prompts (""zero-shot"") that do not require examples (""few-shot""). It is the most natural way to interact with large language models: simply enter a short prompt instructing the model what to do, and get a concise answer from the model.",https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
"Here‚Äôs an example of what Instruct can do - the World Cup. Even if you‚Äôre not a soccer fan, you can be part of the group. Ask Jurassic-1 Instruct to come up with a relevant soccer tweet:",https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
Try it out and discover the power of zero-shot prompting!,https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
"Despite being in open beta, the Jurassic-1 Instruct displays phenomenal capabilities, and will continue to improve over time.",https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
We hope you'll enjoy using Jurassic-1 Instruct.,https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
"We are pleased to announce the availability of the Python Software Development Kit (SDK) for AI21 Studio's state-of-the-art natural language processing models, including the Jurassic-1 series and all specialized models.",https://docs.ai21.com/changelog/python-sdk-is-now-available
"This SDK enables developers to easily connect their Python applications to AI21 Studio's advanced language processing capabilities, such as text completion, instruct commands, rewrite, summarization, and more. In addition, the SDK includes several helpful utilities, such as automatic authentication and error handling, to facilitate the integration of Jurassic-1 into Python applications.",https://docs.ai21.com/changelog/python-sdk-is-now-available
"In the Rewrite and Summarize APIs, you can delete your customized presets if you find that you no longer need them. In addition, in the top navigation, we have included a question mark (help) icon that opens up a live chat window with our customer service department.",https://docs.ai21.com/changelog/small-yet-useful-new-features-for-preset-management-documentation-and-customer-support
"As part of the third update, we have now added a search option to the live chat window, enabling you to search our documentation, guides, API reference, and more. This new search option will save you time and help you get the answers you need more quickly and easily.",https://docs.ai21.com/changelog/small-yet-useful-new-features-for-preset-management-documentation-and-customer-support
Two new features are now available:,https://docs.ai21.com/changelog/new-features-in-ai21-studio-delete-datasets-custom-models
Both operations can be done through the playground or through the API.,https://docs.ai21.com/changelog/new-features-in-ai21-studio-delete-datasets-custom-models
Python client for the AI21 Studio API.,https://docs.ai21.com/reference/python-sdk-complete
"To install the client, run the following command:",https://docs.ai21.com/reference/python-sdk-complete
You can find your API key here.,https://docs.ai21.com/reference/python-sdk-complete
"API keys can be set globally using ai21.api_key, like so:",https://docs.ai21.com/reference/python-sdk-complete
Or pass it to any function call as a named argument. For example:,https://docs.ai21.com/reference/python-sdk-complete
"In the following example, an AI21 API client is used with an API key and timeout parameter set globally. This example uses a simple completion call with only the prompt and maxTokens arguments supplied (all other completion settings are set to their defaults):",https://docs.ai21.com/reference/python-sdk-complete
Delete a dataset by id.,https://docs.ai21.com/reference/delete-dataset
You can use the Get datasets list endpoint to retrieve all of your datasets IDs.,https://docs.ai21.com/reference/delete-dataset
Upload a dataset crafted specifically to your use-case.,https://docs.ai21.com/reference/add-dataset
You can easily train your own custom model using our API. The training process is divided into 2 steps: ,https://docs.ai21.com/reference/datasets
Get a dadaset by id.,https://docs.ai21.com/reference/get-dataset
"You can generate a text completion for a given text prompt by posting an HTTP request to the complete endpoint corresponding to the desired language model to use. The request contains the input text, called a prompt and various parameters controlling the generation. For authentication, you must include your API key in the request headers. A complete response contains the tokenized prompt, the generated text(s), called completion(s), and various metadata. The request and response specifications are documented in full here.",https://docs.ai21.com/reference/j1-complete
"You can test our API in a web environment on this page, or download the Python SDK if you would like to use it in a Python project.",https://docs.ai21.com/reference/j1-complete
"The response is a nested data structure as described below. At its top level, the response has the following fields:",https://docs.ai21.com/docs/response#tokendata
A unique string id for the processed request. Repeated identical requests get different ids.,https://docs.ai21.com/docs/response#tokendata
"The prompt, including the raw text, the tokens with their logprobs and the top-K alternative tokens at each position, if requested.",https://docs.ai21.com/docs/response#tokendata
Has two nested fields:,https://docs.ai21.com/docs/response#tokendata
"List of completions, including raw text, tokens and logprobs. The number of completions corresponds to requested numResults.",https://docs.ai21.com/docs/response#tokendata
Each completions has two nested fields:,https://docs.ai21.com/docs/response#tokendata
"Both the prompt and each of the completions provide lists of TokenData, where each entry describes a token and, if requested, its top-K alternatives. An instance of TokenData contains the following fields:",https://docs.ai21.com/docs/response#tokendata
Has two nested fields:,https://docs.ai21.com/docs/response#tokendata
"A list of the top K alternative tokens for this position, sorted by probability, according to the topKReturn request parameter, or null if topKReturn=0.",https://docs.ai21.com/docs/response#tokendata
Each token in the list has a token (string) field and a logprob (float) field.,https://docs.ai21.com/docs/response#tokendata
The start and end offsets of this token in the decoded text string.,https://docs.ai21.com/docs/response#tokendata
"The Rewrite API of AI21 Studio provides you access to our state-of-the-art paraphrasing engine. It was designed specifically for paraphrasing purposes and has been fine-tuned for that task. Consequently, it's easier to integrate into your systems, and since it's optimized for this objective - it's also more efficient (and therefore cheaper) than building it from scratch.",https://docs.ai21.com/reference/rewrite
"This API takes a piece of text and returns a list of paraphrases that convey the same meaning using different words. As a specialized API for paraphrasing, it contains features to enable you more control over the output: adjust the tone and rewrite only parts of a text (while keeping the whole context).",https://docs.ai21.com/reference/rewrite
"By specifying an (optional) intent, you can generate paraphrases that are longer, shorter, more formal or more casual than the original text. You can rewrite a specific span while keeping the surrounding text unchanged by passing spanStart and spanEnd (also optional).",https://docs.ai21.com/reference/rewrite
Get a custom model by id.,https://docs.ai21.com/reference/get-custom-model
See all your available custom models.,https://docs.ai21.com/reference/get-custom-models-list
"Text generation is billed based on the number of requests you perform and the amount of text you generate, measured in 1K tokens. The input text is free, and fees vary by the size of the model you choose to use. For example, assume your prompt contains 1,000 tokens, and you generate 3 alternative completions, where each completion is 50 tokens long. Whether your model is pre-trained or fine-tuned to your data, the cost of the request would be as follow: J1-Large = $0.0003 (request) + $0.03 / 1000 x 150 (gen. tokens) = $0.0048. J1-Grande = $0.0008 + $0.08 / 1000 x 150 = $0.0128. J1-Jumbo = $0.005 + $0.25 / 1000 x 150 = $0.0425. Note that the input length doesn't affect billing, since input text is free.", https://studio.ai21.com/pricing
"Custom model training is billed based on the dataset size (measured in MB) and the number of epochs. A 200,000 word dataset is approximately 1MB. For example, if your training dataset is 1 million words, equivalent to the complete works of Shakespeare, it works out to about 5MB. Assuming that you'd like to train for 10 epochs, the training cost would be: J1-Large = $0.1 x 5 x 10 = $5. J1-Grande = $0.5 x 5 x 10 = $25. J1-Jumbo = $3 x 5 x 10 = $150.", https://studio.ai21.com/pricing
"Yes! You can sign up for free and immediately access all Jurassic-1 language models. Upon registration, you will receive 90$ credit for the first 3 months (trial period). With it, you can access all our services, including custom model training. After the trial period ends, you will need to upgrade to a paid plan to continue using your account.", https://studio.ai21.com/pricing
"Once your custom model is trained to your needs, deployment is instantaneous and entirely free of charge. Fees for your custom model's text generation are exactly the same as for a pre-trained Jurassic-1 model of the same size!", https://studio.ai21.com/pricing
"Our models differ in size, which correlates with cost, quality, and processing speed. Jumbo is the largest and most capable model, while Large is the smallest and most affordable. Grande sits between the two: both very capable and very affordable. Deciding between the models is mostly a matter of finding the right cost-quality tradeoff for your needs. Another factor to consider is processing speed, since Large and Grande provides lower latency and higher throughput than Jumbo.", https://studio.ai21.com/pricing
"Yes! Set up one pay-as-you-go account, and add other team members to your organization. To add team members, go to Account -> Organization -> Invite Member and type your teammate's email address. It's that simple. They will get an email with an invitation link to join your organization on AI21 Studio. The organization is billed through one credit card for the combined usage by all team members.", https://studio.ai21.com/pricing