title,text,link
Overview,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Overview
AI21 Studio is a platform that provides developers and businesses with top-tier natural language processing (NLP) solutions, powered by AI21 Labs‚Äô state-of-the-art language models.
Our second-generation language model series,
, is now available for you to use. The Jurassic-2 family base includes LMs of different sizes - Jumbo, Grande, and Large, as well as instruction-tuned LMs of Grande and Jumbo. Jurassic-2 offers top-tier performance with significant improvements in quality and new capabilities like instruction-following.
Jurassic-2 supports various non-English languages, including Spanish, French, German, Portuguese, Italian, and Dutch, and offers up to 30% faster performance.
Complete
Using our Complete API, you can generate text completions for an input prompt. You can embed the API in your application or service, or use our
to experiment with the models.
Instruct
The
Instruct models
API makes it easy to add instruction-following functionality to your applications. Simply integrate the API into your service and input specific instructions for execution. Our Instruct models are already trained to handle your instructions, so no examples are needed. You can also test the models in our
interactive web environment
.
Our
task-specific
APIs offer plug-and-play capabilities that enable you to implement generative AI in your products in minutes. The first collection of task-specific APIs is the Wordtune API, giving you access to the language models behind Wordtune, AI21 Labs‚Äô consumer-facing app that hosts tens of millions of users worldwide. The Wordtune API provides summarization, paraphrasing, grammatical error corrections, text improvement suggestions, and text segmentation.
Create your account on AI21 Studio and start building with Jurassic-2. We offer flexible pay-as-you-go plans as well as a free trial with a generous amount of free credits to get you started.
Updated
about 1 month ago
What‚Äôs Next
Quickstart
Table of Contents
Welcome to AI21 Studio! ü¶ñü¶ï
Jurassic-2
Task-Specific
How can I start",https://docs.ai21.com/docs/overview
AI21 Labs,"AI21 Labs
Company
About
Ask RBG
When Machines Become Thought Partners
AI has a way to go before it matches human intelligence.
We aim to get it a little bit closer.
NLP is the Next
AI Frontier
We are at the start of a revolution in Natural Language Processing (NLP), or the ability of machines to understand and generate natural text. It‚Äôs no coincidence that language is a unique human ability, so making significant progress in NLP calls for considerable scientific and engineering innovations.
At AI21 we aim to lead this revolution. And if we succeed, we'll have turned machines into the ultimate thought partners.
Reimagining
Reading and Writing
We believe both writing and reading can be radically transformed by making them AI-first experiences. Machines should work alongside humans and empower them to be better versions of their writing and reading selves.
Your thoughts
in words
AI21's premier product is a writing companion tool that helps you rephrase your writing to say exactly what you mean.
Start Writing
A revolutionary
reading experience
Wordtune Read is an AI reader that summarizes long documents so you can understand more, faster.
Start Reading
Advancing the Ecosystem
We make our sophisticated language models available to other developers who want to create
AI-powered
products at scale, inspiring them to dream up exciting applications in every domain.
Build scalable & efficient applications powered by AI21's state of the art language models that can process any language comprehension or generation task. No NLP expertise needed.
Start building
Generate and Analyze Text With Easy-To-Use Large Language Model APIs
Get started
Learn more
AI21 Studio offers a new way to launch NLP-based applications, with an array of Large Language Model APIs, and with the ability to easily customize those models to suit the needs of your application.
Build scalable & efficient applications powered by AI21's state of the art language models that can process any language comprehension or generation task.
Our
Technology
We believe that pattern recognition at scale - of the sort offered by current deep language models - is necessary but not sufficient to achieve our goals. We‚Äôre building enriched models that understand context and semantics at unprecedented levels.
Research & more
Dive into our demos, watch talks from our leadership, and read more about our advancements in natural language processing and machine learning.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Case study
How Verb created a game-changing author tool with AI21 Studio
Discover how Verb.ai used AI21 Studio to create a revolutionary writing tool for authors, improving brainstorming and expression. Read the case study now.
Read more
We are always on the lookout for outstanding people
Check out our open positions
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/
Advanced,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Advanced
For specific needs and use cases, the Advanced section contains information about practices and features that are less common and not needed to get started. This is similar to a car manual, where the basic information is needed to get started, but the advanced section contains information about less common practices and features.
Updated
6 months ago
What‚Äôs Next
Repetition penalties
Logit bias",https://docs.ai21.com/docs/advanced
Privacy Policy,"Company
About
Ask RBG
Start building
This is the privacy policy (‚ÄúPrivacy Policy‚Äù) that governs how we, AI21 Labs Ltd. (‚ÄúAI21‚Äù, ‚Äúwe‚Äù, ‚Äúour‚Äù or ‚Äúus‚Äù), use Personal Information (defined below) that we collect, receive and store about individuals in connection with the use of the website
https://www.ai21.com/
, and any other website that we operate (each, together with its sub-domains, content and services, a ‚ÄúSite‚Äù).
We do not ourselves host any of the services ‚Äì all hosting is done by third party service providers that we engage. This means that data you provide us or that we collect from you (including any Personal Information, as defined below) ‚Äì as further described in this Privacy Policy ‚Äì is hosted with such third party service providers on servers that they own or control. Regardless of where such third party service providers are located (and some are located in the US), their servers may be located anywhere in the world (including the US). Your data may even be replicated across multiple servers located in multiple countries. So please be aware that you are consenting to your data being transferred to various third party service providers around the world (including the US).
Introduction.
We have implemented this Privacy Policy because your privacy, and the privacy of other users, is important to us. This Privacy Policy explains our online information practices and the choices you can make about the way your Personal Information is collected and used in connection with the Site. ‚ÄúPersonal Information‚Äù means any information that may be used, either alone or in combination with other information, to personally identify an individual, including, but not limited to, a first and last name, an email address, a phone number, or other contact information.
Terms of Use.
This Privacy Policy forms part of our Terms of Use which is available at
http://www.ai21.com/terms
(‚ÄúTerms‚Äù). Any capitalized but undefined term in this Privacy Policy shall have the meaning given to it in the Terms.
Consent and Modification.
You are not legally obligated to provide us Personal Information, and you hereby confirm that providing us Personal Information is at your own free will. By using the Site, you consent to the terms of this Privacy Policy and to our collection, processing and sharing of Personal Information for the purposes set forth herein. If you do not agree to this Privacy Policy, please do not access or otherwise use the Site. We reserve the right, at our discretion, to change this Privacy Policy at any time. Such change will be effective ten (10) days following posting of the revised Privacy Policy on the Site, and your continued use of the Site thereafter means that you accept those changes.
What Personal Information We Collect and How We Collect It.
We do not currently require you to provide Personal Information in order to have access to general information available on the Site. But, we do receive and/or collect Personal Information from you in the following ways:
4.1.
‚ÄòContact Us‚Äô Information.
If you send us a ‚ÄúContact Us‚Äù request, whether by submitting an online form that we make available or by sending an email to an email address that we display, you may be required to provide us with certain information such as your name and email address.
4.2.
Log Files.
We may make use of log files. The information inside the log files includes internet protocol (IP) addresses, type of browser, Internet Service Provider (ISP), date/time stamp, referring/exit pages, clicked pages and any other information your browser may send to us. We may use such information to analyze trends, administer the Site, track users‚Äô movement around the Site, and gather demographic information.
4.3.
Cookies and Other Tracking Technologies.
Our Site may utilize ‚Äúcookies‚Äù, anonymous identifiers and other tracking technologies in order to for us to provide our Site and present you with information that is customized for you. A ‚Äúcookie‚Äù is a small text file that may be used, for example, to collect information about activity on the Site. Certain cookies and other technologies may serve to recall Personal Information, such as an IP address, previously indicated by a user. Most browsers allow you to control cookies, including whether or not to accept them and how to remove them. You may set most browsers to notify you if you receive a cookie, or you may choose to block cookies with your browser.
4.4.
Google Analytics.
The Site may use a tool called ‚ÄúGoogle Analytics‚Äù to collect information about use of the Site. Google Analytics collects information such as how often users visit this site, what pages they visit when they do so, and what other sites they used prior to coming to this Site. We use the information we get from Google Analytics to maintain and improve the Site and our products. We do not combine the information collected through the use of Google Analytics with personally identifiable information. Google‚Äôs ability to use and share information collected by Google Analytics about your visits to this Site is restricted by the Google Analytics Terms of Service, available at
http://www.google.com/analytics/terms/us.html
, and the Google Privacy Policy, available at
http://www.google.com/policies/privacy/
. You may learn more about how Google collects and processes data specifically in connection with Google Analytics at
http://www.google.com/policies/privacy/partners/
. You may prevent your data from being used by Google Analytics by downloading and installing the Google Analytics Opt-out Browser Add-on, available at
https://tools.google.com/dlpage/gaoptout/
The Way We Use Personal Information
. If you submit or we collect Personal Information through the Site, then we may use such Personal Information in the following ways, via any applicable communication channel, including but not limited to communication via email.
5.1. We will use your Personal Information to provide and improve our Site, to send you marketing/advertisement communications that we believe may be of interest to you, to contact you in connection with the Site and certain programs or offerings that you may have registered for.
5.2. We may use your designated email address to: (i) send you updates or news regarding the Site and our products; and/or (ii) respond to a ‚ÄúContact Us‚Äù or administrative request.
5.3. We may transfer your Personal Information to our local or foreign subsidiaries or affiliated companies for the purpose of storing or processing such information on our behalf. Such information may be transferred to other countries. We require that these parties agree to process such information in compliance with our Privacy Policy.
5.4. We may share your Personal Information with our third party service providers and partners, but only to assist us with our business operations and to provide our Site to you and other users. Such information may be transferred to other countries. We use commercially reasonable efforts to only engage or interact with third party service providers and partners that post a privacy policy governing their processing of Personal Information.
5.5. We may disclose your Personal Information or any information you submitted via the Site if we have a good faith belief that disclosure of such information is helpful or reasonably necessary to: (i) comply with any applicable law, regulation, legal process or governmental request; (ii) enforce our Terms, including investigations of potential violations thereof; (iii) detect, prevent, or otherwise address fraud or security issues; or (iv) protect against harm to the rights, property or safety of AI21, our users, yourself or the public.
Use of Anonymous Information.
We may use Anonymous Information (as defined below) or disclose it to third party service providers in order to improve our Site and enhance your experience with the Site. We may also disclose Anonymous Information (with or without compensation) to third parties, including advertisers and partners. ‚ÄúAnonymous Information‚Äù means information which does not enable identification of an individual user, such as aggregated information about the use of our Site.
Opting Out.
You may choose not to receive future promotional, advertising, or other Site-related emails from us by selecting an unsubscribe link at the bottom of each email that we send. Please note that even if you opt out of receiving the foregoing emails, we may still send you a response to any ‚ÄúContact Us‚Äù request as well as administrative emails (for example, in connection with a password reset request) that are necessary to facilitate your use of the Site.
Choice.
At all times, you may choose whether or not to provide or disclose Personal Information. If you choose not to provide mandatory Personal Information, you may still visit parts of the Site, but you may be unable to access certain options, programs, offers, and services that involve our interaction with you.
Access/Accuracy.
To the extent that you do provide us with Personal Information, we wish to maintain accurate Personal Information. If you would like to delete or correct any of your other Personal Information that we may be storing, you may submit an access request by sending an email to
. Your email should include adequate details of your request.
Links to and Interaction with Third Party Products.
The Site may enable you to interact with other third party websites that are not owned or controlled by us (each a ‚ÄúThird Party Service‚Äù). We are not responsible for the privacy practices or the content of such Third Party Services. Please be aware that Third Party Services may collect Personal Information from you. Accordingly, we encourage you to read the terms and conditions and privacy policy of each Third Party Service that you choose to use or interact with.
Children‚Äôs Privacy.
The Site is not structured to attract children under the age of 18 years. Accordingly, we do not intend to collect Personal Information from anyone we know to be under 18 years. If we learn that we have collected Personal Information from a child under 18 years, we will delete that information as quickly as possible. If you believe that we might have any such information, please contact us at:
Security.
The security of Personal Information is important to us. We follow generally accepted industry standards, including the use of appropriate administrative, physical and technical safeguards, to protect the Personal Information submitted to us. However, no method of transmission over the Internet, or method of electronic storage, is 100% secure. Therefore, while we strive to use reasonable acceptable means to protect your Personal Information, we cannot guarantee its absolute security or confidentiality. If you have any questions about security on the service, you can contact us at:
Merger, Sale or Bankruptcy.
In the event that we are acquired by or merged with a third party entity, or in the event of bankruptcy or a comparable event, we reserve the right to transfer or assign Personal Information in connection with the foregoing events.
California Privacy Rights.
California Civil Code Section 1798.83 permits our customers who are California residents to request certain information regarding our disclosure of Personal Information to third parties for their direct marketing purposes. To make such a request, please send an email to:
. Please note that we are only required to respond to one request per customer each year.
Our California Do Not Track Notice.
We do not track consumers over time and across third party websites and therefore do not respond to Do Not Track signals. We do not allow third parties to collect personally identifiable information about an individual consumer‚Äôs online activities over time and across different web sites when a consumer uses the Site.
Commitment.
We are committed to protecting your privacy. Protecting your privacy online is an evolving area, and we are constantly evolving our service to meet these demands. If you have any comments or questions regarding our Privacy Policy, or your Personal Information that we may be storing and using, please contact us at:
.
 
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/privacy-policy
Changelog,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Contexto m√°s largo in Contextual-Answers API
13 days ago
Contextual Answers API [Beta]
now supports an expanded context of 50,000 characters, allowing more text to be included in your source document. In addition, the API provides better support for multilingual capabilities, including Spanish, French, German, Portuguese, Italian and Dutch.
Transitioning to Jurassic-2: Important Updates on Model Retirements and Pricing Changes
We have a few updates to share regarding our Jurassic models at AI21 Studio:
Extending Context Window: Jurassic-2 Instruct Models Now Support 8K Tokens
22 days ago
We're thrilled to announce the extension of the 8K tokens support to our Jurassic-2 Instruct models, specifically J2-Grande-Instruct and J2-Jumbo-Instruct. These models, which are designed to meticulously follow instructions, can now accommodate a context window of 8,192 tokens, allowing for even more detailed and extensive interactions.
Fine-tuning Jurassic-2 models is now available!
Posted by Jack Yulzari
about 1 month ago
Custom model training on top of J2-Grande and J2-Large is now available.
improved
Increased Context Length for J2 Foundation Models
We are excited to announce that our Jurassic-2 Foundation models, including J2-Large, J2-Grande, and J2-Jumbo, now support an increased context length of up to 8K tokens (8192 tokens to be exact). This enhancement allows users to work with longer prompts and receive more comprehensive completions.
Contextual Answers API [BETA] Released
We are pleased to announce the release of the Contextual Answers API, a powerful tool for providing accurate and reliable question answering based on specific document context. This API is designed to avoid any factual issues that may arise when using language models to provide answers, and it receives document text and a question and returns an answer based solely on the provided context.
Introducing Wordtune-Powered Task-Specific APIs
about 2 months ago
We're thrilled to introduce our latest offering - the Task-Specific APIs package. This suite includes specialized language processing capabilities, making it effortless for you to integrate cutting-edge features into your systems. Our APIs are optimized and fine-tuned to ensure fast response times and high-quality results. We're proud to announce that all of our Task-Specific APIs are supported through our
Python SDK
, offering easy integration with your existing Python-based systems. These APIs are powered by the same engines behind our popular
Wordtune
products and include:
Jurassic-2 is now available
2 months ago
We are excited to announce the release of Jurassic-2 (J2), our latest and greatest series of Large Language Models. J2 builds upon the successes of Jurassic-1 and introduces new features and capabilities that set it apart from its predecessor.
New features in AI21 Studio: delete datasets & delete custom models
Posted by Yuval Belfer
Two new features are now available:
added
Python SDK is now available
Posted by Yotam Shinan
5 months ago
We are pleased to announce the availability of the
Python Software Development Kit
(SDK) for AI21 Studio's state-of-the-art natural language processing models, including the Jurassic-1 series and all specialized models.
1 of 2",https://docs.ai21.com/changelog
Prompt Engineering,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Prompt Engineering
Language models are great for generating text. However, we‚Äôd like to make sure the text adheres to our needs as developers. In many use cases, we‚Äôd like to feed the model with some input text and get an output text that satisfies the product need. To do so, you need to engineer the perfect prompt.
To be more concrete, imagine you're building a writing platform that helps your users to write easier in their own voice. One of the main features is paraphrasing: given a sentence, your app should automatically suggest paraphrases of the same sentence that are more fluent and customized to the writer's voice (BTW, if you do happen to build this kind of app and need such a feature - head on over to our
Paraphrase API
).
You‚Äôd like to use AI21 Studio language models to automatically generate the paraphrased suggestions. You can think of the models as smart autocompletion machinery: you feed in text, and the model will generate text that seems like a natural continuation. Your job is to make sure that the desired output (paraphrases, in this example) are the most natural continuation. In other words, you need to create the perfect input to the model, also known as a prompt. So, what are your tools to make that happen?
This is the simplest approach. Simply format your input prompt into a template that screams out what the completion should be:
Zero-shot prompt
[INPUT_TEXT]

Rewrite the sentence above:
Let's put a sentence (by Oscar Wilde) into the template and see what we get:
Be yourself; everyone else is already taken.

Rewrite the sentence above:
Feeding this text into the model, you‚Äôll get a nice completion:
Be yourself; you are the only one who can live your life.
Make sure the text and the output are distinguishable. Did you notice the empty line between ‚Äú[INPUT_TEXT]‚Äù and ‚ÄúRewrite the sentence above:‚Äù? üòâ So did the model. This will make it easier for the model to understand what to do.
Sometimes you'll be able to get better results if you specify the task twice - both at the beginning and at the end. In our case, you could use this template:
Here's a sentence, followed by a paraphrase of it:
[INPUT_TEXT]

A paraphrase of the sentence:
Look again at the output we got earlier. Maybe the new sentence isn‚Äôt exactly what you imagined, and you want a different one. This can be challenging to specify in the prompt.. or maybe it‚Äôs easy, but the model doesn't exactly meet your requirements. Suppose your user requires a formal tone. Simply adjusting the instruction to reflect this may not be enough, and the definition of formal may vary.
A powerful solution would be to use the few-shot approach. Here, you‚Äôll need to gather a few examples of <input text, output text> pairs that adhere to your product needs. You should format the pairs into a template such that the desired output would be the most natural continuation. In our case, a suitable template would look like this (assuming you have two example pairs):
[INPUT_TEXT_1]

Rewrite the sentence above to sound more formal:
[OUTPUT_TEXT_1]

###

[INPUT_TEXT_2]

Rewrite the sentence above to sound more formal:
[OUTPUT_TEXT_2]

###

[INPUT_TEXT_3]

Rewrite the sentence above to sound more formal:
To be more concrete, let's get examples of <input text, output text> that look like what we want, and format it into the template. Notice that we also add the input text provided by the user, but without a matching output text. We‚Äôll get this text that we‚Äôll feed into the model:
You only live once, but if you do it right, once is enough.

Rewrite the sentence above to sound more formal:
One life is all you get, but if you live it properly, you can live it for a lifetime.

###

If you tell the truth, you don't have to remember anything.

Rewrite the sentence above to sound more formal:
It is not necessary to remember anything if you tell the truth.

###

Be yourself; everyone else is already taken.

Rewrite the sentence above to sound more formal:
And here‚Äôs the generated result:
Do not pretend to be someone else; be yourself.
Seems that the model has captured the tone from the examples we provided. You can
try it yourself
in the playground.
Another advantage of the few-shot approach is that we can tell the model when to stop. Did you notice the ### at the end of every rewrite? Besides being a separator between the examples, which helps the model to distinguish between them, it also helps us in knowing when the model should stop generating more text. You can read more about stop sequences
here
Make sure the example inputs you gather are diverse. In the case of paraphrasing, if all the inputs are from the same domain (let‚Äôs say tech), the model might be worse when given an input text from a different domain, such as medical.
When using AI21 Studio for a classification task, make sure the outputs are balanced. For example, if instead of generating a paraphrase, you‚Äôd like to predict a topic out of 5 possible topics, make sure all topics appear in the examples you provide, in a similar frequency.
Moreover, make sure they‚Äôre shuffled: if all the preceding examples have the same topic, the model will be more likely to predict that topic, even if it‚Äôs not the right one.
Want to dive deeper to prompt engineering? Read our
blog post
.
Updated
about 2 months ago
Table of Contents
0Ô∏è‚É£ Zero-shot prompts
‚úç Few-shot prompts
ü™Ñ Tips & Tricks",https://docs.ai21.com/docs/prompt-engineering
Large Language Models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Large Language Models
Introduction to the core of our product
Natural language processing (NLP) has seen rapid growth in the last few years since large language models (LLMs) were introduced. Those huge models are based on the Transformers architecture, which allows for the training of much larger and more powerful language models.
We divide LLMs into two main categories: Autoregressive and Masked LMs (language models). On this page, we will focus on Autoregressive LLMs, as our language models, the Jurassic-1 series, belong to this category.
Autoregressive LLM is a neural network model composed from billions of parameters. It was trained on a massive amount of texts with one goal: to predict the next word, based on the given text. By repeating this action several times, every time adding the prediction word to the provided text, you will end up with a complete text (e.g., full sentences, paragraphs, articles, books, and more). In terms of terminology, the textual output (the complete text) is called a ‚Äúcompletion‚Äù, while the input (the given, original text) is called a ‚Äúprompt‚Äù.
Imagine you had to read all of Shakespeare's works repeatedly to learn a language. Eventually, you would be able to not only memorize all of his plays and poems, but also imitate his writing style.
In similar fashion, we trained the LLMs by supplying them with many textual sources. This has enabled them to gain an in-depth understanding of English, as well as general knowledge.
The LLMs are queried using natural language, also known as
prompt engineering
.
Rather than writing lines of code and loading a model, you write a natural language prompt and pass it to the model as the input. For example:
Data, computation, and engineering resources are required for training and deploying large language models. LLMs, such as our Jurassic-1 models, play an important role here, providing access to this type of technology to academic researchers and developers.
Updated
4 months ago
Table of Contents
‚ö° The task: predict the next word
üéì Added value: knowledge acquisition
üó£Ô∏è Interacting with Large Language Models
‚öôÔ∏è Resource-intensive",https://docs.ai21.com/docs/large-language-models
When Will a Language Model Stop Generating Text?,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
When Will a Language Model Stop Generating Text?
When will a language model stop generating texts? Let's find out!
Mentioned here: stop sequence, max tokens, min tokens
Language models were trained to generate text token by token and produce text completion in a scope that fits the prompt. Just like it learned how to generate text, it is also trained to know when to stop. Jurassic-1 tokenizers have a special token that signals when a reasonable generation should end by default. During pre-training, models were trained on text items containing stop sequence suffixes, and by doing so, they were adjusted to end sequences appropriately. However, there are times when the user will benefit from controlling the scope of the generated text, so how can you control the length of the sequence the models generate?
You can set a lower and upper bound for the amount of tokens the model will generate (
minTokens
and
maxTokens
, respectively). Note that this is very artificial and may cause texts to be cut off in the middle of a sentence.
You can set a stop sequence that tells the model to stop generating text. When the model generates this sequence, we can  make it stop generating more text afterwards. A simple example: in order to generate a single sentence, you can set the character ""."" as a stop sequence, which will signal the model to stop once it is generated.
This is very handy when using a few-shot prompt: where we feed the model with a prompt containing a few examples. A few-shot prompt contains one or more completion examples preceding the actual text to complete. Upon generating the completion, the model may repeat the few-shot structures and generate additional examples unless otherwise instructed. Therefore, it is recommended to separate the examples with a custom sequence, such as ‚Äú==‚Äù, and set it as a stop sequence. Once the text is generated, the model repeats the pattern and generates the separator, which indicates that text generation has been completed. See the example below:
Updated
3 months ago
Table of Contents
üìè Set completion length parameters
üõë Set a stop sequence",https://docs.ai21.com/docs/when-the-generation-stops
Terms of Service,"Terms of Service
Company
About
Ask RBG
Start building
Welcome to
https://www.ai21.com/
(together with its subdomains, Content, Marks and services, the ‚ÄúSite‚Äù). Please read the following Terms of Use carefully before using this Site so that you are aware of your legal rights and obligations with respect to AI21 Labs Ltd. (""AI21"", ""we"", ""our"" or ""us""). By accessing or using the Site, you expressly acknowledge and agree that you are entering a legal agreement with us and have understood and agree to comply with, and be legally bound by, these Terms of Use, together with the Privacy Policy (the ""Terms""). You hereby waive any applicable rights to require an original (non-electronic) signature or delivery or retention of non-electronic records, to the extent not prohibited under applicable law. If you do not agree to be bound by these Terms please do not access or use the Site.
1. Background.
The Site is intended to provide general information about AI21.
2. Modification.
We reserve the right, at our discretion, to change these Terms at any time. Such change will be effective ten (10) days following posting of the revised Terms on the Site, and your continued use of the Site thereafter means that you accept those changes.
3. Ability to Accept Terms.
The Site is only intended for individuals aged eighteen (18) years or older.
4. Site Access.
For such time as these Terms are in effect, we hereby grant you permission to visit and use the Site provided that you comply with these Terms and applicable law.
5. Restrictions.
You shall not: (i) copy, distribute or modify any part of the Site without our prior written authorization; (ii) use, modify, create derivative works of, transfer (by sale, resale, license, sublicense, download or otherwise), reproduce, distribute, display or disclose Content (defined below), except as expressly authorized herein; (iii) disrupt servers or networks connected to the Site; (iv) use or launch any automated system (including without limitation, ""robots"" and ""spiders"") to access the Site; and/or (v) circumvent, disable or otherwise interfere with security-related features of the Site or features that prevent or restrict use or copying of any Content or that enforce limitations on use of the Site.
6. Payments to AI21.
Except as expressly set forth in the Terms, your general right to access and use the Site is currently for free, but AI21 may in the future charge a fee for certain access or usage. You will not be charged for any such access or use of the Site unless you first agree to such charges, but please be aware that any failure to pay applicable charges may result in you not having access to some or all of the Site.
7. Intellectual Property Rights.
7.1.
Content and Marks. The (i) content on the Site, including without limitation, the text, documents, articles, brochures, descriptions, products, software, graphics, photos, sounds, videos, interactive features, and services (collectively, the ""Content""), (ii) the trademarks, service marks and logos contained therein (""Marks""), are the property of AI21 and/or its licensors and may be protected by applicable copyright or other intellectual property laws and treaties. ‚ÄúAI21‚Äù, the AI21 logo, and other marks are Marks of AI21 or its affiliates. All other trademarks, service marks, and logos used on the Site are the trademarks, service marks, or logos of their respective owners. We reserve all rights not expressly granted in and to the Site and the Content.
7.2.
Use of Content. Content on the Site is provided to you for your information and personal use only and may not be used, modified, copied, distributed, transmitted, broadcast, displayed, sold, licensed, de-compiled, or otherwise exploited for any other purposes whatsoever without our prior written consent. If you download or print a copy of the Content you must retain all copyright and other proprietary notices contained therein.
7.3.
Use of Haim Demo. The Site enables users to use a demo of 'Haim' ‚Äì our language model software (
""Demo""
). If you choose to use the demo please note that AI21 shall not be liable in any case that the content generated as a result of your use of the Demo will be inaccurate, offensive or inappropriate, and we disclaim all liability with respect thereof.
8. Information Description.
We attempt to be as accurate as possible. However, we cannot and do not warrant that the Content available on the Site is accurate, complete, reliable, current, or error-free. We reserve the right to make changes in or to the Content, or any part thereof, in our sole judgment, without the requirement of giving any notice prior to or after making such changes to the Content. Your use of the Content, or any part thereof, is made solely at your own risk and responsibility.
9. Links.
9.1 The Site may contain links, and may enable you to post content, to third party websites that are not owned or controlled by AI21. We are not affiliated with, have no control over, and assume no responsibility for the content, privacy policies, or practices of, any third party websites. You: (i) are solely responsible and liable for your use of and linking to third party websites and any content that you may send or post to a third party website; and (ii) expressly release AI21 from any and all liability arising from your use of any third party website. Accordingly, we encourage you to read the terms and conditions and privacy policy of each third party website that you may choose to visit.
9.2. AI21 permits you to link to the Site provided that: (i) you link to but do not replicate any page on this Site; (ii) the hyperlink text shall accurately describe the Content as it appears on the Site; (iii) you shall not misrepresent your relationship with AI21 or present any false information about AI21 and shall not imply in any way that we are endorsing any services or products, unless we have given you our express prior consent; (iv) you shall not link from a website (""Third Party Website"") which prohibits linking to third parties; (v) such Third party Website does not contain content that (a) is offensive or controversial (both at our discretion), or (b) infringes any intellectual property, privacy rights, or other rights of any person or entity; and/or (vi) you, and your website, comply with these Terms and applicable law.
10. Privacy.
We will use any personal information that we may collect or obtain in connection with the Site in accordance with our privacy policy which is available at:
http://www.ai21.com/privacy
. You agree that we may use personal information that you provide or make available to us in accordance with the Privacy Policy.
11. Warranty Disclaimers.
11.1. This section applies whether or not the services provided under the Site are for payment. Applicable law may not allow the exclusion of certain warranties, so to that extent certain exclusions set forth herein may not apply.
11.2. THE SITE (INCLUDING THE DEMO) IS PROVIDED ON AN ""AS IS"" AND ""AS AVAILABLE"" BASIS, AND WITHOUT WARRANTIES OF ANY KIND EITHER EXPRESS OR IMPLIED. AI21 HEREBY DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO IMPLIED WARRANTIES OF MERCHANTABILITY, TITLE, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, AND THOSE ARISING BY STATUTE OR FROM A COURSE OF DEALING OR USAGE OF TRADE. AI21 DOES NOT GUARANTEE THAT THE SITE WILL BE FREE OF BUGS, SECURITY BREACHES, OR VIRUS ATTACKS. THE SITE MAY OCCASIONALLY BE UNAVAILABLE FOR ROUTINE MAINTENANCE, UPGRADING, OR OTHER REASONS. YOU AGREE THAT AI21 WILL NOT BE HELD RESPONSIBLE FOR ANY CONSEQUENCES TO YOU OR ANY THIRD PARTY THAT MAY RESULT FROM TECHNICAL PROBLEMS OF THE INTERNET, SLOW CONNECTIONS, TRAFFIC CONGESTION OR OVERLOAD OF OUR OR OTHER SERVERS. WE DO NOT WARRANT, ENDORSE OR GUARANTEE ANY CONTENT, PRODUCT, OR SERVICE THAT IS FEATURED OR ADVERTISED ON THE SITE BY A THIRD PARTY.
11.3. EXCEPT AS EXPRESSLY STATED IN OUR PRIVACY POLICY, AI21 DOES NOT MAKE ANY REPRESENTATIONS, WARRANTIES OR CONDITIONS OF ANY KIND, EXPRESS OR IMPLIED, AS TO THE SECURITY OF ANY INFORMATION YOU MAY PROVIDE OR ACTIVITIES YOU ENGAGE IN DURING THE COURSE OF YOUR USE OF THE SITE.
12. Limitation of Liability.
12.1. TO THE FULLEST EXTENT PERMISSIBLE BY LAW, AI21 SHALL NOT BE LIABLE FOR ANY DIRECT, INDIRECT, EXEMPLARY, SPECIAL, CONSEQUENTIAL, OR INCIDENTAL DAMAGES OF ANY KIND, OR FOR ANY LOSS OF DATA, REVENUE, PROFITS OR REPUTATION, ARISING UNDER THESE TERMS OR OUT OF YOUR USE OF, OR INABILITY TO USE, THE SITE, EVEN IF AI21 HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR LOSSES. Some jurisdictions do not allow the limitation or exclusion of liability for incidental or consequential damages, so the above limitations may not apply to you.
13. Indemnity.
You agree to defend, indemnify and hold harmless AI21 and our affiliates, and our respective officers, directors, employees and agents, from and against any and all claims, damages, obligations, losses, liabilities, costs and expenses (including but not limited to attorney's fees) arising from: (i) your use of, or inability to use, the Site; (ii) your interaction with any Site user; or (iii) your violation of these Terms.
14. Term and Termination.
These Terms are effective until terminated by AI21 or you. AI21, in its sole discretion, has the right to terminate these Terms and/or your access to the Site, or any part thereof, immediately at any time and with or without cause (including, without any limitation, for a breach of these Terms). AI21 shall not be liable to you or any third party for termination of the Site, or any part thereof. If you object to any term or condition of these Terms, or any subsequent modifications thereto, or become dissatisfied with the Site in any way, your only recourse is to immediately discontinue use of the Site. Upon termination of these Terms, you shall cease all use of the Site. This Section ‚Äé15 and Sections ‚Äé7 (Intellectual Property Rights), ‚Äé10 (Privacy), ‚Äé12 (Warranty Disclaimers), ‚Äé13 (Limitation of Liability), ‚Äé14 (Indemnity), and ‚Äé16 (Independent Contractors) to ‚Äé19 (General) shall survive termination of these Terms.
15. Independent Contractors.
You and AI21 are independent contractors. Nothing in these Terms creates a partnership, joint venture, agency, or employment relationship between you and AI21. You must not under any circumstances make, or undertake, any warranties, representations, commitments or obligations on behalf of AI21.
16. Assignment.
These Terms, and any rights and licenses granted hereunder, may not be transferred or assigned by you but may be assigned by AI21 without restriction or notification to you. Any prohibited assignment shall be null and void.
17. Governing Law.
AI21 reserves the right to discontinue or modify any aspect of the Site at any time. These Terms and the relationship between you and AI21 shall be governed by and construed in accordance with the laws of the State of Israel, without regard to its principles of conflict of laws.
18. General.
These Terms shall constitute the entire agreement between you and AI21 concerning the Site. If any provision of these Terms is deemed invalid by a court of competent jurisdiction, the invalidity of such provision shall not affect the validity of the remaining provisions of these Terms, which shall remain in full force and effect. No waiver of any term of these Terms shall be deemed a further or continuing waiver of such term or any other term, and a party's failure to assert any right or provision under these Terms shall not constitute a waiver of such right or provision. YOU AGREE THAT ANY CAUSE OF ACTION THAT YOU MAY HAVE ARISING OUT OF OR RELATED TO THE SITE MUST COMMENCE WITHIN ONE (1) YEAR AFTER THE CAUSE OF ACTION ACCRUES. OTHERWISE, SUCH CAUSE OF ACTION IS PERMANENTLY BARRED.
 
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/terms-of-use
Tokenizer & Tokenization,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Tokenizer & Tokenization
Now that you know what large language models are, you must be wondering: ‚ÄúHow does a neural network use text as input and output?‚Äù
The answer is:
Tokenization
üß©
Any language can be broken down into basic pieces (in our case, tokens). Each of those pieces is translated into its own vector representation, which is eventually fed into the model. For example:
Each model has its own dictionary of tokens, which determines the language it ""speaks"". Each text in the input will be decomposed into these tokens, and every text generated by the model will be composed of them.
But how do we break down a language? Which pieces are we choosing as our tokens? There are several approaches to solving this:
As a simple solution, each character can be treated as its own token. By doing so, we can represent the entire English language with just 26 characters (okay, double it for capital letters and add some punctuation). This would give us a small token dictionary, thereby reducing the width we need for those vectors and saving us some valuable memory. However, those tokens don‚Äôt have any inherent meaning - we all know what the meaning of ‚ÄúCat‚Äù is, but what is the meaning of ‚ÄúC‚Äù? The key to understanding language is context. Although it is clear to us readers that a ""Cat"" and a ""Cradle"" have different meanings, for a language model with this tokenizer, the ""C"" is the same.
Another approach we can try is breaking our text into words, just like in the example above (""I want to break free"").
Now, every token has a meaning that the model can learn and use. We are gaining meaning, but that requires a much larger dictionary. Also, it raises another question: what about words stemming from the same root word, like ‚Äúhelped‚Äù, ‚Äúhelping‚Äù, and ‚Äúhelpful‚Äù? In this approach, each of these words will get a different token with no inherent relation between them, whereas for us readers, it's clear that they all have a similar meaning.
Furthermore, words may have fundamentally different meanings when strung together. For instance, my run-down car isn't running anywhere. What if we went a step further?
In this approach, we break our text into sentences. This will capture meaningful phrases! However, this would result in an absurdly large dictionary, with some tokens being so rare that we would require an enormous amount of data to teach the model the meaning of each token.
Each method has pros and cons, and like any real-life problem, the best solution involves a number of compromises. AI21 Studio uses a large token dictionary (250K), which contains some elements from every method: separate characters, words, word parts, such as prefixes and suffixes, and many multi-word tokens.
Updated
4 months ago
Table of Contents
üî° Character-level tokenization
üÜí Word-level tokenization
üí¨ Sentence-level tokenization
üèÖ Which is best?",https://docs.ai21.com/docs/tokenizer-tokenization
Recipes,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search",https://docs.ai21.com/recipes
Quickstart,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Quickstart
Using AI21 Studio, you can solve challenging text understanding and generation tasks. Its straightforward API and interactive playground allows you to get started in minutes, without any prior knowledge in Natural Language Processing (NLP).
Below is a quickstart guide to cover all the basics you need in order to start building your solution. After that, you should feel comfortable using our large language models to start and solve your own use-case.
A language model takes some text as input and produces a likely continuation. You can think of it as an exceptional student that can follow instructions and imitate examples.
Here are two words you should know:
Prompt
- the input you provide to the model.
Completion
- the output text the model returns.
You slept in and missed a crucial phone call? Here's how AI21 Studio can help you out of a bind: let's build an excuse generator.
The most naive thing to do is simply provide the model a prompt which is a simple instruction. This is what it looks like:
Zero-shot
, because we are giving the model zero examples. Occasionally this may work, but you may receive various types of completions. The structure and tone of the completion may differ from your expectation, for example a short excuse when expected something elaborated.
If you want to get the most benefit out of large language models, it is recommended to insert a prompt that includes several examples (similarly to teaching a student).
The previous excuse was too generic and could have been used for anything.
By providing the model with examples
, just as a human would, it could produce completions that are more aligned with your intentions. In order to help the model distinguish between each example, we use a stop sequence. The stop sequence itself should be immediately recognizeable when you look at the text as a whole. In this example, the stop sequence is
##
This is called
Few-shot
, because we are inserting a prompt which includes a few examples.
The previous results were rather serious and not the most original. If you‚Äôre looking for some more creative excuses,
it should be reflected in your examples
:
Surely this will work on even the most skeptical boss.
Another way to affect the completion is to adjust some of the model parameters. A useful parameter is the temperature.
You can increase creativity by tweaking the temperature
. With temperature 0, the model will always choose the most probable completion, so it will always be the same. Increasing the temperature will provide variable completions, where the completion may be different for every generation:
A task that requires accurate results (such as classification) is best performed with low temperature, whereas a task that requires more creativity should be conducted with high temperature (0.7 is a reasonable starting point).
Want to explore the various excuses the model can think of?
Try it yourself!
We encourage you to play with our models in the AI21 Studio. Take inspiration from other examples in the playground, such as
Twitter agent
Ads copywriter
,
Outline creator
and more. Finished playing? Learn more about our
completion API
You have a mission and want the best that Studio has to offer?
Optimal results are achieved by
training a custom model
.
Have any questions? Talk to us.
Updated
5 months ago
Table of Contents
Some basics
Experiment with your first use-case
1. Tell the model what you want to do
2. Provide examples
3. Make sure your examples reflect your needs
4. Adjust the parameters
What's next?",https://docs.ai21.com/docs/quickstart
AI21 Studio Documentation,"Jump to Content
Go to Playground
API Key
Account
Log In
AI21 Studio Documentation
Start building with our comprehensive guides, recipes and API references.
Get Started
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
View More‚Ä¶
How To...
Build a Dataset
Train a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Resources
Status Page
Terms of Use
Privacy Policy
Publications
Blog
Press",https://docs.ai21.com/
Latest Articles - Talks,"Latest Articles - Talks
Company
About
Ask RBG
Start building
All Categories
Events
Tutorial
Case study
Publications
Announcements
Blog posts
NLP in the 21st century
Yoav Shoham, AI21 Lab's co-founder, delivers his keynote address at WSDM 2021.
Natural language understanding as the next frontier
Amnon Shashua, AI21 Labs' Chairman & Professor at Hebrew Academy, shares his insights on NLU with the Israel Academy of Sciences and Humanities.
Current state of AI - challenges and opportunities
Yoav Shoham, AI21 Lab's co-founder & professor emeritus of Stanford University, walks us through the the current state of AI landscape.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/talks
AI21 Labs -  About,"AI21 Labs -  About
Company
About
Ask RBG
Start building
First, some background...
In the past decade, neural networks fueled by unprecedented volumes of data and powerful computing led to a revolution in computer vision - the ability of machines to understand and generate images.
Language is harder for machines than vision and requires tectonic shifts in the way we build these machines.
our mission
Why We‚Äôre Here
Simplifying history ever so slightly, in the past millennium there were two important milestones.
1980s
Microsoft PM defined Word, and we've been writing the same ever since.
1440s
Johannes Gutenberg invented the printing press, and we've been reading the same ever since.
Today
AI21 Labs is reimagining the way humans read and write, for the better.
They say two heads are better than one.
We say two heads - one human and one intelligent machine - are the best.
our technology
What We‚Äôre
Building
We‚Äôre building state of the art language models with a laser focus on understanding meaning. And to do this, we're simultaneously introducing scientific innovations and tackling frontier software engineering challenges posed by models of this size and sophistication.
Research & more
who we are
The Team
AI21 Labs was founded by AI pioneers and technology veterans in 2017, including Prof. Yoav Shoham (Professor Emeritus at Stanford), Ori Goshen (Founder of CrowdX), and our chairman, Prof. Amnon Shashua (Founder, Mobileye).
Our Advisors
Omri Abend
Yonatan Belinkov
Dan Jurafsky
Kevin Leyton-Brown
Chris R√©
Dan Roth
Shai Shalev-Shwartz
Sebastian Thrun
Sounds interesting? Come work with us!
Check out our open positions
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/about
Overview,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Overview
AI21 Studio is a platform that provides developers and businesses with top-tier natural language processing (NLP) solutions, powered by AI21 Labs‚Äô state-of-the-art language models.
Our second-generation language model series,
, is now available for you to use. The Jurassic-2 family base includes LMs of different sizes - Jumbo, Grande, and Large, as well as instruction-tuned LMs of Grande and Jumbo. Jurassic-2 offers top-tier performance with significant improvements in quality and new capabilities like instruction-following.
Jurassic-2 supports various non-English languages, including Spanish, French, German, Portuguese, Italian, and Dutch, and offers up to 30% faster performance.
Complete
Using our Complete API, you can generate text completions for an input prompt. You can embed the API in your application or service, or use our
to experiment with the models.
Instruct
The
Instruct models
API makes it easy to add instruction-following functionality to your applications. Simply integrate the API into your service and input specific instructions for execution. Our Instruct models are already trained to handle your instructions, so no examples are needed. You can also test the models in our
interactive web environment
.
Our
task-specific
APIs offer plug-and-play capabilities that enable you to implement generative AI in your products in minutes. The first collection of task-specific APIs is the Wordtune API, giving you access to the language models behind Wordtune, AI21 Labs‚Äô consumer-facing app that hosts tens of millions of users worldwide. The Wordtune API provides summarization, paraphrasing, grammatical error corrections, text improvement suggestions, and text segmentation.
Create your account on AI21 Studio and start building with Jurassic-2. We offer flexible pay-as-you-go plans as well as a free trial with a generous amount of free credits to get you started.
Updated
about 1 month ago
What‚Äôs Next
Quickstart
Table of Contents
Welcome to AI21 Studio! ü¶ñü¶ï
Jurassic-2
Task-Specific
How can I start",https://docs.ai21.com/docs
Sampling From Language Models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Sampling From Language Models
Exploring the way language models choose the next token. In here: Temperature, TopP, TopK
A language model knows how to complete texts
token
by token. But how does it choose the next token? Will it always choose the same token for a given sequence, or will it choose something different every time?
Given a prompt (the input to the model), the model generates a distribution over all possible completions (output from the model). It does that by calculating the probability of every token in the dictionary appearing next. Then, the model samples a completion according to the distribution.
Let's understand this by using a simple example. Suppose the prompt is the phrase ""I will"". Here is the distribution over all possible tokens (assuming a very small dictionary just for the demonstration):
There is a 55% chance that the model will choose the completion ""survive"", a 25% chance of the completion ""always love you"", etc. In simple words, it means that if we give the model this prompt 100 times, we'll likely get ‚Äúsurvive‚Äù 55 times, ""always love you"" 25 times, etc.
As users, we want to have some control over the output, so we can get the most out of it. The key is to somehow change the distribution the model samples without changing anything in the model. Here are three ways to adjust the sampling of language models using sampling parameters. Each of them has its own benefits, and it is also possible to combine them. In the end, it all comes down to what you need.
The most popular sampling parameter to play with is the temperature. Inspired by thermodynamics, low temperature means stagnation and high temperature means movement. The temperature value affects the distribution: for a low temperature, we get a higher weight for the most probable token. At 0 temperature, we always get the maximum token, and the distribution looks like this:
Namely, the model will always sample the same token at every call.
A high temperature does the exact opposite: the distribution tends to be as uniform as possible, meaning all tokens have about the same probability. It will look something like this:
So if you care about consistency and you always want to get the most likely completion (for example, in classification tasks), go for temperature=0. If you want more creativity (usually useful in text generation tasks), try a higher temperature (we recommend to start with 0.7).
Another sampling parameter that helps with adjusting the model‚Äôs sampling is TopK. It‚Äôs pretty simple: instead of using the full distribution, the model only samples from the K most probable tokens. For K=1, we basically get the same situation as temperature=0. In our example, for K=2, the distribution looks like this:
The third parameter is TopP. This is similar to TopK, but instead of limiting the number of tokens, we limit the total cumulative probability from which to sample. It works like this: we take the most likely token, add it to the pool, and add its probability to the amount. We continue adding tokens this way until the sum of probabilities reaches TopP.
What happens here is effectively similar to TopK: we remove the ""tail"" of the tokens with the lowest probabilities, except that TopP is more flexible for the number of tokens. In our example for TopP=0.95, we sample from the following distribution:
If you want accuracy rather than creativity, go for temperature 0. This is useful in tasks of classification (Classification) or when extracting interesting details from texts (Extraction).
If you deal with text generation tasks (whether short texts like tweets or long ones like whole posts) or getting ideas for slogans, for example, you probably need creativity. It is strongly recommended to raise the temp. Is the model getting a little too wacky? Keep the temperature high, but reduce the TopP/TopK and prepare to be amazed.
Updated
3 months ago
Table of Contents
üå°Ô∏è Temperature
üìä TopK
üì∂ TopP
üî® What can I do with this information?",https://docs.ai21.com/docs/sampling-from-language-models
AI21 Careers,"Company
About
Ask RBG
Start building
AI21 Careers
AI21 is bringing AI into the 21st century, developing AI systems with an unprecedented capacity to understand and generate natural language.
Our products
See open positions
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/careers
How Verb created a game-changing author tool with AI21 Studio,"Company
About
Ask RBG
Start building
Discover how Verb.ai used AI21 Studio to create a revolutionary writing tool for authors, improving brainstorming and expression. Read the case study now.
According to a
New York Times article
, 81 percent of Americans feel they have a book in them that they should write. Now, it may be an old statistic, but mankind‚Äôs desire to share stories
has been around since the dawn of time
as a way to share empathy, connection, and entertainment. So, it surely isn‚Äôt leaving human nature anytime soon.
But at the risk of stating the obvious: writing a book is hard. In fact, the writer of the aforementioned article, an author of 14 books, says ‚Äúwithout attempting to overdo the drama of the difficulty of writing ‚Ä¶ composing a book is almost always to feel oneself in a state of confusion, doubt and mental imprisonment.‚Äù
Yeah, it‚Äôs a lot of hard work.
So how did AI21 Studio help Verb, an AI-enhanced tool for fiction writers, create a cutting-edge application designed to help writers and hobbyists alike complete their novels without all the hassle and uncertainty?
We spoke to Ryan Bowman, publishing and creative writing veteran and part of Verb‚Äôs small team of founders, to find out how AI21 Studio was a key to such creative writing success.
Forging the Way toward a New Creative AI Tool
Verb
is a writing tool that helps make completing long-form narratives ‚Äì novels for now but later films, TV shows, even video games ‚Äì faster, easier, and more fun. It does so by assisting with all key stages of creation: brainstorming, writing, and editing. But all that wasn‚Äôt plausible until they found the perfect Language Learning Model (LLM). Let‚Äôs dive in further.
Use Case #1: Brainstorming Plot Points
As we saw in the New York Times quote above, keeping an entire story straight inside your head can be a lot of work. As anyone who‚Äôs tried to write long-form
anything
knows, it can get messy, convoluted, jumbled, and sometimes, uninspiring.
‚ÄúThey say novel writing is a group activity done by yourself,‚Äù Ryan tells us. ‚ÄúSo one of Verb‚Äôs jobs is to be that other person, that brainstorm partner.‚Äù That‚Äôs why they set out to create one of their most important ‚Äì and as it soon turned out, most popular ‚Äì functions inside of their app: brainstorming. This feature allows you to plan the novel scene by scene, chapter by chapter.
That type of brainstorming could look like the following:
You write: ‚ÄúBen is sitting in his office and a woman appears next door.‚Äù
You click: ‚ÄúSuggest a plot point‚Äù
AI generates: ‚ÄúThe woman pulls out a gun and chases him through the hallway.‚Äù
Then, you can either:
Run with that idea in your scene and use it as the next plot point, or
Continue clicking the ‚ÄúWhat happens next‚Äù button to generate more ideas until you find one that sparks your imagination and helps you continue.
An incredibly useful tool for writers, it‚Äôs been something that keeps these authors coming back for more. ‚ÄúOne of the most amazing findings we‚Äôve seen,‚Äù adds Ryan, ‚Äúis that the more you use what makes Verb special - AI features like plot planning, the more likely you are to come back and write.‚Äù
Use Case #2: Writing Literary Language
Generative AI models are incredibly diverse, and capable of outputting new content, summaries, translations, answers to questions, and more. But one thing they haven‚Äôt been able to do just yet is write literary works. That‚Äôs to say, these AI models can create ‚Äì but they‚Äôre not necessarily creative.
‚ÄúWe needed to build tools that are specific to the problems of a novelist. It couldn‚Äôt be just about generating text,‚Äù Ryan explains, noting that Verb knew the AI model they were to use must be able to generate discursive literary language.
‚ÄúLanguage Learning Models (LLM) are not natural storytellers,‚Äù says Ryan, going on to explain how much storytelling is a learned craft; something that must be practiced for years in order to call it a skill. ‚ÄúThere is 2,000 years of literary and practical theory backing up the idea that telling stories is hard ‚Äì important and necessary but difficult.‚Äù
Luckily, Ryan and the team at Verb found the literary solution they needed in AI21 Studio. ‚ÄúWhen generating texts for our users who are looking for more discursive, more literary, more discriminating language, AI21 turned out to have a good tone and feel,‚Äù he says.
Use Case #3: Fine-Tuning, Iterations & Customer Support
One of the critical tasks of validating generative models is having criteria. To validate the reliability of this sort of generative AI effectively, you still need human involvement ‚Äì especially when creating something brand new to the market.
How‚Äôd Verb achieve this? Verb built a platform that tests generative output amongst thousands of judgments across multiple writing professionals. These individuals look at different paragraphs of literary texts and decide which ones they like better, which ultimately helps Verb build a gradient of quality.
‚ÄúWe keep trying and testing and building iterations on top,‚Äù says Ryan, noting that they are always adding options to see which ones humans prefer. ‚ÄúAs crazy as it sounds, we are in the process of teaching it literary theory.‚Äù
Along the same lines, it‚Äôs important to note that creating something so new to the market doesn‚Äôt just call for multiple iterations but also gathers support from everyone involved.
‚ÄúWe‚Äôre in a world of newness,‚Äù Ryan laments. ‚ÄúThere is nothing like [Verb] so we‚Äôre not always sure what we‚Äôre supposed to be doing ‚Äì it is freeing and slightly frightening at the same time.‚Äù
Ryan and the team at Verb knew they needed a company that could see in their vision ‚Äì which is when they turned to AI21 Studio. ‚ÄúWe found working with AI21 to be a breath of fresh air,‚Äù says Ryan, noting that it felt like a collaboration done with real human faces they can interact with for guidance, assistance, and ideas ‚Äì rather than a business-client relationship.
The Results: More Authors Finishing their Novels, Faster
The
self-publishing landscape of 2022
shows that indie writers are becoming the new norm. But
AI has been an alleged threat to writers
since its inception, leading many people to believe that writers wouldn‚Äôt even want the help of an AI-enhanced tool to get them across the finish line.
So, of course, Verb also has to ask themselves the question: Are writers really interested in having a machine collaborator help them with their creative writing? ‚ÄúOur early data says that they are,‚Äù says Ryan, noting that since launching its alpha version using AI21 Studio, Verb has seen a dramatic uptake of this experimental tool.
Not to mention, as we saw with the brainstorming feature, the more creative and collaborative the model, the more likely writers are to stick around the app.
In fact, Ryan confirms that there are a dozen or so authors (out of an intimate group of alpha users) who have done the hardest task ‚Äì actually finishing their book! ‚Äì stating that Verb helped them do just that.
With Verb, and the help of AI21 Studio, it can be done. Dare we say ‚Äì it can be done faster, easier, and with more fun.
Verb.ai & Creative Texts in the Future
Verb launched its beta version in late December 2022 to a select number of users, and plans to use this custom model to expand into other narrative forms such as screenwriting and TV & Film.
With the pairing of new tools such as Verb with custom models from AI21 Studio, generative AI has evolved from just helping individuals generate text to something much more intertwined with the human love of storytelling; an AI tool that is not a threat to writers but actually a collaborator, a copy editor, a creative director, and even a confidante for inspired wordsmiths around the world.
Are you interested in building your own custom model with AI21 Studio by your side? Sign up for a
free account here
.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
How Verb created a game-changing author tool with AI21 Studio
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/verb-ai-case-study
J2 Complete,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
J2 Complete
post
https://api.ai21.com
/studio/v1/j2-
{model_type}
/complete
ü§ñ Generate text using Complete API
Get started with the Jurassic-2 Complete endpoint by trying out our interactive API Reference page. To authenticate your requests, simply enter your
AI21 Studio API key
in the Header input. And if you're building software with Python, consider using our
Python SDK
for even greater ease and flexibility.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/j2-complete-ref
Ai21 Labs News,"Ai21 Labs News
Company
About
Ask RBG
Start building
AI21 Labs News
PMI-Masking
We present a masking strategy that makes bidirectional masked-LM training more educating.
SenseBERT: Driving some sense into BERT
We enrich the self-supervision strategy employed in BERT by applying self-supervision on the Word-Sense level. Our model, SenseBERT, achieves significantly improved lexical disambiguation abilities, setting state-of-the-art results on the Word in Context (WiC) task.
Exemplar Guided Active Learning
Exemplar Guided Active Learning (EGAL) is a method we developed to economically annotate training data for tasks with extremely skewed label distributions, such as disambiguating rare word senses.
Grounding Language Models In-Context: Improving Text Generation and Attribution for Off-the-Shelf LMs
Text generation via language models (LMs) is dramatically improving, but LMs do not attribute their generated text to its sources and can often make mistakes. We propose the simple framework of ùòêùòØ-ùòäùò∞ùòØùòµùò¶ùòπùòµ ùòôùò¶ùòµùò≥ùò™ùò¶ùò∑ùò¢ùò≠ ùòàùò∂ùò®ùòÆùò¶ùòØùòµùò¶ùò• ùòìùò¢ùòØùò®ùò∂ùò¢ùò®ùò¶ ùòîùò∞ùò•ùò¶ùò≠ùò¥, which allows for grounding ùò¢ùòØùò∫ ùò∞ùòßùòß-ùòµùò©ùò¶-ùò¥ùò©ùò¶ùò≠ùòß ùòìùòî in knowledge from external sources, and attributing the text it generates to its sources.
Publications
Auxiliary Tuning and its Application to Conditional Text Generation
We designed a simple and efficient method, called Auxiliary Tuning, for adapting a pre-trained Language Model (LM) to a novel task, and demonstrated the approach on the task of conditional text generation.
NEWSLETTER
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
FOLLOW US
Twitter
LinkedIn
Facebook
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/news
J2 Complete API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
J2 Complete API
To generate text completions for a given prompt, you can send an HTTP request to the
endpoint of your desired
Jurassic-2 language model
. This request should include the input text prompt as well as any relevant parameters for controlling the text generation. Additionally, you must include
your API key
in the request headers for authentication purposes.
Once you've sent your
complete
request, you'll receive a response that includes the tokenized prompt, as well as the generated text completion(s). This generated text is referred to as
, and can include multiple outputs depending on the parameters you set. The response may also contain additional metadata relevant to the generation process.
Jurassic-2 models come in three variations -
Large
,
Grande
and
Jumbo
.
Large:
Designed for fast responses, this model can be fine-tuned to optimize performance for relatively simple tasks.
Grande:
This model offers enhanced text generation capabilities, making it well-suited to language tasks with a greater degree of complexity.
Jumbo:
As the largest and most powerful model in the Jurassic series, J2-Jumbo is an ideal choice for the most complex language processing tasks and generative text applications.
Each of these parameters can be used to customize the behavior of the Jurassic-2 language models, allowing developers to fine-tune the model's responses to better suit their needs:
: The initial prompt to generate responses from.
: The number of responses to generate for a given prompt.
maxTokens
: The maximum number of tokens to generate for each response.
minTokens
: The minimum number of tokens to generate for each response.
temperature
: A value controlling the ""creativity"" of the model's responses.
topP
: A value controlling the diversity of the model's responses.
stopSequences
: A list of sequences that, when generated, will cause the model to stop generating tokens.
: The number of top-scoring tokens to consider for each generation step.
frequencyPenalty
: A penalty applied to tokens that are frequently generated.
presencePenalty
: A penalty applied to tokens that are already present in the prompt.
countPenalty
: A penalty applied to tokens based on their frequency in the generated responses.
JavaScript
fetch(""https://api.ai21.com/studio/v1/j2-grande/complete"", {
  headers: {
    ""Authorization"": ""Bearer YOUR_API_KEY"",
    ""Content-Type"": ""application/json""
  },
  body: JSON.stringify({
      ""prompt"": ""These are a few of my favorite"",
      ""numResults"": 1,
      ""maxTokens"": 30,
      ""temperature"": 0.7,
      ""topKReturn"": 0,
      ""topP"":1,
      ""countPenalty"": {
        ""scale"": 0,
        ""applyToNumbers"": false,
        ""applyToPunctuations"": false,
        ""applyToStopwords"": false,
        ""applyToWhitespaces"": false,
        ""applyToEmojis"": false
      },
      ""frequencyPenalty"": {
        ""scale"": 0,
        ""applyToNumbers"": false,
        ""applyToPunctuations"": false,
        ""applyToStopwords"": false,
        ""applyToWhitespaces"": false,
        ""applyToEmojis"": false
      },
      ""presencePenalty"": {
        ""scale"": 0,
        ""applyToNumbers"": false,
        ""applyToPunctuations"": false,
        ""applyToStopwords"": false,
        ""applyToWhitespaces"": false,
        ""applyToEmojis"": false
      },
      ""stopSequences"":[""##""]
    }),
  method: ""POST""
});
JSON
{
  ""id"": ""75a54d20-dda1-6db7-ff99-59b1af4fdfd3"",
  ""prompt"": {
    ""text"": ""These are a few of my favorite"",
    ""tokens"": [
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅThese‚ñÅare"",
          ""logprob"": -8.139219284057617,
          ""raw_logprob"": -8.139219284057617
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 0,
          ""end"": 9
        }
      },
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅa‚ñÅfew"",
          ""logprob"": -4.903847694396973,
          ""raw_logprob"": -4.903847694396973
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 9,
          ""end"": 15
        }
      },
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅof‚ñÅmy‚ñÅfavorite"",
          ""logprob"": -1.543039321899414,
          ""raw_logprob"": -1.543039321899414
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 15,
          ""end"": 30
        }
      }
    ]
  },
  ""completions"": [
    {
      ""data"": {
        ""text"": "" things!\n\nI love entertaining, entertaining and decorating my home, entertaining clients, entertaining friends, entertaining family...you get the point! One of my favorite things to do is plan parties"",
        ""tokens"": [
          {
            ""generatedToken"": {
              ""token"": ""‚ñÅthings"",
              ""logprob"": -0.012797726318240166,
              ""raw_logprob"": -0.24019983410835266
            },
            ""topTokens"": null,
            ""textRange"": {
              ""start"": 0,
              ""end"": 7
            }
          },
          {
            ""generatedToken"": {
              ""token"": ""!"",
              ""logprob"": -2.060641050338745,
              ""raw_logprob"": -2.189206600189209
            },
            ""topTokens"": null,
            ""textRange"": {
              ""start"": 7,
              ""end"": 8
            }
          },
          {
            ""generatedToken"": {
              ""token"": ""<|newline|>"",
              ""logprob"": -0.840
...Text Truncated...

The response is a nested data structure containing information about the processed request, prompt, and completions. At the top level, the response has the following fields:
A unique string
id
for the processed request. Repeated identical requests receive different IDs.
includes the raw text, the tokens with their log probabilities, and the top-K alternative tokens at each position, if requested. It has two nested fields:
(string)
tokens
(list of TokenData)
A list of completions, including raw text, tokens, and log probabilities. The number of completions corresponds to the requested
numResults
. Each completion has two nested fields:
data
, which contains the
text
(string) and tokens (list of TokenData) for the completion.
finishReason
, a nested data structure describing the reason generation was terminated for this completion.
The TokenData object provides detailed information about each token in both the prompt and the completions. It includes the following fields:
generatedToken
field consists of two nested fields:
: The string representation of the token.
: The predicted log probability of the token as a float value..
field is a list of the top K alternative tokens for this position, sorted by probability, according to the
request parameter. If
topKReturn
is set to 0, this field will be null.
Each token in the list includes:
token
: The string representation of the alternative token.
logprob
: The predicted log probability of the alternative token as a float value.
The
field indicates the start and end offsets of the token in the decoded text string:
start
: The starting index of the token in the decoded text string.
end
: The ending index of the token in the decoded text string.
Table of Contents
Jurassic-2 Models
API Parameters
Example API Request
Example Response
Response
ID
prompt
completions
TokenData
generatedToken:
topTokens
textRange",https://docs.ai21.com/reference/j2-complete-api-ref
J2 Instruct API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
J2 Instruct API
Try Jurassic-2 Instruct API
here
Jurassic-2 Instruct models were developed to handle instruction-only prompts (""zero-shot"") without requiring examples (""few-shot""). This approach provides a more intuitive way to interact with large language models, allowing users to obtain the best possible output for their task without any examples. With their specialized training, Jurassic-2 Instruct models excel at generating coherent and precise text based solely on instructions provided by the user.
Jurassic-2 Instruct models come in two variations -
Grande-Instruct
and
Jumbo-Instruct
.
Grande-Instruct:
optimized for generating precise text based on minimal context, which makes it ideal for use cases such as chatbots and other conversational interfaces.
Jumbo-Instruct:
offers superior language understanding and response generation capabilities, making it ideal for advanced conversational interface needs.
JavaScript
fetch(""https://api.ai21.com/studio/v1/j2-grande-instruct/complete"", {
  headers: {
    ""Authorization"": ""Bearer YOUR_API_KEY"",
    ""Content-Type"": ""application/json""
  },
  body: JSON.stringify({
      ""prompt"": ""Write a tweet about the future of NLP\n"",
      ""numResults"": 1,
      ""maxTokens"": 50,
      ""temperature"": 0.8,
      ""topKReturn"": 0,
      ""topP"":1,
      ""countPenalty"": {
        ""scale"": 0,
        ""applyToNumbers"": false,
        ""applyToPunctuations"": false,
        ""applyToStopwords"": false,
        ""applyToWhitespaces"": false,
        ""applyToEmojis"": false
      },
      ""frequencyPenalty"": {
        ""scale"": 0,
        ""applyToNumbers"": false,
        ""applyToPunctuations"": false,
        ""applyToStopwords"": false,
        ""applyToWhitespaces"": false,
        ""applyToEmojis"": false
      },
      ""presencePenalty"": {
        ""scale"": 0,
        ""applyToNumbers"": false,
        ""applyToPunctuations"": false,
        ""applyToStopwords"": false,
        ""applyToWhitespaces"": false,
        ""applyToEmojis"": false
      },
      ""stopSequences"":[""##""]
    }),
  method: ""POST""
});
Jurassic-2 Instruct
{
  ""id"": ""029cd08c-f65b-06de-49d9-60b47c15e23a"",
  ""prompt"": {
    ""text"": ""Write a tweet about the future of NLP\\n"",
    ""tokens"": [
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅWrite"",
          ""logprob"": -9.832908630371094,
          ""raw_logprob"": -9.832908630371094
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 0,
          ""end"": 5
        }
      },
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅa‚ñÅtweet"",
          ""logprob"": -9.605907440185547,
          ""raw_logprob"": -9.605907440185547
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 5,
          ""end"": 13
        }
      },
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅabout‚ñÅthe‚ñÅfuture‚ñÅof"",
          ""logprob"": -11.053253173828125,
          ""raw_logprob"": -11.053253173828125
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 13,
          ""end"": 33
        }
      },
      {
        ""generatedToken"": {
          ""token"": ""‚ñÅNLP"",
          ""logprob"": -9.101167678833008,
          ""raw_logprob"": -9.101167678833008
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 33,
          ""end"": 37
        }
      },
      {
        ""generatedToken"": {
          ""token"": ""\\n"",
          ""logprob"": -12.08486557006836,
          ""raw_logprob"": -12.08486557006836
        },
        ""topTokens"": null,
        ""textRange"": {
          ""start"": 37,
          ""end"": 39
        }
      }
    ]
  },
  ""completions"": [
    {
      ""data"": {
        ""text"": ""The future of NLP is bright. Using NLP, we can train machines to understand language, reason about knowledge, and interact with humans naturally. #END"",
        ""tokens"": [
          {
            ""generatedToken"": {
              ""token"": ""‚ñÅ"",
              ""logprob"": -0.009251699782907963,
              ""raw_logprob"": -0.025562729686498642
            },
            ""topTokens"": null,
            ""textRange"": {
...Text Truncated...

Table of Contents
Jurassic-2 Instruct Models
Example API Request
Example Response",https://docs.ai21.com/reference/j2-instruct-api-ref
Press Room,"Company
About
Ask RBG
Start building
Press Room
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
April 13, 2023
A.I. Bots Can‚Äôt Report This Column. But They Can Improve It.
February 1, 2023
AI21 Labs launches Wordtune Spices to assist writers
AI21 Labs Proposes A New Method Called ‚ÄòIn-Context RALM‚Äô That Can Add Ready-Made External Knowledge Sources To The Existing Language Model
January 22, 2023
AI21 Jurassic-1 foundation model is now available on Amazon SageMaker
November 30, 2022
AI Dungeon‚Äôs Synthetic Story and Pictures Released on Steam Gaming Platform
August 1, 2022
OpenAI rival AI21 Labs raises $64M to ramp up its AI-powered language services
July 12, 2022
This AI model tries to re-create the mind of Ruth Bader Ginsburg
June 14, 2022
What an A.I. ‚ÄòMiracle‚Äô says about the future of business technology
April 19, 2022
Watch out, GPT-3, here comes AI21's 'Jurassic' language model
AI21 Labs trains a massive language model to rival OpenAI‚Äôs GPT-3
August 11, 2021
Artificial Intelligence Software Will Help Us Formulate Thoughts
December 30, 2020
How AI21 Lab's Wordtune Stacks Up Against Grammarly, GPT-3
Amnon Shashua's AI21 Raises $35M to Reinvent the World of Writing
November 19, 2020
Startup co-founded by AI heavy hitters debuts editing tool it hopes will ‚Äòtransform‚Äô writing
This AI infused writing assistant helps you find the right words
A new AI aims to be a ghostwriter in the machine
October 27, 2020
Press Kit
The company Boilerplate, logos & product screenshots.
Looking for something else? Contact us
press@ai21.com
.
Download Press Kit
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/press
Changelog,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Small yet useful new features for preset management, documentation and customer support
Posted by Jack Yulzari
We've added three small but useful features in this update.
As Roy T. Bennett, author of ‚ÄúThe Light in the Heart‚Äù, wrote: ‚Äú
You make the world a better place by making daily improvements to become the best version of yourself
.‚Äù
improved
A new version of AI21's documentation platform has been released!
The new documentation platform introduces more information on the use of our large language models, how to use our APIs, example recipes, and more!
Jurassic-1 Instruct is now available!
6 months ago
Jurassic-1 Instruct, our instruction-following language model, is now available in open beta! ü¶ñ
NEW: Delete custom presets and datasets
Two new features are included in this update: custom presets can be deleted and uploaded datasets can be deleted. Both of these features are extremely useful for anyone who has a large number of assets and wishes to organize them as well as remove older assets from their collections.
Introducing Rewrite API & Summarize API
7 months ago
We are excited to announce the launch of two specialized APIs from AI21 Studio: Rewrite API and Summarize API. Developed by our experts, these top-notch NLP models are designed to handle the complex tasks of paraphrasing and summarization accurately. All that‚Äôs left is to integrate them into your product and let the magic happen üîÆ‚ú®üí´
added
NEW: Overview page
Posted by Yuval Belfer
9 months ago
We have created a new Overview page to be the entry gate to our platform. With easy access to a set of premade examples (presets), API documentation and custom models, it should be a breeze to start working with our technology right away.
2 of 2",https://docs.ai21.com/changelog?page=2
AI21 Studio,"AI21 Studio
Access Jurassic-2, our next-generation foundation models, FREE for a limited time on a paid plan -
TRY NOW
Product
Foundation Models
Task-Specific APIs
Log In
Start Building
Differentiate your product with
generative text AI
AI21 Studio provides API access to Jurassic-2 large language models. Our models power text generation and comprehension features in thousands of live applications.
Start Building - It‚Äôs Free
Let's Talk
Let's talk
Trusted by developers in leading companies
Inactive-State
Active State
Why AI21 Studio?
Flexible
Take on any language task. Our Jurassic-2 models are trained to follow natural language instructions, requiring no examples to adapt to new tasks.
Specialized endpoints
Use our task-specific APIs for common tasks like summarization, paraphrasing and more. Access superior results at a lower cost without reinventing the wheel.
Customizable
Need to fine-tune your own custom model? You're just 3 clicks away. Training is fast, affordable and trained models are deployed immediately.
Embed AI-first experiences in your product
Leverage AI21 Studio's API across industries and use-cases
AI co-writer
Give your users superpowers by embedding an AI co-writer in your app. Drive user engagement and success with features like long-form draft generation, paraphrasing, repurposing and custom auto-complete.
Read More
AI co-reader
Help your users combat information overload. Compress long documents into short summaries, extract key points and offer high-fidelity semantic search over knowledge bases.
AI business insights
Make sense of unstructured text sitting idly in your data lake. Solve topic classification, sentiment analysis, entity extraction and other challenging language understanding tasks in 15 minutes.
AI content automation
Automate repetitive tasks across all stages of the writing process: drafting, editing and review. Empower content teams to easily expand their reach to new markets, platforms and audiences.
Try Now
Built for developers
Get up and running with one API call.
Start building for free, no credit card required.
Get Started
Integrate with your favorite stack in 3 lines of code
Compress timelines and reach your roadmap goals faster with our enterprise-ready API
Built for scale
We support millions of end users, and we know traffic can fluctuate with seasonality and business needs. Bring it on.
99.99% uptime
Enterprises need production grade reliability.
Designed for security
We are ISO27001 compliant.
Dedicated support
Our NLP experts are here to support you every step of the way.
Hear it from our customers
◊¥We were looking for language models that are fast and reliable while staying cost-effective.
AI21 Studio offers all of that in addition to being agile which is a must in our fast-paced marketplace!
Ryan Seamons
| VP Product
◊¥
AI21 Studio was a game changer in powering our chatbots.
We experienced an immediate impact both from our users and from the quality of information we extracted from chats with our users. Our conversion rate improved by 10X within a few weeks!""
Brent Davidoff
| Product director
Read Case Study
Playground
Interact with the models, explore our presets and play around. Ready to take things to the next level? Our API is at your disposal.
Start exploring
Documentation
Learn more about our language models, read the API reference, discover guides and best practices.
Read the docs
Community
Join the conversation in our Discord server. Regular updates, questions and feature requests - we are here to listen.
Join our community
Here for you
Want to rely on our models, but need some extra guidance? Our NLP experts are happy to help and answer any questions.
Contact us
Our mission is to
revolutionize reading and writing.
Our applications Wordtune and Wordtune Read already
help millions of users
every day. We‚Äôre here to help you do the same for your users!
API
Log in
Docs
Pricing
Terms of use
Privacy Policy
Featured
Case studies
Jurassic-2
Jurassic-X
Co-writing
Publications
Blog
Press
Stay updated
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.",https://www.ai21.com/studio
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation,"Company
About
Ask RBG
Start building
The ever-growing amount of online content makes it difficult for individuals and businesses to remain informed and make informed decisions.
Summarize API, one of our new
Task-Specific APIs
, is specifically built to tackle this textual overload in documents, articles, websites and more, by condensing lengthy amounts of text into short, easy-to-read bites.
Summarize API is powered by an optimized language model trained to perform summarization tasks, as opposed to general Large Language Models (LLMs) such as Open AI's GPT family, which do not target any one specific task.
So which model is better at summarizing?
Read the full whitepaper
Methodology
We evaluated AI21 Labs‚Äô Summarize API performance against OpenAI‚Äôs Davinci-003 and GPT-3.5-Turbo models, using various types of prompts, across both academic and real-world datasets (GPT-4 is not yet available for comparison at the time of writing this post).
We measured performance using both automated metrics and human evaluation.
Automated metrics include:
Faithfulness rate -
an indication of whether a summary is faithful, i.e., factually consistent with the original text
 
Compression rate -
the length of the generated summary relative to the original
Human professionals conducted blind evaluations in a methodological process measuring
pass rate
- the rate of summaries acceptable in real-world use cases.
Results
Across the various evaluations we conducted, AI21 Labs‚Äô Summarize API performes better or on par with OpenAI‚Äôs models, showing higher faithfulness, compression, and pass rates.
Summarize API especially excels in tests that use real-world data, producing summaries with significantly lower levels of hallucinations and reasoning violations.
OpenAI models were 2-4x more likely to produce summaries flagged by humans as ‚ÄúVery Bad‚Äù,
defined as completely unreliable summaries that contradict the source text or deviate from it substantially. Even with extensive prompt engineering, OpenAI‚Äôs results showed no significant improvements.
Some noteworthy stats:
Summarize API has an
18% higher pass rate
than OpenAI‚Äôs Davinci-003, even when a detailed prompt was used.
Summarize API presents a
19% higher faithfulness score
in comparison to OpenAI‚Äôs Davinci-003.
Summarize API achieved a
27% higher compression rate
than GPT-3.5-Turbo.
Summarize API has at least a
50% lower standard deviation of compression rate
, meaning that summaries are consistent in their short length.
Takeaways
AI21 Labs' Summarize API outperforms or on par with OpenAI's LLM results across a variety of models, datasets and prompt types.
The Summarize API holds other advantages as well. As an off-the-shelf solution that does not require prompting, it can generate summaries with only the original text as input. This provides a better user experience and more consistency in results.
Notably, human evaluation found OpenAI summaries to contain higher rates of hallucinations, reasoning violations and incoherence ‚Äì common and costly limitations in LLMs that produce unacceptable results in real-world usage.
To learn more about the research and results, read the full whitepaper here.
ABOUT THE AUTHOR
Yuval Belfer
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/summarize-api-outperforms-openais-models
AI21 Labs,"AI21 Labs
Company
About
Ask RBG
When Machines Become Thought Partners
AI has a way to go before it matches human intelligence.
We aim to get it a little bit closer.
NLP is the Next
AI Frontier
We are at the start of a revolution in Natural Language Processing (NLP), or the ability of machines to understand and generate natural text. It‚Äôs no coincidence that language is a unique human ability, so making significant progress in NLP calls for considerable scientific and engineering innovations.
At AI21 we aim to lead this revolution. And if we succeed, we'll have turned machines into the ultimate thought partners.
Reimagining
Reading and Writing
We believe both writing and reading can be radically transformed by making them AI-first experiences. Machines should work alongside humans and empower them to be better versions of their writing and reading selves.
Your thoughts
in words
AI21's premier product is a writing companion tool that helps you rephrase your writing to say exactly what you mean.
Start Writing
A revolutionary
reading experience
Wordtune Read is an AI reader that summarizes long documents so you can understand more, faster.
Start Reading
Advancing the Ecosystem
We make our sophisticated language models available to other developers who want to create
AI-powered
products at scale, inspiring them to dream up exciting applications in every domain.
Build scalable & efficient applications powered by AI21's state of the art language models that can process any language comprehension or generation task. No NLP expertise needed.
Start building
Generate and Analyze Text With Easy-To-Use Large Language Model APIs
Get started
Learn more
AI21 Studio offers a new way to launch NLP-based applications, with an array of Large Language Model APIs, and with the ability to easily customize those models to suit the needs of your application.
Build scalable & efficient applications powered by AI21's state of the art language models that can process any language comprehension or generation task.
Our
Technology
We believe that pattern recognition at scale - of the sort offered by current deep language models - is necessary but not sufficient to achieve our goals. We‚Äôre building enriched models that understand context and semantics at unprecedented levels.
Research & more
Dive into our demos, watch talks from our leadership, and read more about our advancements in natural language processing and machine learning.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Case study
How Verb created a game-changing author tool with AI21 Studio
Discover how Verb.ai used AI21 Studio to create a revolutionary writing tool for authors, improving brainstorming and expression. Read the case study now.
Read more
We are always on the lookout for outstanding people
Check out our open positions
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/
New features in AI21 Studio: delete datasets & delete custom models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
New features in AI21 Studio: delete datasets & delete custom models
5 months ago
by Yuval Belfer
Two new features are now available:
You uploaded too many datasets and your account is clustered? You can now delete datasets!
Have you trained a model that is no longer needed? It can be deleted from your account!
Both operations can be done through the playground or through the
API
.",https://docs.ai21.com/changelog/new-features-in-ai21-studio-delete-datasets-custom-models
Introducing Wordtune-Powered Task-Specific APIs,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Introducing Wordtune-Powered Task-Specific APIs
about 2 months ago
by Yotam Shinan
We're thrilled to introduce our latest offering - the Task-Specific APIs package. This suite includes specialized language processing capabilities, making it effortless for you to integrate cutting-edge features into your systems. Our APIs are optimized and fine-tuned to ensure fast response times and high-quality results. We're proud to announce that all of our Task-Specific APIs are supported through our
Python SDK
, offering easy integration with your existing Python-based systems. These APIs are powered by the same engines behind our popular
Wordtune
products and include:
Paraphrase API
: Offers access to our state-of-the-art paraphrasing engine, fine-tuned specifically for paraphrasing tasks, enabling you to control tone, style, and context.
Grammatical Error Corrections API
: Integrates our advanced engine into your writing platform, providing users with accurate grammar error detection and correction capabilities.
Text Improvements API
: Access our recommendation engine to enhance your users' writing experience and elevate their final product.
Summarize API
: Provides access to our advanced summarization engine, making it simpler to integrate into your systems and more efficient than developing one from scratch.
Text Segmentation API
: Intelligently segments text into coherent and readable units, based on distinct topics and lines, making it easier to break down long text into manageable chunks.
Try our Task-Specific APIs today and take advantage of their specialized capabilities to enhance your users' writing experience.",https://docs.ai21.com/changelog/announcing-task-specific-apis
"AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models","Company
About
Ask RBG
Start building
AI21 Labs is one of a select few Large Language model providers partnering with Amazon on this
exciting new service
.
Customers, particularly from large organizations, often struggle with the implementation of foundation models, which can be a long and arduous process as it often requires extensive procurement, legal, information security, and technical integration efforts.
Through AI21 Labs‚Äô partnership with Amazon, customers can bypass these processes to build and scale their own generative AI-driven applications with ease. Bedrock allows customers to seamlessly access, privately customize, integrate and consume our top-performing Jurassic-2 foundation models in their AWS environment without having to manage any infrastructure.
The
Jurassic-2 series
is one of the most cutting-edge foundation models available today, built to follow natural language instructions that include summarization, article and email writing, answering questions from a provided knowledge base, and more. Our models support English as well as several other languages including Spanish, French, German, Portuguese, Italian and Dutch.
Ori Goshen, AI21 Labs‚Äô CEO, shared his thoughts on this partnership. ‚ÄúAt AI21 Labs, we help businesses and developers use state-of-the-art language models with the goal of revolutionizing writing and reading experiences using generative AI and without requiring any natural language processing (NLP) expertise. We recently announced the Jurassic-2 family of models that offer best-in-class LLMs, bringing top-tier quality, flexibility, and high performance. We are excited about making Jurassic-2 models available through Amazon Bedrock because it enables developers to easily access Jurassic-2 without leaving their AWS environment and leverage the powerful generative text capabilities without worrying about managing the infrastructure. With the combination of Jurassic-2 models and Amazon Bedrock, developers can maximize the performance of language tasks while optimizing the cost thanks to the impressive zero-shot instruction-following capabilities and small footprint of Jurassic-2, and Bedrock‚Äôs cost-effective infrastructure.‚Äú
Today‚Äôs announcement further builds upon our partnership with AWS. In December, we jointly
announced
the integration of our models within Amazon's SageMaker platform. Jurassic-2‚Äôs availability on Bedrock now brings access to a wide range of builders who can easily consume our models through their Amazon cloud environment. We look forward to the continuation of this partnership as part of our mission to help businesses and developers revolutionize writing and reading experiences through the use of state-of-the art language models.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/announcing-amazon-partnership
Build a CV profile generator using AI21 Studio,"Company
About
Ask RBG
Start building
In just a few minutes, you can transform an idea into a working and integrated application using AI21 Studio
Can a machine automatically generate a paragraph of fluent text? Not so long ago, the answer to this question was ‚ÄòNo!‚Äô. Today, thanks to large language models, practitioners with different levels of expertise can build applications that generate useful text for marketing, content writing and more.
Hold on tight, because in this blog post we‚Äôre going to go from an idea to a completely new text generation feature that you can ship immediately. Ready to get started?
Motivation
Suppose you're building a job marketplace app or a personnel recruitment platform. You probably have a feature that lets candidates upload their CV to your system. Those CVs aren't always stellar. For example, many of them lack a profile section - a short paragraph that highlights the candidate‚Äôs background, skills and ambitions. Luckily, you can use AI21 Studio to help your users by auto-generating a CV profile for them. This is just one example of short-form content generation, where language models are used to draft text up to a paragraph long (more examples are in the summary).
In this post we'll build a CV profile generator that you can integrate into your application or website in just a few minutes of work.
Step 1: Define the problem
Understanding what kind of text you want to generate is essential. In this case we need to ask ourselves:  what makes a good CV profile that our users will appreciate? Let‚Äôs take a look at some examples and try to find ones we like.
Here
is an article you can find online that shows various types of CV profiles. For example, let‚Äôs look at a profile for a chemical engineer:
I am a dedicated, hardworking and proactive Chemical Engineer with a strong background in design, plant operations, offshore operations, and process and safety improvements. I have solid work experience in designing, testing and analysing processes to increase the overall efficiency of operations. I am currently looking for an opportunity to utilise my technical skills in a challenging working environment and become a valuable asset to the organization that I work for.
As you can see, it‚Äôs a short paragraph that covers the candidates background, experience and the type of role they are looking for. Browsing through more examples, it is clear that most CV profiles follow this pattern. Let‚Äôs make a note of a few examples (3-5 will do) that we like. Our goal is to generate texts similar to these examples. Now we are ready to log into the AI21 Studio and start building.
Step 2: Create your (initial) prompt
Language models take in some text as input and generate some likely continuation of that text. We call the input text the
prompt
and the generated text the
completion
. You can think of large language models as smart auto-completion algorithms: they are very good at latching on to hints and patterns expressed in plain English, and generating text that follows the same patterns.
For example, if we input a prompt that is likely to be followed by a CV profile, we can get the model to generate new and original CV profiles as completions. One simple way to do this is to spell out an instruction, just like you would when asking a person to produce some text:
Let‚Äôs take this prompt and see what the model will generate. Go to the AI21 Studio, put this prompt in the input field and click ‚Äúgenerated‚Äù. This is the completion the model generated:
Mr George Mwangi is a Teacher who has completed Diploma, Degree and Masters Degree in Education. He has vast teaching experience of 7 years. His expertise is in the field of Science, Biology, Chemistry and Physics. He is a hardworking, dedicated candidate with vast experience of teaching various levels, including University students.
What do we like about this completion?
It matches the profession we provided (Teacher).
It contains relevant education and experience.
It uses some good adjectives.
What do we not like about this completion?
This paragraph is written in third person (‚ÄúMr Mwangi is‚Ä¶‚Äù), whereas our good CV profile examples are always written in the first person (‚ÄúI am‚Ä¶‚Äù).
The details the model generated are completely made up - they may or may not reflect our candidates' true skills.
How can we make the model produce the output we want?
You can try to phrase the instruction differently. Be descriptive and clear, and try a few different ones, like:
Following is an exceptional CV profile for a Teacher:
or
Here is an enthusiastic Teacher‚Äôs CV profile:
That said, you shouldn't spend too much time on choosing the perfect adjectives.
The most powerful tool you have at your disposal is providing examples that demonstrate what you expect from the model. This is the most effective way to guide the generations according to your intentions, and if you have time to do only one thing - this is it.
In this case, we already collected some relevant examples in Step 1. All that‚Äôs left is to create the prompt from instruction-profile pairs. Below you can find a prompt we made by stringing together a sequence of examples we liked. The bold text is the completion our model generated.
Write a winning Sales/retail CV profile:
I am a mature, positive and hardworking individual, who always strives to achieve the highest standard possible, at any given task. In my previous role as a Sales Representative, I demonstrated the ability to work under intense pressure, sell products and services to customers from all backgrounds, handle customer complaints and solve problematic situations as and when they arose. I was promoted twice for exceeding my sales targets.
Write a winning Teaching CV profile:
I am a loyal, talented and caring teacher who loves making a difference in the lives of young children. I am open-minded, patient and supportive towards other people, especially towards children or those who suffer from disabilities. In my previous role as a primary school teacher, I have taught and nurtured more than 100 pupils from all backgrounds, successfully preparing them for the next stages of their young lives.
Write a winning Media CV profile:
I am a professional, ambitious and highly skilled Camera Operator able to use a wide range of technical equipment, including professional cinematography camcorders. I have extensive experience working on a number of television and theatre projects, demonstrating an ability to follow artistic direction and the physical capability required on a professional production set. I am comfortable filming on-location and outside the studio with some previous work experience in live broadcasting.
Write a winning Software Engineer CV profile:
I am a highly talented Software Engineer with extensive experience of developing complex software systems. I have excellent analytical and problem-solving skills, which allow me to quickly identify and resolve problems. I am self-motivated, able to work on my own initiative and as part of a team. I have excellent communication skills, both written and verbal, and I am able to communicate effectively with people from a wide range of backgrounds.
Did we solve all the problems? Well, the profile is written in first person, just like we wanted. Unfortunately, it still contains made up details. We solve this in the following section.
There are a couple of important things to note here:
The instruction we chose was ‚ÄúWrite a winning ‚Ä¶ CV profile:‚Äù. It‚Äôs good to be consistent and use the exact same phrasing throughout the examples in the prompt.
Each CV profile ends with a pair of hashes, which establishes a pattern for the model to follow. As a result, when the model produces a new CV profile in the completion, it generates ‚Äò##‚Äô after it. We can use this signal to detect that the entire profile has been written and terminate the generation using the
stop sequence parameter
Want to see the generation or check another profile?
Try it yourself in our playground
Step 3: Add personalization to your prompt
The prompt we have at this point produces well-formatted, impressive-sounding CV profiles for specific roles. You can try it in the playground and see that it‚Äôs pretty reliable. Each time we generate a new text, we get a random profile for a candidate for the desired role.
Although the profiles fit the role, they may be inconsistent with the candidates' actual skills, experience and ambitions. You probably want to provide your users a way to guide the generated profile to stick to the facts that are true for them. One way to do it is to inject specific features that you want to be reflected in the profile into the instruction.
We took the prompt from the previous section and tweaked it to include ‚Äúfeatures‚Äù. We extracted them manually from the examples we gathered earlier. This is the completion generated by the model:
Write a winning Business management CV profile incorporating the following features:
1. Logical mind
2. Problem solver
3. 2 years of experience in management
4. Eager to learn
Write a winning IT CV profile incorporating the following features:
I am a highly competent IT professional with a proven track record in designing websites, networking and managing databases. I have strong technical skills as well as excellent interpersonal skills, enabling me to interact with a wide range of clients. I am eager to be challenged in order to grow and further improve my IT skills. My greatest passion is in life is using my technical know-how to benefit other people and organisations.
Write a winning Sales Executive CV profile incorporating the following features:
1. Energetic and ambitious
2. 6 years of selling experience
3. Love working in a team
4. Independent
5. MBA from Stanford
You can see that now we can direct the model to include specific skills and experience!
Want to see how your features turn into a profile?
Try here
.
When working with prompts like these, it is critical to maintain a strong correlation between the features and the generation. If an example's output mentions facts that totally contradict the input or are completely original and unrelated, the model will follow suit and have a tendency to make up things. We call this phenomenon ‚Äúhallucinations‚Äù. On the other hand, if you omit certain features from an example's output, the model will imitate this and occasionally drop some of the provided features.
To understand that, let‚Äôs take a look at the following bad example (do NOT try this at home!):
Write a winning Business manager CV profile incorporating the following features:
1. Creative person
2. experience in management
3. Have an MBA from Stanford
I have a clear, logical mind with a practical approach to problem-solving and a drive to see things through to completion. I have more than 2 years of experience in managing and leading teams across multiple sectors. I am eager to learn, I enjoy overcoming challenges, and I have a genuine interest in Business Management and making organisations successful.
Write a winning IT manager CV profile incorporating the following features:
1. Experience IT professional
2. Record designing websites, networking and managing databases
3. Excellent interpersonal skills
4. Looking for a challenge
Profile:
Having 3 years experience in all aspects of IT, including web design, networking, databases and technical support. I am looking for a new challenge. I thrive in challenging environments and I am committed to high standards in all aspects of my work.
##
A single example (Business manager) was fed into the model here, but there is some mismatch between some skills and the profile. The table below shows both phenomena in this example: What was wrong with the prompt, and how it affected the completion.
Prompt (Business manager)
Completion (IT manager)
Hallucination
2 years of experience
3 years of experience
Omission
Creativity, MBA
interpersonal skills
Step 4: Explore the parameters
Another way to affect the completion is to adjust some of the generation parameters. There are quite a few parameters and you can learn about them
here
. For now, let's focus on one of the most significant parameters: Temperature.
The temperature controls creativity. Increasing the temperature tends to result in more varied and creative completions, whereas decreasing it produces more stable and repetitive completions. With temperature set to zero, the model will always generate the most probable completion for a given prompt (which will be the same completion every time).
Below are examples of three different generations using the same prompt from the previous step:
Temperature
Completion
0
I am an energetic and ambitious Sales Executive with 6 years of selling experience. I am a team player, but I am also able to work on my own initiative. I am an MBA from Stanford, and I am looking for a challenging position where I can use my sales skills to benefit an organisation.
0.7
I am ambitious, energetic and hard-working. Over the last 6 years, I have gained valuable experience in selling products and services to businesses and consumers. I possess strong communication and presentation skills and I am a team player. I am good at building relationships with clients and I am known for my integrity and honesty. I am currently studying for an MBA from Stanford. I am confident that I can build a successful career in sales.
1
I am an extremely ambitious and energetic individual with 6 years of selling experience. I have a strong Business Administration degree, along with an MBA from Stanford, which has increased my market knowledge. I am a team player who thrives in challenging environments and relishes the opportunity to work autonomously.
Want to see more results?
Try it yourself
in the playground!
Step 5: Integrate with your code
After you've finished building your prompt and you are happy with the results you see in the playground, you'd want to integrate some code to call the AI21 Studio API in your product. You can click the API button and copy the necessary code snippet.
The request includes your API key (which is linked to your account), certain parameters, and more importantly - the prompt. In production the prompt will need to end with a different input every time we generate a completion, corresponding to the role and the candidate features. We'll need to write a bit of code that injects this into our prompt. Here's how you would do it in Python:
def create_prompt(role, highlights):
    """"""
        Arguments:
        - role         : what is the profession of the candidate
        - highlights   : what are the skills and ambitions of the candidate

        Returns:
        - prompt       : a full prompt, including few shot examples
    """"""
    
    few_shot_prompt = #Paste here the few shot prompt, ends with the stop sequence#
    current_input = f""Write a winning {role} incorporating the following features:\n""
    skills_str = """"
    for i in range(len(highlights)):
        skills_str += f""{i + 1:d}. {highlights[i]}\n""
    skills_str += ""\nProfile:""

    return few_shot_prompt + current_input + skills_str
Check out this
notebook
for more details.
Summary
In this post, we have explored the process of going from an idea to an implementation of a short-form text generation feature with AI21 Studio. Other examples of short-form text that you can generate with AI21 Studio are
tweets
online ads
,
product descriptions
and more.
Creating a good prompt is a process that involves some trial and error, but it doesn't require a PhD in AI. So don't give up if your first attempt fails to produce good results. Look for good examples and keep iterating!
 
ABOUT THE AUTHOR
Yuval Belfer
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Tutorial
Build a CV profile generator using AI21 Studio
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/building-cv-profile-generator-using-ai21-studio
Python SDK is now available,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Python SDK is now available
5 months ago
by Yotam Shinan
We are pleased to announce the availability of the
Python Software Development Kit
(SDK) for AI21 Studio's state-of-the-art natural language processing models, including the Jurassic-1 series and all specialized models.
This SDK enables developers to easily connect their Python applications to AI21 Studio's advanced language processing capabilities, such as text completion, instruct commands, rewrite, summarization, and more. In addition, the SDK includes several helpful utilities, such as automatic authentication and error handling, to facilitate the integration of Jurassic-1 into Python applications.
Install AI21 Studio Python SDK",https://docs.ai21.com/changelog/python-sdk-is-now-available
Jurassic-2 is now available,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Jurassic-2 is now available
2 months ago
by Yotam Shinan
We are excited to announce the release of Jurassic-2 (J2), our latest and greatest series of Large Language Models. J2 builds upon the successes of Jurassic-1 and introduces new features and capabilities that set it apart from its predecessor.
The J2 series includes 3 base language models, and 2 instruction-tuned language models, all accessible through the AI21 Studio API:
J2-Jumbo
: The largest and most powerful model in the Jurassic series. Ideal for the most complex language processing tasks and generative text applications.
J2-Grande
: Offers enhanced text generation capabilities, making it well-suited to language tasks with a high degree of complexity.
J2-Large
: Features fast response times and less processing power. Ideal for tasks that require maximum affordability.
J2-Grande-Instruct
: Designed specifically for generating text based on minimal context. Highly accurate, and can be fine-tuned to power smart chatbots and other conversational interfaces.
J2-Jumbo-Instruct
: Similar to Grande-Instruct, but with superior language understanding and response generation capabilities. Ideal for users with more advanced conversational interface needs.",https://docs.ai21.com/changelog/jurassic-2-and-task-specific-apis-are-now-available
Contextual Answers API [BETA] Released,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Contextual Answers API [BETA] Released
about 2 months ago
by Yotam Shinan
We are pleased to announce the release of the Contextual Answers API, a powerful tool for providing accurate and reliable question answering based on specific document context. This API is designed to avoid any factual issues that may arise when using language models to provide answers, and it receives document text and a question and returns an answer based solely on the provided context.
The
Contextual Answers API
is optimized for efficiency and is a Task-Specific API that can be easily integrated into existing systems without requiring any prompt engineering. With this API, you can get a high-quality, grounded question answering mechanism in just a matter of seconds. Additionally, it provides a user-friendly and efficient solution for accurate and context-based question answering.
The API requires two parameters for a successful request:
context
and
question
, both of which should be provided as plain text strings. The API returns a response with an
answer
parameter containing the text of the answer.
We hope that the Contextual Answers API will prove to be a valuable resource for your projects and look forward to seeing the innovative applications that you will build with it. Please let us know if you have any questions or feedback.",https://docs.ai21.com/changelog/contextual-answers-api-beta-released
Python SDK,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Python SDK
This SDK enables interaction with all of AI21 Studio's models and services, including Jurassic-2 and Task-Specific APIs.
To get started with AI21's SDK, you'll need to install it first. To do so, simply run the following command:
Terminal
$ pip install ai21
Before you can start using the SDK, you'll need to obtain your API key from
AI21 Studio
. Once you have your API key, you can set it globally in your Python code like this:
import ai21
ai21.api_key = <YOUR_API_KEY>
To generate text using Jurassic-2 language models, you need to provide a prompt for the model to complete. We recommend following our
Prompt Engineering
best practices to achieve the best results.
Here are a couple of examples of prompts you can use to get started:
""Zero Shot"" prompt:
prompt = ""These are a few of my favorite""
""Few Shot"" prompt:
prompt = """"""
Complete the following sentence.
Sentence: These are a few of my favorite
Completion: things. Cream-colored ponies and crisp apple strudels.

##

Complete the following sentence.
Sentence: These are a few of my favorite
Completion: rock bands: The Beatles, The Doors, Fleetwood Mac.

##

Complete the following sentence.
Sentence: These are a few of my favorite
Completion:
""""""
Below is a sample usage of the AI21 Python SDK to interact with Jurassic-2 models, demonstrating some of the frequently utilized parameters:
import ai21
ai21.api_key = <YOUR_API_KEY>

# J2 Grande
response_grande = ai21.Completion.execute(
  model=""j2-grande"",
  prompt=""These are a few of my favorite"",
  numResults=1,
  maxTokens=2,
  temperature=0.4,
  topKReturn=0,
  topP=1,
  stopSequences=[""##""]
)

# J2 Grande Instruct
response_grande_instruct = ai21.Completion.execute(
  model=""j2-grande-instruct"",
  prompt=""explain black holes to 8th graders"",
  numResults=1,
  maxTokens=100,
  temperature=0.7,
  topKReturn=0,
  topP=1,
  stopSequences=[""##""]
)

print(response_grande)
print(response_grande_instruct)
By customizing these parameters, you can control the content and style of the generated text. For a full list of available options, check out our
Complete API
page.
All Jurassic-2 models can be interacted with using the same ai21.Completion.execute() function, including j2-large, j2-grande, j2-jumbo, j2-grande-instruct, and j2-grande-jumbo.
Here's an example of a response object from executing a j2-grande model:
JSON
{
   ""id"":""94078cb6-687e-4262-ef8f-1d7c2b0dbd2b"",
   ""prompt"":{
      ""text"":""These are a few of my favorite"",
      ""tokens"":[
         {
            ""generatedToken"":{
               ""token"":""‚ñÅThese‚ñÅare"",
               ""logprob"":-8.824776649475098,
               ""raw_logprob"":-8.824776649475098
            },
            ""topTokens"":""None"",
            ""textRange"":{
               ""start"":0,
               ""end"":9
            }
         },
         {
            ""generatedToken"":{
               ""token"":""‚ñÅa‚ñÅfew"",
               ""logprob"":-4.798709869384766,
               ""raw_logprob"":-4.798709869384766
            },
            ""topTokens"":""None"",
            ""textRange"":{
               ""start"":9,
               ""end"":15
            }
         },
         {
            ""generatedToken"":{
               ""token"":""‚ñÅof‚ñÅmy‚ñÅfavorite"",
               ""logprob"":-1.0864331722259521,
               ""raw_logprob"":-1.0864331722259521
            },
            ""topTokens"":""None"",
            ""textRange"":{
               ""start"":15,
               ""end"":30
            }
         }
      ]
   },
   ""completions"":[
      {
         ""data"":{
            ""text"":"" things ‚Äì"",
            ""tokens"":[
               {
                  ""generatedToken"":{
                     ""token"":""‚ñÅthings"",
                     ""logprob"":-0.0003219324571546167,
                     ""raw_logprob"":-0.47372230887413025
                  },
                  ""topTokens"":""None"",
                  ""textRange"":{
                     ""start"":0,
                     ""end"":7
                  }
               },
               {
                  ""generatedToken"":{
                     ""token"":""‚ñÅ‚Äì"",
                     ""logprob"":-7.797079563140869,
                     ""raw_logprob"":-4.319167613983154
                  },
                  ""topTokens"":""None"",
                  ""textRange"":{
                     ""start"":7,
                     ""end"":9
                  }
               }
            ]
...Text Truncated...

The response is a nested data structure containing information about the processed request, prompt, and completions. At the top level, the response has the following fields:
A unique string
id
for the processed request. Repeated identical requests receive different IDs.
includes the raw text, the tokens with their log probabilities, and the top-K alternative tokens at each position, if requested. It has two nested fields:
(string)
tokens
(list of TokenData)
A list of completions, including raw text, tokens, and log probabilities. The number of completions corresponds to the requested
numResults
. Each completion has two nested fields:
data
, which contains the
text
(string) and tokens (list of TokenData) for the completion.
finishReason
, a nested data structure describing the reason generation was terminated for this completion.
The TokenData object provides detailed information about each token in both the prompt and the completions. It includes the following fields:
generatedToken
field consists of two nested fields:
: The string representation of the token.
: The predicted log probability of the token as a float value..
field is a list of the top K alternative tokens for this position, sorted by probability, according to the
request parameter. If
topKReturn
is set to 0, this field will be null.
Each token in the list includes:
token
: The string representation of the alternative token.
logprob
: The predicted log probability of the alternative token as a float value.
The
field indicates the start and end offsets of the token in the decoded text string:
start
: The starting index of the token in the decoded text string.
end
: The ending index of the token in the decoded text string.
import ai21
ai21.api_key = <YOUR_API_KEY>

response = ai21.Paraphrase.execute(
  text=""You only live once, but if you do it right, once is enough."",
  style=""general"" 
)

print(response.summaries[0].text)
Note: This API will return a list of up to 10 suggested paraphrases with every request. Read more
import ai21
ai21.api_key = <YOUR_API_KEY>

response = ai21.GEC.execute(
  text=""jazzz is a great stile off music"",
)

print(response.corrections[0].suggestion)
print(response.corrections[0].startIndex)
print(response.corrections[0].endIndex)
print(response.corrections[0]['originalText'])
print(response.corrections[0]['correctionType'])
Note: This API can return 7 different types of grammatical error corrections:
Grammar
Missing Word
Punctuation
Spelling
Word Repetition
Wrong Word
. Read more
import ai21
ai21.api_key = <YOUR_API_KEY>

response = ai21.Improvements.execute(
    text=""Affiliated with the profession of project management, I have ameliorated myself with a different set of hard skills as well as soft skills"",
    types=[""fluency"", ""vocabulary/specificity""]
)

print(response.improvements[0].originalText)
print(response.improvements[0].suggestions)
print(response.improvements[0].suggestions[0])
print(response.improvements[0].improvementType)
print(response['improvements'][1].startIndex)
print(response['improvements'][1].endIndex)
Note: This API can return as many as 5 different text improvement
types
:
fluency
vocabulary/specificity
vocabulary/variety
,
clarity/short-sentences
, and
clarity/conciseness
import ai21
ai21.api_key = <YOUR_API_KEY>

response = ai21.Summarize.execute(
  source=""https://en.wikipedia.org/wiki/Koala"",
  sourceType=""URL"" 
)

print(response.summary)
Python
import ai21
ai21.api_key = <YOUR_API_KEY>

response = ai21.Segmentation.execute(
  source=""https://www.ai21.com/blog/summarizing-legal-documents-for-different-personas-using-ai21-studio"",
  sourceType=""URL"" 
)

print(response.segments[0].segmentText)
print(response.segments[0].segmentType)
Note:
sourceType
can be either
""URL""
or
""TEXT""
.  Read more
here
.
Table of Contents
AI21 Studio Python SDK Guide
Set up
API Keys
Building a Prompt
Jurassic-2
Jurassic-2 with Python SDK Code Example
Response
ID
prompt
completions
TokenData
generatedToken:
topTokens
textRange
Task-Specific APIs
Paraphrase API with Python SDK Code Example
Grammatical Error Correction (GEC) API with Python SDK Code Example
Text Improvements API with Python SDK Code Example
Summarize API with Python SDK Code Example
Text Segmentation API with Python SDK Code Example",https://docs.ai21.com/reference/python-sdk
Fine-tuning Jurassic-2 models is now available!,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Fine-tuning Jurassic-2 models is now available!
about 1 month ago
by Jack Yulzari
Custom model training on top of J2-Grande and J2-Large is now available.
As with Jurassic-1 models, custom model training on top of J-2 models* is an easy 2-step process of upload a dataset, and train your own custom model using that dataset.
Log in to the AI21 Studio and try it via the
Models page
For more information, read the
detailed guide
or the
API references
.
*Jurassic-1 legacy models are still available for custom model training, however, they will be discontinued by June 1st, this year.",https://docs.ai21.com/changelog/fine-tuning-jurassic-2-models-is-now-available
AI21 Studio,"Company
About
Ask RBG
Start building
AI21 Studio Blog
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
Announcing Jurassic-2 and Task-Specific APIs
Announcing the launch of Jurassic-2, the latest generation of AI21 Studio‚Äôs foundation models, a game-changer in the field of AI, with top-tier quality and new capabilities. And that's not all - we're also releasing our task-specific APIs, with plug-and-play reading and writing capabilities that outperform competitors.
How Tweet Hunter scaled to an 8-figure exit with AI21‚Äôs LLM
Discover how Tweet hunter built its product and eventually landed an 8-figure exit with AI21 Studio.
How Verb created a game-changing author tool with AI21 Studio
Discover how Verb.ai used AI21 Studio to create a revolutionary writing tool for authors, improving brainstorming and expression. Read the case study now.
Events
Revolutionizing web search: The winning solution of AI21 Labs' Hackathon
Over 1,900 participants took part in the the ever first AI21 Labs Hackathon, with 24 different projects competing for the first prize.
Summarizing legal documents for different personas using AI21 Studio
Create your own custom summarizer using AI21 Studio's large language models. This tutorial demonstrates the process on legal documents.
How Latitude scaled production of their gaming worlds while reducing costs
AI21 Labs managed to build enterprise-level production models which served players at Latitude to elevate the gaming experience while at the same time improving cost.
Case study
How Harambee built conversational flows to achieve a 20% sign-up increase
Learn how Harambee used AI21 Labs' custom models to create an NLP chatbot app to onboard job seekers to one of their career programs.
Build a dashboard based on freeform sentiment analysis of hotel reviews
Analyze large quantities of reviews in minutes using AI21 Studio
Build a CV profile generator using AI21 Studio
In just a few minutes, you can transform an idea into a working and integrated application using AI21 Studio
Best practices for deploying language models
Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models
Introducing J1-Grande!
AI21 Studio releases Grande, a high-quality, affordable language model at the convenient size of 17B parameters.
Jurassic-X: Crossing the neuro-symbolic chasm with the MRKL system
We present the next evolution in natural language processing ‚Äì the Modular Reasoning, Knowledge and Language (MRKL, pronounced ‚Äúmiracle‚Äù) system ‚Äì and Jurassic-X, AI21 Labs‚Äô implementation of it. MRKL systems include one or more language models, and augment them with external knowledge sources as well as symbolic reasoning experts that can handle tasks that lie beyond the reach of neural models.
Introducing Wordtune Read
AI21 Labs newest product joins its writing counterpart to tackle information overload & help everyone read more productively
Zero-to-production: bootstrapping a custom model in AI21 Studio
Learn how to develop a text-based AI application in AI21 Studio and grow it from prototype to production using custom Jurassic-1 models
Tutorial
Discover use cases for AI21 Studio and Jurassic-1
Learn how to use Jurassic-1 to perform summarization, idea generation, classification and many other language tasks
Announcements
Announcing AI21 Studio and Jurassic-1 language models
AI21 Labs‚Äô new developer platform offers instant access to our 178B-parameter language model, to help you build sophisticated text-based AI applications at scale
NLP in the 21st century
Yoav Shoham, AI21 Lab's co-founder, delivers his keynote address at WSDM 2021.
Natural language understanding as the next frontier
Amnon Shashua, AI21 Labs' Chairman & Professor at Hebrew Academy, shares his insights on NLU with the Israel Academy of Sciences and Humanities.
Current state of AI - challenges and opportunities
Yoav Shoham, AI21 Lab's co-founder & professor emeritus of Stanford University, walks us through the the current state of AI landscape.
NEWSLETTER
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
FOLLOW US
Twitter
LinkedIn
Facebook
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog
NLP in the 21st century,"Company
About
Ask RBG
Start building
Yoav Shoham, AI21 Lab's co-founder, delivers his keynote address at WSDM 2021.
ABOUT THE AUTHOR
Professor Yoav Shoham
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
NLP in the 21st century
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/nlp-21st-century
Latest Articles - Blog posts,"Latest Articles - Blog posts
Company
About
Ask RBG
Start building
All Categories
Events
Tutorial
Case study
Publications
Announcements
Blog posts
No items found.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/blog-posts
Extending Context Window: Jurassic-2 Instruct Models Now Support 8K Tokens,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
improved
Extending Context Window: Jurassic-2 Instruct Models Now Support 8K Tokens
22 days ago
by Yotam Shinan
We're thrilled to announce the extension of the 8K tokens support to our Jurassic-2 Instruct models, specifically J2-Grande-Instruct and J2-Jumbo-Instruct. These models, which are designed to meticulously follow instructions, can now accommodate a context window of 8,192 tokens, allowing for even more detailed and extensive interactions.
Impact: With this update, users of our Instruct models can input larger prompts or use more extensive conversation histories. This leads to improved accuracy and relevance in the AI's responses, and makes the models even more adaptable to a wider range of tasks and applications. The extension of the 8K tokens feature to the J2-Grande-Instruct and J2-Jumbo-Instruct models greatly enhances their ability to simplify and facilitate your work.
Usage: Making use of the extended context window is straightforward. All you need to do is provide your prompt or conversation history within the increased token limit. The models will take care of the rest, automatically processing the additional context without the need for any modifications to the API call.
As always, your
feedback
is incredibly valuable to us. Don't hesitate to reach out with any questions, comments, or concerns. Stay tuned for more exciting updates and improvements coming your way!",https://docs.ai21.com/changelog/extending-context-window-jurassic-2-instruct-models-now-support-8k-tokens
Natural language understanding as the next frontier,"Company
About
Ask RBG
Start building
Amnon Shashua, AI21 Labs' Chairman & Professor at Hebrew Academy, shares his insights on NLU with the Israel Academy of Sciences and Humanities.
ABOUT THE AUTHOR
Professor Amnon Shashua
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Natural language understanding as the next frontier
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/natural-language-as-next-frontier
Latest Articles - Announcements,"Latest Articles - Announcements
Company
About
Ask RBG
Start building
All Categories
Events
Tutorial
Case study
Publications
Blog posts
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
Announcing Jurassic-2 and Task-Specific APIs
Announcing the launch of Jurassic-2, the latest generation of AI21 Studio‚Äôs foundation models, a game-changer in the field of AI, with top-tier quality and new capabilities. And that's not all - we're also releasing our task-specific APIs, with plug-and-play reading and writing capabilities that outperform competitors.
Introducing J1-Grande!
AI21 Studio releases Grande, a high-quality, affordable language model at the convenient size of 17B parameters.
Jurassic-X: Crossing the neuro-symbolic chasm with the MRKL system
We present the next evolution in natural language processing ‚Äì the Modular Reasoning, Knowledge and Language (MRKL, pronounced ‚Äúmiracle‚Äù) system ‚Äì and Jurassic-X, AI21 Labs‚Äô implementation of it. MRKL systems include one or more language models, and augment them with external knowledge sources as well as symbolic reasoning experts that can handle tasks that lie beyond the reach of neural models.
Introducing Wordtune Read
AI21 Labs newest product joins its writing counterpart to tackle information overload & help everyone read more productively
Announcements
Announcing AI21 Studio and Jurassic-1 language models
AI21 Labs‚Äô new developer platform offers instant access to our 178B-parameter language model, to help you build sophisticated text-based AI applications at scale
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/announcements
Latest Articles - Publications,"Latest Articles - Publications
Company
About
Ask RBG
Start building
All Categories
Events
Tutorial
Case study
Announcements
Blog posts
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/publications
J-1 Complete API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
J-1 Complete API
You can generate a text completion for a given text prompt by posting an HTTP request to the
endpoint corresponding to the desired
language model
to use. The request contains the input text, called a
and various parameters controlling the generation. For authentication, you must include your API key in the request
headers
. A
complete
response contains the tokenized prompt, the generated text(s), called
completion(s)
, and various metadata.
The response is a nested data structure as described below. At its top level, the response has the following fields:
A unique string id for the processed request. Repeated identical requests get different ids.
The prompt, including the raw text, the tokens with their logprobs and the top-K alternative tokens at each position, if requested.
(string)
).
List of completions, including raw text, tokens and logprobs. The number of completions corresponds to requested
numResults
.
Each completions has two nested fields:
data
, containing
text
(string) and
tokens
(list of
) for the completion.
finishReason
, a nested data structure describing the reason generation was terminated in this completion.
Both the prompt and each of the completions provide lists of
, where each entry describes a token and, if requested, its top-K alternatives. An instance of
contains the following fields:
Has two nested fields:
- the string representation of the token.
- the predicted log probability of the token (float).
A list of the top K alternative tokens for this position, sorted by probability, according to the
request parameter, or null if
topKReturn
=0.
Each token in the list has a
token
(string) field and a
logprob
(float) field.
The start and end offsets of this token in the decoded text string.
Table of Contents
Response
id
prompt
completions
TokenData
generatedToken
topTokens
textRange",https://docs.ai21.com/reference/completion
Increased Context Length for J2 Foundation Models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
improved
Increased Context Length for J2 Foundation Models
about 2 months ago
by Yotam Shinan
We are excited to announce that our Jurassic-2 Foundation models, including J2-Large, J2-Grande, and J2-Jumbo, now support an increased context length of up to 8K tokens (8192 tokens to be exact). This enhancement allows users to work with longer prompts and receive more comprehensive completions.
Impact:
Users can now feed more extensive input prompts or utilize larger conversation histories for their tasks, enabling more contextually relevant and accurate responses from the AI models. This update provides a significant boost in the flexibility and capabilities of our Jurassic-2 Foundation models, making them suitable for even more use cases and applications.
Usage:
To take advantage of the increased context length, simply provide your prompt or conversation history within the allowed token limit. The models will automatically handle the additional context without any further changes required in the API call.
As always, we appreciate your
feedback
and encourage you to reach out with any questions or concerns. Stay tuned for more updates and improvements in the future!",https://docs.ai21.com/changelog/increased-context-length-for-j2-foundation-models
Latest Articles - Case study,"Latest Articles - Case study
Company
About
Ask RBG
Start building
All Categories
Events
Tutorial
Publications
Announcements
Blog posts
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
How Tweet Hunter scaled to an 8-figure exit with AI21‚Äôs LLM
Discover how Tweet hunter built its product and eventually landed an 8-figure exit with AI21 Studio.
How Verb created a game-changing author tool with AI21 Studio
Discover how Verb.ai used AI21 Studio to create a revolutionary writing tool for authors, improving brainstorming and expression. Read the case study now.
How Latitude scaled production of their gaming worlds while reducing costs
AI21 Labs managed to build enterprise-level production models which served players at Latitude to elevate the gaming experience while at the same time improving cost.
Case study
How Harambee built conversational flows to achieve a 20% sign-up increase
Learn how Harambee used AI21 Labs' custom models to create an NLP chatbot app to onboard job seekers to one of their career programs.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/case-study
Current state of AI - challenges and opportunities,"Company
About
Ask RBG
Start building
Yoav Shoham, AI21 Lab's co-founder & professor emeritus of Stanford University, walks us through the the current state of AI landscape.
Watch here
 
ABOUT THE AUTHOR
Professor Yoav Shoham
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Current state of AI - challenges and opportunities
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/current-state-of-ai
Latest Articles - Events,"Latest Articles - Events
Company
About
Ask RBG
Start building
All Categories
Tutorial
Case study
Publications
Announcements
Blog posts
Events
Revolutionizing web search: The winning solution of AI21 Labs' Hackathon
Over 1,900 participants took part in the the ever first AI21 Labs Hackathon, with 24 different projects competing for the first prize.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/events
Latest Articles - Tutorial,"Latest Articles - Tutorial
Company
About
Ask RBG
Start building
All Categories
Events
Case study
Publications
Announcements
Blog posts
Summarizing legal documents for different personas using AI21 Studio
Create your own custom summarizer using AI21 Studio's large language models. This tutorial demonstrates the process on legal documents.
Build a dashboard based on freeform sentiment analysis of hotel reviews
Analyze large quantities of reviews in minutes using AI21 Studio
Build a CV profile generator using AI21 Studio
In just a few minutes, you can transform an idea into a working and integrated application using AI21 Studio
Best practices for deploying language models
Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models
Zero-to-production: bootstrapping a custom model in AI21 Studio
Learn how to develop a text-based AI application in AI21 Studio and grow it from prototype to production using custom Jurassic-1 models
Tutorial
Discover use cases for AI21 Studio and Jurassic-1
Learn how to use Jurassic-1 to perform summarization, idea generation, classification and many other language tasks
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/category/tutorial
Python SDK - with Amazon SageMaker,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Python SDK - with Amazon SageMaker
This guide covers how to use the AI21 Studio Python SDK with SageMaker integration for interaction with Jurassic-2 models.
To get started with AI21's SDK with SageMaker integration, you'll need to install it first. To do so, simply run the following command:
Terminal
$ pip install -U ai21[SM]
To use the AI21 Studio Python SDK with SageMaker, first, create an Amazon SageMaker instance and configure it. Then, install the AI21 Studio Python SDK with SageMaker integration using the command mentioned above. After setting up the environment, you can follow the same steps as described in the AI21 Studio Python SDK Guide for Jurassic-2 models.
Below is a sample usage of the AI21 Python SDK with SageMaker integration to interact with Jurassic-2 models:
Python
import ai21

# J2 Grande
response_grande = ai21.Completion.execute(
  sm_endpoint=""j2-grande"",
  prompt=""These are a few of my favorite"",
  numResults=1,
  maxTokens=2,
  temperature=0.4
)

# J2 Grande Instruct
response_grande_instruct = ai21.Completion.execute(
  sm_endpoint=""j2-grande-instruct"",
  prompt=""explain black holes to 8th graders"",
  numResults=1,
  maxTokens=100,
  temperature=0.7
)

print(response_grande)
print(response_grande_instruct)
By customizing the request parameters, you can control the content and style of the generated text. For a full list of available options, check out our
Complete API
page.
All Jurassic-2 models can be interacted with using the same ai21.Completion.execute() function, including j2-large, j2-grande, j2-jumbo, j2-grande-instruct, and j2-grande-jumbo.
Here's an example of a response object from executing a j2-grande model:
JSON
{
   ""id"":""94078cb6-687e-4262-ef8f-1d7c2b0dbd2b"",
   ""prompt"":{
      ""text"":""These are a few of my favorite"",
      ""tokens"":[
         {
            ""generatedToken"":{
               ""token"":""‚ñÅThese‚ñÅare"",
               ""logprob"":-8.824776649475098,
               ""raw_logprob"":-8.824776649475098
            },
            ""topTokens"":""None"",
            ""textRange"":{
               ""start"":0,
               ""end"":9
            }
         },
         {
            ""generatedToken"":{
               ""token"":""‚ñÅa‚ñÅfew"",
               ""logprob"":-4.798709869384766,
               ""raw_logprob"":-4.798709869384766
            },
            ""topTokens"":""None"",
            ""textRange"":{
               ""start"":9,
               ""end"":15
            }
         },
         {
            ""generatedToken"":{
               ""token"":""‚ñÅof‚ñÅmy‚ñÅfavorite"",
               ""logprob"":-1.0864331722259521,
               ""raw_logprob"":-1.0864331722259521
            },
            ""topTokens"":""None"",
            ""textRange"":{
               ""start"":15,
               ""end"":30
            }
         }
      ]
   },
   ""completions"":[
      {
         ""data"":{
            ""text"":"" things ‚Äì"",
            ""tokens"":[
               {
                  ""generatedToken"":{
                     ""token"":""‚ñÅthings"",
                     ""logprob"":-0.0003219324571546167,
                     ""raw_logprob"":-0.47372230887413025
                  },
                  ""topTokens"":""None"",
                  ""textRange"":{
                     ""start"":0,
                     ""end"":7
                  }
               },
               {
                  ""generatedToken"":{
                     ""token"":""‚ñÅ‚Äì"",
                     ""logprob"":-7.797079563140869,
                     ""raw_logprob"":-4.319167613983154
                  },
                  ""topTokens"":""None"",
                  ""textRange"":{
                     ""start"":7,
                     ""end"":9
                  }
               }
            ]
...Text Truncated...

The response is a nested data structure containing information about the processed request, prompt, and completions. At the top level, the response has the following fields:
A unique string
id
for the processed request. Repeated identical requests receive different IDs.
includes the raw text, the tokens with their log probabilities, and the top-K alternative tokens at each position, if requested. It has two nested fields:
(string)
tokens
(list of TokenData)
A list of completions, including raw text, tokens, and log probabilities. The number of completions corresponds to the requested
numResults
. Each completion has two nested fields:
data
, which contains the
text
(string) and tokens (list of TokenData) for the completion.
finishReason
, a nested data structure describing the reason generation was terminated for this completion.
The TokenData object provides detailed information about each token in both the prompt and the completions. It includes the following fields:
generatedToken
field consists of two nested fields:
: The string representation of the token.
: The predicted log probability of the token as a float value..
field is a list of the top K alternative tokens for this position, sorted by probability, according to the
request parameter. If
topKReturn
is set to 0, this field will be null.
Each token in the list includes:
token
: The string representation of the alternative token.
logprob
: The predicted log probability of the alternative token as a float value.
The
field indicates the start and end offsets of the token in the decoded text string:
start
: The starting index of the token in the decoded text string.
end
: The ending index of the token in the decoded text string.
For a detailed example of using Jurassic-2 Grande on SageMaker through Model Packages, you can refer to this
notebook
on AI21 Labs' SageMaker GitHub repository.
By using the AI21 Studio Python SDK with SageMaker integration, you can seamlessly utilize AI21 Studio Jurassic-2 models in your SageMaker environment, allowing for streamlined development and deployment of your machine learning solutions. Note that the SDK version for SageMaker supports Jurassic-2 models but not the Task Specific APIs. Additionally, there's no need to use an AI21 Studio API key when using the SDK version for SageMaker.
Updated
2 months ago
Table of Contents
AI21 Studio Python SDK with Amazon SageMaker Guide
Set up
Using AI21 Studio Python SDK with SageMaker
Example: Using AI21 Studio Python SDK with SageMaker for Jurassic-2
Response
ID
prompt
completions
TokenData
generatedToken:
topTokens
textRange
Additional Resources",https://docs.ai21.com/docs/python-sdk-with-amazon-sagemaker
Choosing the Right Instance Type,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Usage
Responsible Use
Safety Research
Choosing the Right Instance Type
How to choose the right instance type in Amazon SageMaker
Each of our models can be run in multiple instances. When you have decided on a model, choosing the right instance is mainly a matter of economics. Depending on your use case, you probably want the most cost-effective instance possible.
Note:
Not all instances are available in all regions. Also,
ml.p4de
being in preview, and you need to ask from Amazon SageMaker access.
You can find the recommended instances per model below based on your input size and desired throughput, divided into Foundation models (out Jurassic-2 large language models series) and Task-specific models.
Our large language models support a context window of up to 8191 tokens. In large language models the context window refers to the limited amount of tokens the model considers when generating a response. The context window acts as a threshold for the amount of tokens in the prompt and the completion, namely: prompt + completion <= context window. As an estimate for your use-case: the average token size in our tokenizer is six characters. You can also check any text you want using our
/tokenize
API.
ml.p4de.24xlarge
2048
Recommended instances based on maximum context window:
Instance / Context window
4096
8191
As plug-and-play and easy to use APIs, our task-specific models work with specified inputs and outputs. The input restrictions are therefore based on characters.
Recommended instances based on maximum characters in the context:
Instance / Input characters
10K
25K
50K
ml.g5.12xlarge
ml.g5.48xlarge
‚ùå
ml.p4d.24xlarge
‚úÖ
Currently, the input text is limited to 500 chars. The recommended instance is
.
Currently, the input text is limited to 500 chars. The recommended instances are
ml.g4dn.2xlarge
(cheaper) or
ml.g5.2xlarge
(faster).
Updated
about 14 hours ago
Table of Contents
Foundation models
Jurassic-2 Jumbo Instruct
Jurassic-2 Jumbo
Jurassic-2 Grande Instruct
Jurassic-2 Grande
Jurassic-2 Large
Task-specific models
AI21 Contextual-answers
AI21 Paraphrase
AI21 Grammar Error Correction",https://docs.ai21.com/docs/choosing-the-right-instance-type-for-amazon-sagemaker-models
Query your Custom Model,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Query your Custom Model
üìò
Custom models are private
Only you and members of your organization will be able to send requests to your custom models. Other AI21 Studio users don‚Äôt have access to them.
Once trained, you'll be able to query your custom model in the
playground
by selecting it from the model dropdown. You can also query the model via the API by posting a
complete
request with the model name in the URL corresponding to your custom model:
ü§ì
Complete API - querying trained model
Open Recipe
When querying the trained model with new examples, you should use exactly the same structure you used in the training data. A stop sequence is not needed.
For example, to query a model trained on ad generation, as in
this example
, your prompt text should be:
Python
import requests

prompt = ""Model name: Kuki\nFuel consumption: 30 MPG\nHorsepower: 80 HP\nPrice: $5,000\n##\n""

requests.post(
    ""https://api.ai21.com/studio/v1/MODEL_TYPE/MODEL_NAME/complete"",
    headers={""Authorization"": ""Bearer YOUR_API_KEY""},
    json={
        ""prompt"": prompt,
        ""numResults"": 1,
        ""maxTokens"": 64,
        ""temperature"": 0.7,
        ""topKReturn"": 0
    }
)
Updated
3 months ago
Table of Contents
Querying Trained Custom Models",https://docs.ai21.com/docs/training-custom-models-1
Safety Research,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
AI21 Labs is on a mission to make reading and writing AI-first experiences, with machines working alongside humans as thought partners, thereby promoting human welfare and prosperity. To deliver its promise, this technology must be deployed and used in a responsible and sustainable way, taking into consideration potential risks, including malicious use by bad actors, accidental misuse and broader societal harms. We take these risks extremely seriously and put measures in place to mitigate them.
AI safety is an important challenge with a large surface area, which we believe can be addressed most effectively by
working together
. We invite anyone interested in conducting research or otherwise promoting AI safety to contact us at
[email protected]
and explore opportunities for collaboration. We encourage members of the community to contact us at the same address to report bad experiences, vulnerabilities and suspected misuse of our products or to voice any other safety-related concerns.
Updated
7 months ago",https://docs.ai21.com/docs/safety-research
Contexto m√°s largo in Contextual-Answers API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
improved
Contexto m√°s largo in Contextual-Answers API
13 days ago
by Yuval Belfer
Contextual Answers API [Beta]
now supports an expanded context of 50,000 characters, allowing more text to be included in your source document. In addition, the API provides better support for multilingual capabilities, including Spanish, French, German, Portuguese, Italian and Dutch.",https://docs.ai21.com/changelog/contexto-m%C3%A1s-largo-in-contextual-answers-api
Tips: Training a Custom Model,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Tips: Training a Custom Model
Start with a few-shot prompt.
Don't jump right into training a model. The playground exists for a reason, so try out different prompt structures to see what works best for you. Found it? Use this exact structure to train your model.
Test the different models on the playground before choosing what to train on.
Model training is not a one-time affair, but an iterative process.
In cases of complex tasks, we recommend training several versions on smaller parts of your dataset to root out any problems in the data (that cannot be identified by few-shots alone), as well as setting the correct hyperparameters.
We selected the default hyperparameters after testing several benchmarks and choosing those that gave optimal results across the board. Nevertheless, if your trained model doesn't work as expected, you may want to train another version with different hyperparameters.
Sometimes custom models work better when fed a few-shot prompt. Be sure to perform some calls with few-shot prompts when testing your trained model.
There is no guarantee that more epochs will provide a better result. From our experience, this is especially true when you want your model to generate expressive and diverse content. A relatively short training will help retain J-1‚Äôs original abilities. Longer training will provide a model that behaves more like the data in your dataset (for good or bad).
The model reflects the data
, so if the data has biases, the model will learn the bias. For example, if most of your data begins with the words ‚ÄúI think that‚Äù, then the model will learn to give high probability for these words. This can help in debugging the model, so look at the probabilities (using alternative tokens) to understand the biases in the data.
For classification tasks, try to balance the data, meaning an equal number of examples for each class.
Updated
4 months ago",https://docs.ai21.com/docs/tips-tricks
Transitioning to Jurassic-2: Important Updates on Model Retirements and Pricing Changes,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
Transitioning to Jurassic-2: Important Updates on Model Retirements and Pricing Changes
22 days ago
by Yotam Shinan
We have a few updates to share regarding our Jurassic models at AI21 Studio:
Jurassic-1 Models Retirement
: As of June 1st, 2023, all Jurassic-1 models will be retired. We encourage users to transition to our more powerful Jurassic-2 models and train new custom models based on Jurassic-2 as soon as possible.
Jurassic-2 Models Pricing
: Starting from May 1st, 2023, the usage of Jurassic-2 models will no longer be free. You can find detailed information about pricing at
this link
.
Free Custom Model Training
: Although the usage of Jurassic-2 models is now at cost, the training of custom models on Jurassic-2 will remain free until June 1st, 2023.
To ensure a smooth transition, please update your code and switch to Jurassic-2 models, including updating the URL in your API requests. For example, replace:
api.ai21.com/studio/v1/j1-grande/complete
with:
api.ai21.com/studio/v1/j2-grande/complete
For new custom models, consider adopting the same name as the previous version with a
""-j2""
suffix to track your upgrades.
As always, feel free to reach out with any questions or concerns on our
Discord server
or through our usual channels.
Thank you for being a part of our community, and we look forward to witnessing your innovative work with Jurassic-2!",https://docs.ai21.com/changelog/transitioning-to-jurassic-2-important-updates-on-model-retirements-and-pricing-changes
Responsible Use,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Safety Research
Responsible Use
AI21 Studio provides open access to state-of-the-art language models that can be used to power a large variety of useful applications. We believe it is important to ensure that this technology is used in a responsible way, while allowing developers the freedom they need to experiment rapidly and deploy solutions at scale.
In order to use AI21 Studio, you are required to comply with our
Terms of Use
and with the following
usage guidelines
. Provided you comply with these requirements, you may use AI21 Studio to power applications with live users without any additional approval. We reserve the right to limit or suspend your access to AI21 Studio at any time where we believe these terms or guidelines are violated.
Please check these usage guidelines periodically, as they may be updated from time to time. For any questions, clarifications or concerns, please contact
[email protected]
AI21 Studio must not be used for any of the following activities:
Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights;
Harassment, victimization, intimidation, fraud or spam;
Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.
Your application may present content generated by AI21 Studio directly to humans (e.g., chatbots, content generation tools, etc).
In this case
, you are required to ensure the following:
No content generated by AI21 Studio will be posted
automatically
(without human intervention) to any public website or platform where it may be viewed by an audience greater than
100 people
.
This means that you can use AI21 Studio to build a bot for your team‚Äôs 7-person Slack channel. In contrast, you are not allowed to build a Twitter bot, unless each tweet is checked by a human before it is posted. You can build a customer service bot that interacts with any number of customers, assuming it's chatting with each human separately in a 1:1 conversation.
In any case, the first human to view text generated by AI21 Studio must not be led to believe that it was written by a human.
If you‚Äôre building a copywriting tool for marketing professionals, your users must be informed that the text proposed to them is machine generated. They are then free to use and present it as their own, at their discretion. As another example, if you‚Äôre building a chatbot, it must be clear to your users that they are corresponding with a machine rather than a live human.
Language models such as those accessible via AI21 Studio may generate inappropriate, biased, offensive or otherwise harmful content (see our
technical paper
for an evaluation of bias in our models). If your application is used by more than
100 people per month
, you must provide a method for users to
report generated text as harmful
. You should monitor these reports and respond to them appropriately.
üìò
Example
You can build a demo, launch a closed beta, etc. without any special requirements, as long as it is accessed by fewer than 100 users per month. Once you exceed 100 monthly users, you must implement a ‚Äúflag as inappropriate‚Äù button or some similar functionality to collect negative feedback.
Except when using
custom models
, the prompt text for any completion request must contain at least
60 characters
of text (about 10 words)
not written by your users
. This text should be crafted by you to produce the desired functionality for the user.
Language models such as those accessible via AI21 Studio can generate content that is biased against particular groups of people. You may not use AI21 Studio to power
automated decision making
where individuals may be denied benefits, refused access to a service or otherwise have their wellbeing substantially harmed based on protected characteristics.
AI21 Studio must not be used to classify or profile people based on protected characteristics (like racial or ethnic background, religion, political views, or private health data).
Updated
6 months ago
Table of Contents
Usage Guidelines",https://docs.ai21.com/docs/responsible-use
Train a Custom Model,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Train a Custom Model
To train a new model, simply follow these steps:
Collect your training data. For optimal results, make sure to follow the
guidelines
.
Head over to the Models tab and click ""New"".
Choose from an existing dataset, drag & drop, or browse to upload a new valid
.jsonl
or
.csv
file.
Follow the steps on screen to pick the model's name, its size (Jumbo, Grande or Large), specify training hyper-parameters (or use the defaults), and then click ""Train Model"".
Your new model will now begin training. You'll see that it's added to the table under the Models tab with its status indicating ""Training"". Once the model is trained, it is immediately deployed and available for you to use.
Updated
3 months ago
Table of Contents
üöÇ How to train your own custom model",https://docs.ai21.com/docs/training-custom-models
Announcing Jurassic-2 and Task-Specific APIs,"Company
About
Ask RBG
Start building
Announcing the launch of Jurassic-2, the latest generation of AI21 Studio‚Äôs foundation models, a game-changer in the field of AI, with top-tier quality and new capabilities. And that's not all - we're also releasing our task-specific APIs, with plug-and-play reading and writing capabilities that outperform competitors.
Our focus at AI21 Studio is to help developers and businesses leverage reading and writing AI to build real-world products with tangible value. Today marks two important milestones with the release of Jurassic-2 and Task-Specific APIs, empowering you to bring generative AI to production.
(or J2, as we like to call it) is the next generation of our foundation models with significant improvements in quality and new capabilities including zero-shot instruction-following, reduced latency, and multi-language support.
Task-specific APIs
provide developers with industry-leading APIs that perform specialized reading and writing tasks out-of-the box.
Read on for an in-depth look at each.
Jurassic-2
We‚Äôre proud to present our brand new family of state-of-the-art Large Language Models. J2 not only improves upon Jurassic-1 (our previous generation models) in every aspect, but it also offers new features and capabilities that put it in a league of its own.
The Jurassic-2 family includes base language models in three different sizes: Large, Grande and Jumbo, alongside instruction-tuned language models for Jumbo and Grande.
Jurassic is already making waves on
Stanford‚Äôs Holistic Evaluation of Language Models
(HELM), the leading benchmark for language models. Currently, J2 Jumbo ranks second (and climbing) according to an evaluation we conducted using HELM‚Äôs official repository. No less important, our mid-sized model (Grande) ranks significantly higher than models up to 30x larger in size, enabling users to optimize production costs and speed without needing to sacrifice quality.
What's new compared to Jurassic-1?
Improved quality
With cutting-edge pre-training methods combined with the latest data (current up to mid-2022), J2‚Äôs Jumbo model has scored an 86.8% win-rate on HELM by our internal evaluations, solidifying it as a top-tier option in the LLM space.
Instruct capabilities
J2‚Äôs best-in-class models offer zero-shot instruction capabilities, allowing them to be steered with natural language without the use of examples. J2‚Äôs Jumbo and Grande models have been adapted to include these capabilities. Here's an example:
Multilingual support
J2 supports several non-English languages, including Spanish, French, German, Portuguese, Italian and Dutch.
Performance
In terms of latency, J2‚Äôs models can perform up to 30% faster than our previous models.
Take it for a spin
Jurassic-2 will be
available for free
until May 1st, 2023. In addition, Jurassic-2 and Jurassic-1 models are now offered under our new reduced and simplified
pricing model,
based on the total length of text (input + output).
All Jurassic-2 models are now available for you on our playground and API. To help you get started, we‚Äôve collected some tips and tricks for working with the new Instruct models
here
.
Today, AI21 Labs is also proud to announce our new line of
Task-Specific APIs
, with the launch of the
Wordtune API set,
giving developers access to the language models behind our massively popular consumer-facing reading and writing apps.
Why do we need Task-Specific APIs?
General Large Language Models are incredibly powerful, and many of our customers have successfully customized them to power their applications. However, we‚Äôve also seen that certain use-cases recur frequently among many users.
By providing developers with task-specific APIs, they can leap over much of the needed model training and fine-tuning stages, allowing them to take full advantage of our ready-made best-in-class language processing solutions.
 
and
both use cutting-edge AI to assist users with writing and reading tasks ‚Äì all while saving time and improving performance.
With the release of
Wordtune API
, we‚Äôre giving developers access to the AI engine behind this award-winning line of applications, allowing them to take full advantage of Wordtune‚Äôs capabilities and integrate them into their own apps:
Paraphrase
Reword texts to fit any tone, length, or meaning.
Summarize
-
Condense lengthy texts into easy-to-read bite-sized summaries.
Grammatical Error Correction (GEC)
- Catch and fix grammatical errors and typos on the fly.
Text Improvements
- Get recommendations to increase text fluency, enhance vocabulary, and improve clarity.
Text Segmentation
- Break down long pieces of text into paragraphs segmented by distinct topic.
Outperforming the Competition
When it comes to paraphrasing and summarizing capabilities, Wordtune API is truly a best-in-class performer.
Summarize API
Faithfulness rates measure how factually consistent a summary is with the original text. As you can see below, our new Summarize API has reached a faithfulness rate that outperforms OpenAI‚Äôs Davinci-003 by 19%.
Acceptance rates measure how satisfied human evaluators are with the quality of generated summaries, and we‚Äôre proud to say that our Summarize API has achieved an acceptance rate that is 18% higher than that of OpenAI‚Äôs.
Paraphrase API
Our Paraphrase API‚Äôs latency is approximately
a 1/3 of OpenAI‚Äôs.
Our Paraphrase API outperforms OpenAI both in terms of diversity of results
(33%)
as well as meaning preservation
(8%).
QQP benchmark:
STS-B benchmark:
The new releases of the Jurassic models and Task-Specific APIs both demonstrate our commitment to providing cutting-edge technology that enables our customers to build better language processing applications with ease, and deploy them into production in minutes.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Announcing Jurassic-2 and Task-Specific APIs
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/introducing-j2
Jurassic-X: Crossing the neuro-symbolic chasm with the MRKL system,"Company
About
Ask RBG
Start building
We present the next evolution in natural language processing ‚Äì the Modular Reasoning, Knowledge and Language (MRKL, pronounced ‚Äúmiracle‚Äù) system ‚Äì and Jurassic-X, AI21 Labs‚Äô implementation of it. MRKL systems include one or more language models, and augment them with external knowledge sources as well as symbolic reasoning experts that can handle tasks that lie beyond the reach of neural models.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Jurassic-X: Crossing the neuro-symbolic chasm with the MRKL system
We present the next evolution in natural language processing ‚Äì
the Modular Reasoning, Knowledge and Language (MRKL
, pronounced
‚Äúmiracle‚Äù
) system ‚Äì and
, AI21 Labs‚Äô implementation of it. MRKL systems include one or more language models, and augment them with external knowledge sources as well as symbolic reasoning experts that can handle tasks that lie beyond the reach of neural models.
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system
Harambee,"Harambee
Docs
Pricing
Case Study
How NLP-powered chatbots can help you scale up
10X
increase in conversion
rate to sign-up
1000+
new daily sign-ups
The story
Harambee is the official platform for governmental bodies in South Africa for assisting the youth in their job hunt. They faced sharp increase in demand, thus needed to find a solution to automate the onboarding process of their candidates and to extract as much valuable information from the conversation.
From our previous work with other chatbots [before finding AI21], we had seen how the signup process was a vital component for ensuring high levels of engagement and most chatbots failed to do that with an audience like ours. I saw that AI21 Studio had an easy-to-use fine-tuning feature that did not require any previous coding experience, I was excited to see how quickly I could prototype different conversational flows and build something that felt human and relatable.
Brent Davidoff |
Product director, Harambee
The goal
Automate the onboarding process and extract key insights from it
The solution
Using AI21 Studio's summarization and text generation API
Harambee wanted to built a conversational onboarding process that would collect valuable information from the user while creating an authentic connection.
Traditional chatbot technology did not meet the mark so Harambee set out to implement their own, on top of AI21 Studio as the text generation engine powering the conversation.
The impact was immediate already after few sessions. Harambee's number of applicants grew by 10X and the conversion to sign-ups improved by 20% compared to their prior approaches.
Contact us",https://www.ai21.com/studio/harambee
Tips: Building a Dataset,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Tips: Building a Dataset
Make sure you keep to the same format of prompt, both in the dataset and while querying the trained model. For example, you should keep the same instruction for each input and make sure the number of spaces is identical.
Finish each prompt with a newline, or start every completion with a whitespace. Make sure you do the same for the entire dataset.
Make sure the examples in your dataset reflect the type of tasks the model will face. Examples:
If you are generating copy for a wide variety of industries, you should have examples from all these industries in your dataset.
If you‚Äôre building a model that generates movie taglines and only train it on comedies, it won‚Äôt do a great job in generating horror movie taglines.
You should clearly define what you expect from the output and then create examples that show these expectations. If you expect information from the input to appear in the output, provide only examples that follow that logical path. Every completion in your dataset should be something you will be happy to get from the model.
Your model is as good as your data. Make sure you are providing your best examples.
Although 50 is the minimum, try to provide more examples, if possible. If you end up with 50 examples, make sure you provide a large variety to avoid overfitting the model to certain types of examples.
Make sure your dataset is clean and has no wrong, empty or duplicated examples.
Remove duplicates to prevent data leakage - otherwise, you can end up with an example that appears both in train and test, and the test loss will not reflect the ‚Äútrue‚Äù loss.
Just like with few-shot prompts, having a clear instruction may help, even the phrasing of your prompt matters, and it‚Äôs not an exact science. Try different variations and see what works best.
As opposed to few-shot prompts, here, you don‚Äôt need to end your generations with a distinctive token (e.g ##). The model learns when to finish the generation and it will simply provide a completion and nothing else.
Updated
4 months ago",https://docs.ai21.com/docs/tips-building-a-dataset
Pricing,"Product
Log In
Start Building
Start with a free trial, no credit card required, then pay based on usage.
See usage pricing for
Foundation, Instruct, Custom Models
and
Task-Specific APIs.
Starter Plan
Access all features through usage-based pricing,
with a minimum subscription fee of $29 per month.
Access all features through usage-based pricing, with a minimum subscription fee of $29 per month.
Usage-based pricing
Foundation model APIs & SDK
Custom model training
Unlimited seats
Free Trial
$90 credits for 3 months
No credit card needed
Start Now For FREE
Custom Plan
For developers who are looking to scale, require custom implementation or dedicated support.
Everything in the Starter Plan
Volume discounts
Premium API rate limits
Private cloud hosting
Priority support
Dedicated account manager
Expert AI consultancy
Contact Sales
Foundation Models
Base, Instruct and Custom models
Jurassic foundation models
are trained on a massive corpus of text, making them a powerful basis for a wide range of natural language processing applications, capable of understanding & composing human-like text.
Ranked best-in-class by Stanford
University's HELM index.
Train custom models with exceptional flexibility.
Use your fine-tuned models at no extra cost.
Jumbo
Highest quality
$0.015 / 1k tokens
$3
Grande
(Base & Instruct)
Quality & speed
$0.01 / 1k tokens
$0.5
Large
(Base)
Fastest
$0.003 / 1k tokens
Fine-Tuning
Train a custom model
$0.1
/MB /epoch
What is a Token?
Tokens are used in language models to break down text into small pieces. With AI21 Studio's models, an average token corresponds to 1 word or 6 characters of English text. Comparatively, this is up to 30% more text per token than other providers,
saving you 30% of the cost.
Task-Specific APIs
Specialized APIs tailored for reading and writing
Documentation
Task-specific APIs
offer out-of-the-box reading and writing capabilities, enabling developers to build AI-powered apps without any NLP expertise or additional model training. Powered by highly optimized models, the APIs deliver industry-leading results and strong, reliable performance at low latency.
Outperforms main market solutions in quality and latency.
No prompt-engineering or fine-tuning needed.
Plug-and-play NLP, accessible to any developer.
Wordtune API
Paraphrase
Takes a piece of text and returns a list of paraphrases that convey the same meaning using different words.
Summarize
Takes a document (raw text or URL) and returns a summary of the text.
Grammatical Error Corrections
Detects grammar, spelling, punctuation, and word choice errors in text, and suggests how to correct them.
Text Improvements
Provides rewrite recommendations for improving the fluency, clarity and style of the input text.
$0.0005 / API request
Text Segmentation
Takes a document (raw text or URL) and returns segmentation into paragraphs by topic.
$0.001 / API request
Question Answering API
Contextual Answers API
BETA
Receives a document and a question and returns an answer based entirely on the document context.
$0.005 / API request
Frequently Asked Questions
Can I still use Jurassic-1 models?
Jurassic-1 models remain available until June 1st, 2023, after which they will be deprecated in favor of Jurassic-2.
What is the difference between training and usage rates for fine-tuned models?
Custom models cost the same to use as pre-trained foundation models. However, training a custom model requires a one-time fee. The cost is dependent on the selected model, and is calculated by the size of the dataset, measured in megabytes, multiplied by training duration, measured in epochs (each epoch is one complete run of the entire training dataset).
What is an epoch, and how many epochs are required to train a custom model?
When training a custom model, an epoch is defined as one pass of the entire training dataset. Typically, models are trained for 5-20 epochs, though finding the optimum number of epochs may require experimentation.
How can I track my usage and spending?
To track usage, log in and navigate to 'Account,' then click 'Model Usage'. This page shows a detailed view of your organization's usage for the current billing period. To see your future expected payment and previously paid invoices, navigate to 'Account', and then click 'Billing & Plans'.
When does the billing cycle begin?
Usage is billed monthly, starting on the date you upgraded to a paid plan. Each month, the billing cycle is the same. On the day you upgrade, your usage for the month will be billed, and then the next month's billing cycle will start on the same date. This will continue on a monthly basis until you switch plans or cancel your subscription.
Who is eligible for the volume discount?
Volume discounts are available to customers with high monthly usage, regardless of whether they are developers, startups, enterprises, or research teams. This type of discount offers a reduced rate for increased usage, when subscribing to a custom plan. Our sales team will be happy to tailor an offer to meet your requirements and volume of business.
API
Pricing
Docs
Terms of use
Privacy Policy
Log in
Featured
Jurassic-1
Jurassic-X
AI Co-Writing
Publications
Blog
Press",https://www.ai21.com/studio/pricing
Contact | Studio,"Contact | Studio
Pricing
Start building
Docs
Differentiate your product with
generative text AI
Specialized endpoints
Flexible APIs
Production grade reliability
Customizable language models
Clear docs for seamless integration
Expert generative AI consultancy
Trusted by developers at leading companies
Contact our sales team
Fill out your details to request a personalized demo from our team of product experts
First name*
Last name*
Work email*
Phone number
Company name *
Job title *
How can our team help you?
I acknowledge and accept the terms
of the
privacy policy
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Privacy policy
Terms of use
Contact us
help@wordtune.com",https://www.ai21.com/meeting/contact
How Latitude scaled production of their gaming worlds while reducing costs,"Company
About
Ask RBG
Start building
AI21 Labs managed to build enterprise-level production models which served players at Latitude to elevate the gaming experience while at the same time improving cost.
Latitude
is a pioneer in the AI gaming space, offering powerful AI-generated digital gamescapes for its players.
Latitude is most famously known for AI Dungeon, a text-based adventure game that uses artificial intelligence to generate unique and unpredictable stories, depending on the choices that a player makes. In the past, computer adventure games were limited in terms of the amount of actions and scenarios they offered. By using Large Language Models, AI Dungeon grants players the flexibility to perform virtually any action and have the game respond to that action.
Example from AI Dungeon
Latitude got good traction with its early implementation of AI Dungeon on top of GPT-3, but when planning their future roadmap, they quickly realized that they needed an LLM partner who shared their vision of immersive AI-driven experiences. They found an eager partner in AI21 Labs, who worked collaboratively with Latitude to discover roadblocks and brainstorm solutions. This resulted in improvements to issues such as latency, flexibility, and user satisfaction, to name just a few.
So, how did they do it?
AI21 Labs managed to build enterprise-level production models which served players at Latitude to elevate the gaming experience while at the same time improving cost efficiency. Latitude found AI21 Labs to be a collaborative LLM partner, which wasn‚Äôt just a plug-and-play solution to a scaling problem, but rather a trusted partner with whom they could collaborate on AI solutions.
But what were the exact problems preventing Latitude from realizing its vision? And how did AI21 Labs overcome them? Read on for the full story.
Who is Latitude?
Latitude was never envisioned as a gaming company - it actually started as a Hackathon project that translated into a Dungeons and Dragons plugin. The team decided to go to market with the plugin, and within the first week, they had roughly 100,000 customers which quickly grew to a million in just the first month.
The verdict was in: there was a creative use case for large language models for game-like experiences and writing.
Searching for a collaborative solution
Latitude wanted to offer a stronger game experience, with richer text and better AI responses. For this, they partnered with the legacy GPT-3 enterprise, OpenAI.
But with rapidly evolving technology came growing pains, and OpenAI was not aligned with Latitude's vision - thus, the visionary gaming experience became impossible. It became clear to Latitude that they needed to seek out a new tech partner who was interested in solving the use case of creating an AI-Driven adventure role play game..
Switching from OpenAI to AI21 Labs
Latitude booked a call with AI21 Labs when they‚Äôd just launched their Jurassic-1 Model. A Jurassic prototype was set up for Latitude, and they started experimenting with the features and the accuracy of results. The final model was perfect for Latitude‚Äôs AI Dungeon use case. Soon after that, the team declared it an alpha model for their audience.
In order to get to that stage, the teams had to overcome two massive roadblocks.
The first roadblock: creative restrictions
OpenAI‚Äôs policy of non-violence restricted integral elements of Latitude‚Äôs AI Dungeon adventures ‚Äî quests, swords, and fights. It was impossible to have a role playing expedition without weapons.
‚ÄúWe were interested in a partner who understands the nuances of the creative use case.‚Äù
says Ryan Seamons, VP of Product at Latitude.
Ryan Seamons - VP Product @ Latitude
Latitude prioritized finding a partner who was not only aligned philosophically but willing to become a true partner and collaborator in building a quality AI-driven role-play experience.
‚ÄúWe need to offer AI-assisted role-play at scale to thousands of daily players. We need models that are fast, reliable, and creative.‚Äù
The collaborative opportunity: agility
AI21 Labs‚Äô team of developers, creators, and stakeholders were analytical problem-solvers who created reliable production models for Latitude.
A precise production model is critical for a gaming company like Latitude. It defines the customer experience and determines whether users will come back. So, it needs to be hyper-accurate and reliable. To achieve this, there has to be excellent communication during prototyping.
Latitude and AI21 Labs had a system for rapid back-and-forth between teams and numerous collaborative checkpoints. As a result, they got to the production stage quickly.
Even after launching the model, the AI21 Labs team worked tirelessly to ship updates, create new features, and build on feedback.
‚ÄúWe‚Äôve experimented with other tools, but they have been demanding and daunting with direct orders and no problem-solving. But not AI21 (Labs). They‚Äôre enthusiastic, collaborative, and innovative ‚Äî a true gaming visionary.‚Äù
The second problem: exponential costs
Latitude offers AI-assisted role-play at scale to thousands of daily players.
Not only did Latitude want to offer existing models to new players, they also wanted to create more immersive and realistic worlds.
They wanted an LLM partner who offered customizable pricing because gaming models are extremely expensive to run at scale.
‚ÄúAI costs are one of our most significant ongoing expenses, and so finding ways to reduce our AI costs help us to operate sustainably as a business.‚Äù
The collaborative opportunity: cost-effectiveness through optimization
AI21 Labs put in hours of skilled talent to make the large language model efficient enough to be cost-effective. They helped Latitude transition from Jurassic-1 Jumbo to Jurassic-1 Grande to scale performance at the right cost.
Jurassic-1 Jumbo, AI21‚Äôs biggest model, processes 178 billion parameters to generate an output. But after running multiple experiments, their team concluded that Latitude‚Äôs game did not need this many parameters. They switched from Jumbo to Grande (which uses 17B parameters), and the result was the perfect sweet spot for a compelling experience at a sustainable price with faster response time. The cost savings are great, but the faster response times are also something players can benefit from. The lower costs also let Latitude experiment with additional ways to improve output quality, such as Hydra mode which generates multiple responses and selects the best one for a player.
Being able to experiment with new data sets more quickly and affordably also yielded positive results and will be a major part of Latitude‚Äôs AI strategy this year.
‚Äú
The biggest benefit of working with AI21 (Labs) is for agile companies who want more hands-on attention in service.
What I‚Äôve been most impressed with is the proactiveness in optimizing costs for multiple use cases. It‚Äôs been a breath of fresh air compared to competitors.‚Äù
says Seamons.
The final results
Latitude discovered that the Grande model struck the right balance of cost vs. performance, all while generating higher quality results than small models such as GPT-J or GPT-3 Curie.
By using an ensemble model approach called Hydra, Latitude was able to achieve quality similar to that of larger models.
At every stage, the team at AI21 Labs devised innovative solutions to roadblocks and proactively and continuously improved cost efficiency.
Whether through large-scale prototyping or improving production after release, Latitude found AI21 Labs to be a creative, efficient, and reliable partner on every level.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
How Latitude scaled production of their gaming worlds while reducing costs
Two years ago, Latitude wanted to scale its imaginative AI use cases and the number of players. Latitude found a collaborative LLM partner in AI21 Labs. AI21 Labs wasn‚Äôt only a plug-and-play solution to a scaling problem, they became a specialized partner who proactively detected gaming roadblocks and brainstormed solution prototypes. AI21 managed to build enterprise-level production models for individual players at Latitude to elevate the gaming experience while at the same time improving cost efficiency for Latitude.
 
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/latitude-case-study
Help Your Users Write Better Using Generative AI,"Start Building
Help Your Users Write Better Using Generative AI
Leverage LLMs and offer the latest and greatest in AI writing assistance.
Get Started
Let‚Äôs talk
Powering writing experiences for leading companies
Our capabilities
Everything you need to provide a 360¬∫ co-writing solution
Short-form text generation
Create concise and engaging text for ads, website copy and more.
Long-form text generation
Generate blog posts, articles, ebooks and long texts.
Grammar correction and writing improvement
Ensure that your users‚Äô written work
is accurate, clear, and professional.
Summarization
Highlight the main points of any piece of text.
Paraphrasing
Convey the same meaning of a sentence or paragraph in different words.
Customization
Train the model to write in your tone and voice.
Web builders & editors
Website builders and content editors
Text generation.
The hardest part of writing is getting started.
Let the AI handle the first draft for your users.
Guided paraphrasing.
Increase your users‚Äô productivity by automating time-consuming tasks such as iterating on ad copy or repurposing content for a new target audience.
Grounded generation.
Generate content that is rooted in verifiable knowledge and give your users peace of mind by providing proper citations.
Knowledge platforms
Smart auto-drafting.
Your users will love writing at the speed of thought using  generative AI and contextual completions for sentences and paragraphs.
Fine-tuned summarization.
Every long document needs a TL;DR. Help your users enhance reports with executive summaries, simplify onboarding material with recaps, and more - all automatically generated with AI.
AI proofreading and editing.
Help organizations level-up their knowledge base with a full suite of spelling, grammar and style improvements.
Communication platforms
AI-generated messages.
Help users save time by generating context-relevant responses based on a short prompt.
Multi-purpose summarization.
Reduce information overload by summarizing messages, threads, and links.
Grammar corrections and recommendations.
Bring global teams closer together with an AI safety net that helps English Second Language (ESL) speakers express themselves easily.
Join the AI era
Many leading platforms have already adopted AI co-writing in their text editors. These include Google, Microsoft, Canva and Notion.
The market size for these tools was valued at $410.92 million in 2021 and is expected to grow to $1.3B by 2030.
Benefits for users
Increase user engagement
Users who find value in your product tend to utilize it with increased frequency.
Increase user productivity
Whatever your users are writing, co-writing features will help them write it better.
Draw users to your platform
Today's users know about the power of generative AI and expect the latest technology readily available in their writing tools.
Benefits of our models
5M+ users
We know co-writing
Having developed Wordtune, we have unparalleled knowledge and expertise in AI writing.
99.99% uptime
Reliable responses
Utilizing our industry-leading LLMs will ensure your users will get useful and reliable suggestions every time.
3,000+  custom models
Fine tuning
Create content based on your
own models.
All programming languages
Easy integration
Developers are just one line of code away from leveraging our powerful and flexible API.
Level up your writing app
AI21 Labs offers the best production-grade LLM solution for co-writing apps and editors. Learn how you can save money and valuable development time, while helping your users write better and faster with AI.
Contact us
API
Pricing
Docs
Terms of use
Privacy Policy
Log in
Featured
Jurassic-2
Jurassic-X
AI Co-Writing
Publications
Blog
Press
Stay updated
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.",https://www.ai21.com/ai-co-writing
Task-specific APIs,"Task-specific APIs
Product
Foundation Models
Log In
Start Building
Task-Specific APIs
Best-in-class NLP made accessible
Build exceptional AI-powered reading and writing experiences with plug-and-play APIs, no NLP expertise needed.
Leverage task-specific APIs across use cases and industries
Text editors
Enhance your text editor tools with a wide range of AI capabilities that level up your users‚Äô writing skills.
Retail software
Automate the writing of product descriptions based on specified requirements, including text length, tone and diversity.
Knowledge and
support platforms
Deliver instantaneous answers to users asking questions based on knowledge hosted in your help center or internal repository.
Content management systems
Generate summaries of long documents or articles at scale, allowing your users to consume more content in less time.
Ready to level up your app with generative text AI?
Let‚Äôs Talk
Wordtune API
Access the AI engine behind
Wordtune
, our award-winning app that elevates the reading and writing skills of its millions of users.
Paraphrase API
Implement paraphrasing functionality within your app, including rewriting text based on tone and length.
Text Improvements API
Help your users better articulate their thoughts in writing with improvement recommendations.
Summarize API
Embed text summarization features into your solution, giving users the ability to extract key insights from long documents.
Grammatical Error Corrections API
Supercharge your app with the ability to correct spelling, grammar, punctuation, misused words and more.
Text Segmentation API
Slice large amounts of text into distinct topics. Used in conjunction with Summarize API, allow your users to summarize long texts slice-by-slice.
Question Answering API
Generate questions and answers based entirely on information contained in a given text, document or URL.
Contextual Answers API
Provide answers to your users‚Äô questions that are accurate, relevant, and fully grounded in the context of your source materials.
Try Now
Why AI21 Studio?
Exceptional performance
Superior quality, reliability and speed versus other providers, thanks to highly efficient models.
Effortless integration
Get up and running with one API call. No fine-tuning or prompt-engineering needed.
Simple usage pricing
Easily calculate expected spend with pay-per-request pricing.
Trusted by developers in leading companies
Inactive-State
Active State
Production-ready APIs
Get up and running with one API call. Integrate AI into your app for reading and writing tasks, no NLP experience required.
Get Started
Contact us
Integrate with your favorite stack in 3 lines of code
Start Building - It‚Äôs Free
API
Log in
Docs
Pricing
Terms of use
Privacy Policy
Featured
Case studies
Jurassic-2
Jurassic-X
Co-writing
Publications
Blog
Press
Stay updated
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.",https://www.ai21.com/studio/task-specific-apis
Foundation Models - Best-In-Class LLMs - AI21 Labs,"Foundation Models - Best-In-Class LLMs - AI21 Labs
Product
Task-Specific APIs
Log In
Start Building
Foundation Models
Take on any language task
Access Jurassic-2, our best-in-class large language models that give you maximum flexibility to provide AI-first reading and writing experiences.
Trusted by developers in leading companies
Inactive-State
Active State
Power any application with NLP that‚Äôs as flexible as you need.
Base models
Jumbo. Grande. Large.
Three language models of various sizes and speeds, suitable for any type of task at hand.
Instruction models
Instruction-tuned models that can follow natural language instructions without needing any examples.
Custom models
Optimize models to fit your specific needs with effective, easy-to-use tools that train custom models. Save when you scale, with no additional charge for custom model usage.
Privacy and security
Deploy a dedicated model for your organization‚Äôs instance. ISO27001 certified.
Ready to level up your app with generative text AI?
Let's Talk
Let‚Äôs Talk
Why AI21 Studio?
Top-ranked quality
Jurassic-2 models are among the highest in the industry ranked for accuracy and reliability, according to Stanford‚Äôs HELM.
Tailored to your app
Generative text AI that fits your product like a glove. Build and deploy customized models, access your unique instance, and more.
Cost-effective
30% more efficient than other providers, plus no additional charge for using fine-tuned models.
Hear it from our customers
◊¥We were looking for language models that are fast and reliable while staying cost-effective.
AI21 Studio offers all of that in addition to being agile which is a must in our fast-paced marketplace!
◊¥
Ryan Seamons
| VP Product
‚ÄúWe needed to build tools that are specific to the problems of our users.
It couldn‚Äôt be just about generating text. We found working with AI21 to be a breath of fresh air.‚Äù
Ryan Bowman |
Co-Founder
‚ÄúWe chose AI21 Studio because of its pricing and flexibility with fine tuning the models.
We were able to maintain high standards on the quality of content, enabling our users to succeed and for us to grow.‚Äù
Thibault Louis-Lucas |
Founder
Start building
Get up and running with generative AI that offers unmatched quality, flexibility, speed, and cost.
Get Started
Contact us
Integrate with your favorite stack in 3 lines of code
Start Building - It‚Äôs Free
API
Log in
Docs
Pricing
Terms of use
Privacy Policy
Featured
Case studies
Jurassic-2
Jurassic-X
Co-writing
Publications
Blog
Press
Stay updated
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.",https://www.ai21.com/studio/foundation-models
Introducing J1-Grande!,"Company
About
Ask RBG
Start building
AI21 Studio releases Grande, a high-quality, affordable language model at the convenient size of 17B parameters.
During the past few weeks, we've been quietly test-driving Grande with AI21 Studio users. The feedback was incredible. In fact, while Grande is significantly closer in size to J1-Large (7.5B parameters), a great majority of users have found that J1-Grande‚Äôs quality is comparable to that of J1-Jumbo (178B parameters). This is great news for all budget-conscious practitioners; J1-Grande, our mid-size model, offers access to supreme quality text generation at a more affordable rate.
Check it out: we asked each of the Jurassic-1 models to generate a humorous poem about a friendship between a dog and a cat:
You‚Äôll find that while each of the three models composed comical (though quite meaningful) poems, Grande and Jumbo exhibit a far more sophisticated level of writing.
Try it out for yourself
in the AI21 Studio playground.
With a response time twice as fast as Jumbo, at one-third the cost of Jumbo, Grande delivers an excellent combination of price, quality and speed to even the most seemingly complex use-cases. To learn more about subscription plans, visit the
pricing page
Benchmarks
Distilling the quality of a language model into a single metric is notoriously difficult. Nevertheless, we find it helpful to compare the performance of different models on standard NLP tasks. Below we examine the accuracy of J1-Large, J1-Grande and J1-Jumbo on a diverse selection of tasks, including common knowledge question answering, reading comprehension and common sense.
None of the models were trained specifically for the tasks presented. We compared the models in two distinct circumstances:
Few-shot: demonstrating with a few examples of ideal outputs for it to mimic (as seen
)
Zero-shot: void of any guidance whatsoever (as seen
here
).
Data indicates the average accuracy of the broad range of tasks assigned to the Jurassic-1 models in experiments of both Zero-shot and Few-shot.Zero-shot trials included ARC-Challenge, ARC-Easy, BoolQ, HellaSwag, PIQA, RACE-high, RACE-middle, RTE, StoryCloze, and Winogrande. Few-shot trails included ARC-Challenge, ARC-Easy, OpenBookQA, BoolQ, RTE, StoryCloze and Winogrande. All tasks were posed in a multiple-choice format. See Jurassic-1
white paper
for more details.
The perplexity (PPL) of Jurassic-1 models is illustrated by average log-probabilities per byte, where a higher number is a more impressive figure. The Zero-shot and Few-shot findings correspond to the same circumstances and data in the bar graph above.
 
Learn more at
https://www.ai21.com/studio
or try it yourself in the
playground
.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Introducing J1-Grande!
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/introducing-j1-grande
Announcing AI21 Studio and Jurassic-1 language models,"Company
About
Ask RBG
Start building
AI21 Labs‚Äô new developer platform offers instant access to our 178B-parameter language model, to help you build sophisticated text-based AI applications at scale
We are thrilled to announce the launch of AI21 Studio, our new developer platform where you can use our state-of-the-art Jurassic-1 language models to build your own applications and services. Jurassic-1 models come in two sizes, where the Jumbo version, at 178B parameters, is the largest and most sophisticated language model ever released for general use by developers. AI21 Studio is currently in open beta, allowing anyone to sign up and immediately start querying Jurassic-1 using our API and interactive web environment.
Our mission at AI21 Labs is to fundamentally reimagine the way humans read and write by introducing machines as thought partners, and the only way we can achieve this is if we take on this challenge together. We‚Äôve been researching language models since our Mesozoic Era (aka 2017 üòâ). Jurassic-1 builds on this research, and it is the first generation of models we‚Äôre making available for widespread use.
Jurassic-1 models are highly versatile, capable of both human-like text generation, as well as solving complex tasks such as question answering, text classification and many others. Our models utilize a unique 250,000-token vocabulary which is not only much larger than most existing vocabularies (5x or more), but also the first to include multi-word tokens such as expressions, phrases, and named entities. Because of this, Jurassic-1 needs fewer tokens to represent a given amount of text, thereby improving computational efficiency and reducing latency significantly.
Jurassic-1 in action, generating blog post ideas in AI21 Studio.
Check out our white paper
for more technical details, as well as a thorough evaluation of our models.
In order to help developers scale their applications beyond a proof-of-concept and efficiently serve production-scale traffic, AI21 Studio allows developers to train custom versions of Jurassic-1 models. Training a custom model is easy and requires as few as 50-100 training examples. Once trained, your custom model is served in AI21 Studio and immediately available for your exclusive use.
We created AI21 Studio to democratize access to cutting-edge AI technology. Using Jurassic-1 within AI21 Studio, you can quickly build text-based applications that rival those being dreamed up in the world‚Äôs biggest labs, even if you have no prior experience. We‚Äôve been using AI21 Studio internally to power our own applications, and it has propelled our product development immensely.
Now it‚Äôs your turn.
GET STARTED NOW
To learn more, visit our blog posts highlighting
different use-cases for Jurassic-1
and demonstrating how to
bootstrap a custom model in AI21 Studio
or read the AI21 Studio
documentation
.
 
Read our official
press release.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Announcing AI21 Studio and Jurassic-1 language models
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1
Introducing Wordtune Read,"Company
About
Ask RBG
Start building
AI21 Labs newest product joins its writing counterpart to tackle information overload & help everyone read more productively
We are so excited to welcome our newest product,
, to the Wordtune family! A year ago we launched Wordtune to empower people across backgrounds, nationalities and industries to write with more confidence and ease. And now with Wordtune Read we hope to do the same for reading! Our mission at AI21 Labs is to fundamentally reimagine the way people write
and read
, so we thought it was high time to share our vision for the reading part of that equation.
Underpinned by our sophisticated language models, Wordtune Read was specifically designed to help professionals across a range of industries and academia navigate the issue of information overload. Wordtune Read analyzes and summarizes a document within seconds, enabling anyone to read long and complex text faster and more efficiently. And because it‚Äôs built on our powerful AI technology, it‚Äôs not just extracting key sentences like other reading tools - it‚Äôs actually summarizing the main points for you.
You simply upload a PDF or copy and paste a link of the text you want to read. Within seconds, short snippets appear alongside the text which identify and summarize the main themes of the document and help you rapidly decipher complex language, so you can focus on the parts that matter. In addition, the Spotlight feature can re-summarize the text from different points-of-view, putting the emphasis on the information that you care about the most. From articles to reports to academic papers, Wordtune Read helps you get to the point of long documents, instantly summarizing key information & saving you time.
We built Wordtune Read specifically to make it easier for people to consume information more easily - so whether you‚Äôre doing a competitive analysis, market research, or writing an award winning scientific study, Wordtune Read has got you covered.
You know you want to try it! Give it a go:
https://www.wordtune.com/read
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Introducing Wordtune Read
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/introducing-wordtune-read
Summarizing legal documents for different personas using AI21 Studio,"Company
About
Ask RBG
Start building
Create your own custom summarizer using AI21 Studio's large language models. This tutorial demonstrates the process on legal documents.
We‚Äôve all experienced reading long, tedious, and boring pieces of text - financial reports, legal documents, or terms and conditions (though, who
actually
reads those terms and conditions to be honest?).
Imagine a company that employs hundreds of thousands of employees. In today's information overload age,
nearly 30% of the workday
is spent dealing with documents. There's no surprise here, given that some of these documents are long and convoluted on purpose (did you know that reading through all your privacy policies would take
almost a quarter of a year
?). Aside from inefficiency, workers may simply refrain from reading some documents (for example,
Only 16% of Employees Read Their Employment Contracts Entirely Before Signing
!).
This is where AI-driven summarization tools can be helpful: instead of reading entire documents, which is tedious and time-consuming, users can (ideally) quickly extract relevant information from a text. With large language models, the development of those tools is easier than ever, and you can offer your users a summary that is specifically tailored to their preferences.
Let's take legal documents, for example. Though they are written in English, many people find legal documents to be difficult to comprehend, as if they were actually written in a foreign language. Moreover, the interesting parts of each document may differ depending on the person who reads it, so off-the-shelf summarization tools may be too general or too specific. As an example, let's look at the involved personas:
Lawyers
. They are interested in several key points, but legal language and terms are especially relevant to them.
Your average Joe.
Doesn‚Äôt understand all the legal terms, and really wants to get the gist in simple words.
Using the
IRS
as our example, we will demonstrate here how to build a simple summarizer for those 2 personas, and discuss which future directions one should consider.
Working with large language models
Large language models naturally follow patterns in input (prompt), and provide coherent completion that follows the same patterns. For that, we want to feed them with several examples in the input (""
few-shot prompt""
), so they can follow through. The process of creating the correct prompt for your problem is called prompt engineering, and you can read more about it
Collecting data
Ideally, you should have a variety of examples to draw from. It is important that those examples represent the actual documents that your summarizer should work on. This means they should be written in the same way as real world documents, and they should be as varied as possible.
Don't have it? No need to worry - large language models generalize exceptionally well, so the results will still be good. In the end, optimal results can always be achieved with proper data - but you can revisit this at a later date.
Summarize for lawyers
If you are summarizing legal documents for lawyers, you should definitely maintain all legal terms from the original document. In this demonstration, we will work on the opening paragraphs of legal letters.
- Grandparent died and left the residue of his estate to Trust 1 and Trust 2, testamentary trusts established under Will. The trustees of Trust 1 want to divide the estate equally between Grandchild 1 and Grandchild 2.
- Section 9(a) of Trust 1 provides that Trustees may distribute the net income to Grandchild 1 and Grandchild 1's descendants in any proportion they determine is desirable.
- Section 9(b) of Trust 1 provides that Trustees may distribute principal to Grandchild 1 and Grandchild 1's descendants as they determine is desirable.
- Section 9(c) of Trust 1 provides that if Grandchild 1 and Grandchild 1's descendants all die before 21 years, Trust 1 will terminate early.
- A taxpayer requested an extension of five years under IRC section 4943(c)(7) for disposing of certain excess business holdings.
- A testamentary gift of stock to Taxpayer and a testamentary disposition to Granddaughter, both disqualified persons, resulted in Taxpayer having excess business holdings of Entity 1 under IRC section 4943(c)(1).
- On Date 3, Taxpayer received an unusually large testamentary gift or bequest of an LLC membership interest, which is an excess business holding.
You will now be presented with a part of a legal letter. Read it and summarize it. Make sure the summary maintains formal terms.
And the completion:
- The Parties requested an extension of time under ¬ß301.9100-3 of the Procedure and Administration Regulations to file an election.
- The Parties are requesting an extension of time to file the Election Statement with respect to Purchaser's acquisition of all the stock of S Corporation Target from Shareholder on Date 1.
- The Parties represented that they are not seeking to alter a return position for which an accuracy-related penalty has been or could be imposed under section 6662.
Notes
It is wise to try several phrasings for your prompt. You can, for instance, keep it simple and direct by writing:
Summarize the following part of a legal letter while maintaining formal terms.
Alternatively, you can take a more elaborate approach, such as:
You are LegalAI, an AI legal assistant that excels at summarizing legal documents.
Below you will find part of a legal letter. Read it and summarize it. Make sure the summary maintains formal terms.
[LETTER]
As you can see, we are providing the model with several examples, separated by a stop sequence, which is easily spotted while reading the text. You can read more about stop sequences
Because this task requires high accuracy, we recommend working at a low temperature. It's best to explore the range of 0.0-0.3, since temperature 0 does tend to produce short summaries. You can read more about temperature
playground.
There is a consistent structure to all the examples in the prompt. This few-shot prompt can be created using the following code (assuming you have the paragraphs and summaries):
def make_single_example(letter, summary):
    example = ""You will now be presented with a part of a legal letter. Read it and summarize it. Make sure the summary maintains formal terms.\n""
    example += ""Letter:\n""
    example += letter
    example += ""\n""
    example += ""Summary:\n""
    example += summary
    
    return example

# This is the stop sequence
SEPARATOR = ""\n##\n""

FEW_SHOT_PREFIX = SEPARATOR.join(
    make_single_example(letter, summary) for letter, summary in zip(letters, summaries)
)

def make_few_shot_prompt(letter):
    
    return FEW_SHOT_PREFIX + SEPARATOR + make_single_example(letter, '') # keep the summary empty and let the model complete
Summarize for the average Joe
Despite the fact that there are over 1.3 million lawyers in the United States alone, most people  (still) aren't lawyers and have trouble understanding legal documents. In this case, we probably want the summary to be written in a simple, easy-to-understand manner.
As this task involves both summarizing and simplifying texts, it is inherently more difficult. Thus, we will probably need more ""shots"" in our few-shot prompt (in this case, we added another example to the prompt).
Here is an example of a few-shot prompt:
This letter responds to your authorized representatives‚Äô letter of May 19, 2022, and subsequent correspondence, requesting rulings regarding the income, estate, gift, and generation-skipping transfer (GST) tax consequences of the proposed division of Trust 1.
The facts and representations submitted are as follows:
Grandparent died on Date 1, leaving the residue of Grandparent‚Äôs probate estate in equal shares to Trust 1 and Trust 2, testamentary trusts established under Will. Trust 1 is held for the benefit of Grandchild 1 and Grandchild 1‚Äôs descendants, and Trust 2 is held for the benefit of Grandchild 2 and Grandchild 2‚Äôs descendants. Grandchild 1 has five children, Great-Grandchild 1, Great-Grandchild 2, Great-Grandchild 3, GreatGrandchild 4, and Great-Grandchild 5. Grandchild 2 has one child, Great-Grandchild 6. Neither Grandchild 1 nor Grandchild 2 has any deceased children. Trustees serve as trustees of Trust 1. Trust 1 is the subject of this ruling request.
Section 9(a) of Trust 1 provides that Trustees may distribute the net income of Trust 1 to or for the benefit of Grandchild 1 and Grandchild 1‚Äôs descendants in such proportions and at such times as Trustees determine is desirable or necessary, considering their needs, best interests, and other sources of income, or may annually accumulate and add all or part of the net income to the principal of Trust 1.
Section 9(b) of Trust 1 provides that Trustees may distribute the principal of Trust 1 to or for the benefit of Grandchild 1 and Grandchild 1‚Äôs descendants in such proportions PLR-110419-22 3 and at such times as Trustees determine is desirable or necessary for their medical care, comfortable maintenance, education, or general support and welfare, considering their other resources.
Section 9(c) of Trust 1 provides that Trust 1 will terminate 21 years after the death of the survivor of Grandchild 1 and Grandchild 2, and the principal of Trust 1 will be distributed to Grandchild 1‚Äôs descendants, per stirpes. If, however, Grandchild 1 and Grandchild 1‚Äôs descendants all die before that date, Trust 1 will terminate early, and the principal of Trust 1 will be distributed to Trust 2.
The purpose of this letter is to describe a trust set up by a grandparent for the benefit of their grandchildren and great-grandchildren. The trustees may distribute money from the trust, but they must follow certain rules. After 21 years, the trust will end, and the remaining money will be distributed to the main beneficiary's descendants. If all the descendants of the main beneficiary pass away before then, the remaining money will be transferred to another trust.
This letter ruling is in response to a request from your authorized representative dated March 11, 2022, and subsequent documentation requesting an extension of an additional five years under Internal Revenue Code (‚ÄúIRC‚Äù) section 4943(c)(7) for disposing of certain excess business holdings. Taxpayer represents the facts as follows.
FACTS
Taxpayer was incorporated as a State nonprofit corporation. Taxpayer is exempt from federal income tax under IRC section 501(a) as an organization described in IRC section 501(c)(3) and is classified as a private foundation under IRC section 509(a). Taxpayer was created by Individuals to support the domestic and international Community and various charitable organizations. Individuals were substantial contributors to Taxpayer within the meaning of IRC section 507(d)(2), and therefore disqualified persons with respect to Taxpayer under IRC section 4946(a)(1)(A).
As a result of Individuals‚Äô death, Taxpayer received A shares of Entity 1 common voting stock from Trust, a disqualified person, on Date 1, which Taxpayer represents is an unusually large testamentary gift or bequest. Additionally, on Date 2, Granddaughter, who is the granddaughter of one of the Individuals, and who serves as a co-trustee of Taxpayer, received a testamentary disposition from Trust of B shares of Entity 1 common voting stock. Granddaughter is also a disqualified person under IRC section 4946. The combined shares of Taxpayer and Granddaughter represent approximately C percent of Entity 1‚Äôs outstanding capital stock and are a minority interest in Entity 1. As a result of the testamentary gift or bequest of the A shares, Taxpayer has excess business holdings of Entity 1 under IRC section 4943(c)(1).
On Date 3, also as a result of Individuals‚Äô death, Taxpayer received from Trust an approximate Z percent membership interest in Entity 2, an LLC, which taxpayer represents is an unusually large testamentary gift or bequest. As a result of the testamentary gift or bequest of the LLC membership interest, which is a minority interest, Taxpayer has excess business holdings of Entity 2 under IRC section 4943(c)(1).
A nonprofit organization asks for more time to sell extra stocks it received after the deaths of a few key contributors. Nonprofit organizations have a limit on how many stocks they can keep, so they request an extension to get rid of them.
You will now be presented with a part of a legal letter. Read it and summarize it. Make sure the summary is short and written in simple words.
Letter:
Dear [Name],
This letter responds to a letter dated March 15, 2022, submitted on behalf of S Corporation Target, Purchaser, and Shareholder (collectively, the ""Parties""), requesting an extension of time under ¬ß301.9100-3 of the Procedure and Administration Regulations to file an election. The Parties are requesting an extension of time to file the election statement under ¬ß1.336-2(h)(3)(iii) of the Income Tax Regulations (the ""Election Statement"") with respect to Purchaser's acquisition of all the stock of S Corporation Target from Shareholder on Date 1. The material information submitted is summarized below.
On Date 1, Purchaser acquired all the stock of S Corporation Target from Shareholder (the ""Stock Disposition""). It has been represented that the Stock Disposition qualified as a ""qualified stock disposition"" as defined in ¬ß1.336-1(b)(6).
The Parties intended to make a section 336(e) election for the Stock Disposition but, for various reasons, a timely election was not fully made. Subsequently, this request was submitted, under ¬ß301.9100-3, for an extension of time to file the Election Statement. The Parties each represented that they are not seeking to alter a return position for which an accuracy-related penalty has been or could be imposed under section 6662.
Regulations promulgated under section 336(e) permit certain sales, exchanges, or distributions of stock of a corporation to be treated as asset dispositions if: (1) the disposition is a ""qualified stock disposition"" as defined in ¬ß1.336-1(b)(6); and (2) a section 336(e) election is made.
Summary:
Due to the difficulty of this task, this prompt is not sufficient. By adding another example (""shot""), however, we will get much better results. Below you can see the completion:
A corporation asks the government for more time to file a statement related to its financial performance for a specific tax year. The government has granted the request but may check the information provided by the company later.<br>
##
Notes:
Like in the previous case, you should try several phrasings for your prompt.
You can test several options for the prompt in our
playground
.
Alternatively, you could have summarized for lawyers first, and then simplified the summary (using a different prompt). This method may, however, result in some information being lost.
Summary
In this post, we explore the use-case of summarization.
If you need a simple, off-the-shelf summarizer, be sure to check out our specialized
summarization API
. However, for more specific use-cases and customization, it‚Äôs wise to get closer to the core with the help of large language models, as custom models that are tailored to your specific needs will always get you higher quality results. Click
here
to learn more.
ABOUT THE AUTHOR
Yuval Belfer
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Tutorial
Summarizing legal documents for different personas using AI21 Studio
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/summarizing-legal-documents-for-different-personas-using-ai21-studio
How Harambee built conversational flows to achieve a 20% sign-up increase,"Company
About
Ask RBG
Start building
Learn how Harambee used AI21 Labs' custom models to create an NLP chatbot app to onboard job seekers to one of their career programs.
Harambee is the official platform for government bodies wanting to hire youth in South Africa. But when the pandemic hit, they needed to find a low-touch yet incredibly authentic way to connect with the growing number of unemployed youth who were looking to get trained and hired.
Harambee logo
So, how was it done? Harambee not only created a new virtual onboarding process, but also drove a 20% conversion rate increase in sign-ups by using AI21 as their Natural Language Processing (NLP) engine. This was achieved by setting up our Language Models to act as intelligent chatbots. The bots were able to understand the context of each conversation, build rapport with the individuals, and respond naturally ‚Äì guiding them toward their career goals.
We spoke with Brent Davidoff, who leads Harambee's effort to scale transformative interventions using their omni channel contact center.
Brent Davidoff, Harambee Youth Employment Accelerator
Who is Harambee?
Harambee Youth Employment Accelerator
is a not-for-profit social enterprise that solves youth employment through partnerships. Harambee works with partners who are also committed to results that can work at scale ‚Äì including government, the private sector, civil society, and over three million youth. By fusing brilliant minds with best-in-class technology, Harambee is working to unlock jobs and break down the barriers that keep millions of young South Africans unemployed.
But how they bridge the gap between unemployed with no experience to ready to work and employable is a key reason why Harambee eventually needed AI21 Studio.
Harambee put these youth through a simulation of a workplace that they call the ‚Äúbridging process‚Äù. In it, the individuals report to a manager and are measured on punctuality and soft skills with a scorecard.
‚ÄúAfter three months of daily bridging, they were transformed,‚Äù said Brent, noting that employers would always see a positive difference in these young adults after completing the program.
And then the 2020 pandemic happened.
Pivoting their processes, and turning to NLP during a pandemic
The once highly personalized, streamlined work socialization experience was now at risk. ‚ÄúWith only 120 personnel at the time, we stopped doing face-to-face processes and didn‚Äôt do the bridging anymore,‚Äù says Brent.
Like many companies during that time, they went fully remote and launched a new website ‚Äì
SAYouth
. And while they still had companies wanting to employ these youths, these individuals weren‚Äôt yet ready for the job market. ‚ÄúThey were missing the secret sauce [of the bridging process],‚Äù adds Brent.
Searching for a Solution that Could Match Human Intelligence
This led them to the development of a chatbot that they called ‚ÄúCoachmee‚Äù. It created a conversation based learning experience that used evidence-based techniques to effect measurable behavior change in its users. But not without some snags along the way.
‚ÄúFrom our previous work with other chatbots [before finding AI21], we had seen how the signup process was a vital component for ensuring high levels of engagement and most chatbots failed to do that with an audience like ours for a number of reasons,‚Äù Brent tells us, explaining why he went searching for a new solution.
Here‚Äôs what Harambee needed ‚Äì and what led them to AI21.
Problem #1: A chatbot that can understand, not just repeat
Their focus was deeper than simply having quick response times for their customers. Harambee needed help creating trust, rapport, and relationships with their users during their sign-up process ‚Äì a critical, pivotal moment in their program.
‚ÄúTraditional intent-based NLPs are all about understanding what someone says, but then returning something that is prewritten. But no conversation is like that. You must be unique,‚Äù says Brent, providing us with an example of an everyday conversation during the sign-up process.
Chatbot: ‚ÄúWelcome to Coachmee, please tell me your name.‚Äù
Person: ‚Äú19547896‚Äù
Chatbot: ‚ÄúThat looks like an ID number, would you mind, with respect, telling me your name again?‚Äù
Person: ‚ÄúMy name is Rejoice Precious Mikateko ‚Äù
Chatbot: ‚ÄúHello, Rejoice!‚Äù
‚ÄúAlready there, the ability to see someone and get their name right. ‚ÄúThere‚Äôs no traditional intent-based NLP that can do that.‚Äù
Problem #2: Adapt to overcome language barriers and context
There are many models that offer a multitude of language options, but one was missing ‚Äì what about broken English?
There are times when people switch between languages and use a mix of words that would not be understood by a normal chatbot. Our goal isn't just to find something that speaks one of South Africa's 11 official languages, but to find out what someone really is trying to convey.‚Äù says Brent.
Why AI21 Studio? Better accessibility and support
While we at AI21 have
best practices to help mitigate the risk
of malicious use of language models, AI21‚Äôs barrier to entry was non-existent, meaning Harambee could jump right in.
‚ÄúI was astonished that there was no huge waiting list to get into this platform and I found the company's vision quite inspiring. I signed up and started playing around on the playground.‚Äù
It‚Äôs important to be able to interact with the models, explore presets, and play around before committing to an NLP.
‚ÄúI am not a coder,‚Äù he adds. ‚ÄúWhen I saw that AI21 Studio had an easy-to-use fine-tuning feature that did not require any previous coding experience, I was excited to see how quickly I could prototype different conversational flows and build something that felt human and relatable.‚Äù
Beyond the Chatbot: How Harambee Used AI21 to Reach Their End Goal
Harambee saw incredible success using the chatbot.
‚ÄúThe conversations [work seekers are having] are incredible,‚Äù says Brent. ‚ÄúFor the first time, they feel like they are important. For the first time, they feel like their goals are important. They feel like there is someone there to support them.‚Äù
Beyond building rapport and genuine connection with the South African youth, they were able to utilize AI21 to make their jobs easier and improve further processes.
Solution #1: Content creation through ‚Äúlifehacks‚Äù
With AI copywriting, you can automate repetitive writing tasks. Brent and the Harambee team were able to develop around 60 different ""lifehacks"" for users who had signed up for Coachmee check-in sessions.
Lifehacks have to strike a careful balance between being aspirational and transcendent, while being practical and relevant. All within a few sentences, making sure someone doesn't have to scroll back up to read the full message.
Another unique contribution of AI21 Labs was around the use of emojis, which enabled the lifehacks to be much more playful and engaging.
Solution #2: Unique reference letters
With the summarization tool, you can compress documents and
extract key insights into short summaries
. Brent and the Harambee team used this to create 100% unique, relevant reference letters for each individual who finished their training.
‚ÄúSometimes the model can go way too far and make up crazy things about the person,‚Äù says Brent, discussing what has gone wrong while using other applications.
‚Äú[But] when a user completes 20 check-ins with Coachmee, we have enough data that can factually testify to someone's commitment to growth and goal-achievement. That information, together with the deep insights into their aspirations and personality that we lifted from the initial sign-up conversation, we are able to use Studio API to generate beautiful reference letters that they can attach to their CVs and take with them to interviews,‚Äù explains Brent. ‚ÄúI [once] got a message saying, ‚ÄòI gotta frame this!‚Äô‚Äù
Reference letter - example
The Result: Helping Thousand of Youths Gain Employment When They Need it Most
Harambee has fine-tuned its AI21 NLP experience to drive meaningful conversations. Their data shows that the stronger the rapport that is built at the beginning of the relationship, the more chance the person has at continuing and completing the process.
Pillar 1 - Engagement: Most start, most finish
Brent concludes that ‚Äúcompared to the first iteration of Coachmee which did not use an NLP for the sign-up process, our conversion rate from sign-up to completion has improved by 20%.‚Äù
In addition, he tells us that almost 1,000 young people have measurably higher prospects of employment thanks to the unique reference letters that AI21 Studio API helped create. ‚ÄúAI21 has been the most generous, collaborative and supportive technology partner that I have ever worked with.‚Äù
We are thrilled to have the opportunity to use our NLP technology to help elevate the careers of thousands of youths in Africa. We hope this project serves as inspiration to many other organizations around the world.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
How Harambee built conversational flows to achieve a 20% sign-up increase
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/harambee-case-study
Revolutionizing web search: The winning solution of AI21 Labs' Hackathon,"Company
About
Ask RBG
Start building
Over 1,900 participants took part in the the ever first AI21 Labs Hackathon, with 24 different projects competing for the first prize.
The winner of AI21 Labs‚Äô first ever hackathon is
Rahel Gunaratne
, who nabbed the first place prize with his
project - An AI-based question-answering tool designed to help users find specific information using questions instead of keyword search within a webpage. WebIndexer can be integrated into any website, offering users a much-needed solution to the slow and tedious process of keyword search, and can serve as a valuable alternative to both ChatGPT and traditional search bars like Google.
WebIndexer
on Streamlit
The AI21 Labs Hackathon, which was produced in conjunction with
Lablab AI
, kicked off on January 13th and concluded eight days later on the 21st. Over 1,900 participants took part in the event, with 24 different projects competing for the first prize.
The winning projects were chosen by a panel of judges which includes AI21‚Äôs
Yuval Belfer
(who also initiated and produced the event),
, and
Jack Yulzari
, alongside representatives from NewNative - the company behind Lablab AI.
The projects were selected according to the following criteria:
It must be an innovative idea
It has to solve a real-world problem or pain point
It needs to be built on beautiful code
It must have great documentation
The Finalists
Coming in second place were three notable projects:
Team Last Minute
- A smart cooking solution that aims to reduce household food waste worldwide by using AI to help users determine what meals to prepare based only on the ingredients that they have left in their refrigerator.
Kitchen Genie
on Github | Watch the
on Youtube
T.E.A (Test English AI)
Team Think Tank -
A web application designed to help English students excel in language proficiency tests with the help of personalized, AI-generated reading exercises. Trained on IELTS Academic as well as general reading tasks, T.E.A brings users one step closer to a real-world exam experience.
T.E.A
on Heroku
by
Team MedBrief -
Designed with the aim of significantly reducing medical review time, MedBrief provides users with summaries of lengthy patient reports and highlights significant medical terminology. A big standout feature is Medbrief‚Äôs ability to answer questions based on an individual‚Äôs medical records by incorporating AI21‚Äôs tech with their own well-written code.
Check out
MedBrief
on Github | Try the
demo
on Vercel
 
"" The hackathon's submissions left me, as a mentor, astounded. The number of production-ready projects, coupled with the broad range of innovative solutions they provided to real-world issues, serves as proof of the participants‚Äô talent. Additionally, it's a testament to the infinite possibilities of generative AI. ""
- Jack Yulzari
ABOUT THE AUTHOR
Yotam Shinan
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Events
Revolutionizing web search: The winning solution of AI21 Labs' Hackathon
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/first-hackathon-winning-projects
Discover use cases for AI21 Studio and Jurassic-1,"Company
About
Ask RBG
Start building
Learn how to use Jurassic-1 to perform summarization, idea generation, classification and many other language tasks
In this blog post we showcase different ways of using AI21 Studio and Jurassic-1 to perform different language tasks. We hope these will help you kickstart your applications, and even inspire you to come up with ideas for new use cases. For convenience, the examples are grouped into categories, though this grouping doesn‚Äôt follow very strict rules. Make sure to check out the last group of
fun examples
for some laughs!
All of the examples below use prompts we crafted manually, and they are available in AI21 Studio as presets, so you can try them yourself, tinker with them and use them as a basis for your own prompts.
Prompt engineering, the process of composing a prompt to perform a specific task, is a fast, easy, and flexible way to build a demo or prototype. In fact, the prompts we‚Äôre sharing here are the product of one day's work, at most. To take your application beyond proof-of-concept, we recommend you train a custom model. Custom models in AI21 Studio can be trained on very small datasets with as few as 50-100 examples. They offer better precision and latency and can be more economically scaled-up to serve production traffic. Read our blog post to learn more about bootstrapping your own custom model.
Summarizing or simplifying text
Jurassic-1 is great at applying different transformations to existing text - consuming some text and then generating a piece of text that relates to it.
One common transformation is summarization. Summarization has many business use-cases, such as extracting the gist of online restaurant reviews:
Note that the model successfully follows the style of the example provided in the prompt, and outputs a sequence of short 2-3 word phrases summarizing the review. In a practical setting, we can imagine this method being used to squeeze reviews for display on small mobile devices.
Another useful transformation is simplifying text to make it more readable and accessible. A useful application could be rephrasing a sentence to avoid business jargon:
Or more explicitly, using Jurassic-1 to explain the meaning of a word in context:
Try it live in AI21 Studio
Ideation and copywriting
Jurassic-1 can be used to augment human creativity in content creation, marketing, ecommerce and even creative writing.
By priming our model with titles for blog posts about AI and tourism, we can generate plausible ideas for new blog posts about another topic of our choosing:
Humor and sarcasm are nuanced and notoriously hard for AI models to produce. Nevertheless, it turns out you can feed article topics into the model and get it to generate funny headlines:
Another useful application is writing one-sentence product descriptions for marketing and ecommerce. In the following example, Jurassic-1 generates a short description based on a product name and a list of features:
Generating code
Jurassic-1 models can process not only English text but also code in a variety of programming languages. We can use this to translate plain English descriptions into correct Python one-liners:
Or even translate entire functions from one programming language to another:
Working with tables
Text often comes in a structured format, like a table. Below are two examples that show how Jurassic-1 can both extract information from a table and generate a properly formatted table from natural language:
These two examples highlight the flexibility of Jurassic-1‚Äôs universal ‚Äútext-in, text-out‚Äù interface. The model properly handles various forms of text data out of the box, freeing developers to focus on core functionality instead of worrying about format conversions.
Classification
Most use-cases above were generative in nature, meaning they involve generating a phrase, sentence, line of code etc. Another important subset of language tasks are text classification tasks, where the goal is to label a piece of text.
For instance, consider topic classification. The following example demonstrates classifying news articles based on their title and their summary:
Note there are four categories - ‚ÄúWorld‚Äù, ‚ÄúSports‚Äù, ‚ÄúBusiness‚Äù or ‚ÄúScience and Technology‚Äù - and we specify them explicitly in the prompt. The model then outputs these as the classification labels.
We can use the same idea to perform binary classification. In this example the model determines whether a certain attribute indicates a high or low level of openness (one of the
Big Five personality traits
in psychology):
This time, the two possible labels (‚ÄúHigh‚Äù and ‚ÄúLow‚Äù) aren‚Äôt spelled out in the prompt, and the model picks them up from the examples.
World knowledge
Because it was trained on a massive amount of text, Jurassic-1 acquired knowledge about different topics. By composing a suitable prompt, we can retrieve facts encoded in the model in natural language form. It‚Äôs often a good idea to build a Q&A or ‚Äúinterview‚Äù style prompt for this, like the one we use in the following example to answer sports trivia questions:
A different kind of knowledge is common sense knowledge. In this example we probe the model‚Äôs ability to predict outcomes of different actions according to common sense:
Try it live in AI21 Studio
It‚Äôs important to keep in mind that the coverage and accuracy of knowledge encoded in Jurassic-1 may vary depending on factors such as time, topic and geography, and may also reflect bias found in the human-written texts the model was trained on. In particular, don‚Äôt expect the model to possess highly domain-specific knowledge. Furthermore, note that the model doesn‚Äôt have any knowledge of current events, since it was trained on texts dated up to year 2020.
Other fun examples
Finally, we‚Äôd like to share a few fun examples, built by members of our team on a one-day internal hackathon. These projects were primarily designed to make you laugh, but we hope they also help you imagine the opportunities that AI21 Studio unlocks for media, content creation, human-computer interaction and many other industries.
Jurassic-1 write rap lyrics
The team used Jurassic-1 to generate lyrics for rap songs about historical figures. The inspiration is, of course, the musical Hamilton. They primed the model with lyrics about Alexander Hamilton, George Washington (both from ‚ÄúHamilton‚Äù) and Eva Per√≥n (from ‚ÄúEvita‚Äù). Then they had the model generate new lyrics about Barack Obama. Note that they didn‚Äôt explicitly provide the model with any of the biographical information about Obama, so all the knowledge (Harvard Law, Michelle, Chicago etc.) is encoded within the model itself. Once they had the lyrics, they packaged them nicely in a video using an off-the-shelf deep fake engine that supports rap, added a beat, et viola.
Jurades: AI charades powered by Jurassic-1
In this game, players take turns trying to communicate the identity of random famous characters, without stating their names, following the standard rules of charades. Unlike a normal game of charades, the one responsible for guessing the the characters' identities is not a human, but a language model... Jurassic-1!
The model is fed with a few-shot prompt that taps into its world knowledge and text comprehension capabilities. Jurassic-1 is surprsingly good at understanding non-coherent, associative descriptions that humans make under pressure. The prompt is set up to allow the model to self-correct based on failed guesses and follow up hints.
 
JurassiChess
Continuing our games theme, JurassiChess uses Jurassic-1 to give you verbal feedback on your chess moves, by integrating it with
Stockfish
, an open-source chess AI. When you play against Stockfish, it provides a score that represents the strength of your position as well as the AI‚Äôs suggestions for the best alternative move (
in chess notation
). We feed this information into Jurassic-1 and use specific prompts to generate relevant positive, negative or neutral feedback, resulting in a responsive AI chess tutor experience. And if you don‚Äôt mind a little trash-talking, a different set of prompts gives your AI opponent a way to taunt you.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Tutorial
Discover use cases for AI21 Studio and Jurassic-1
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/ai21-studio-use-cases
How Tweet Hunter scaled to an 8-figure exit with AI21‚Äôs LLM,"Company
About
Ask RBG
Start building
Discover how Tweet hunter built its product and eventually landed an 8-figure exit with AI21 Studio.
The Brand
Tweet Hunter is an all-in-one Twitter growth tool, designed to help users grow and monetize their Twitter audience. Their goal is to make it as easy as possible for users to create high-performing content, build an audience around their topics of expertise, and monetize opportunities.
The Story
The founders of
Tweet Hunter
started with an insane challenge: ship one new product every week till you find the one that fits.
‚ÄúGenerating revenue from the product was our number one, clear signal for validation.‚Äù says Thibault Louis-Lucas, founder of Tweet Hunter.
The team started with Twitter as a distribution channel for their products because they had an engaged following of 2,000 people. So they started building a product to help people with a Twitter following generate sales.
Their principle was: consistently great content was crucial to a creator‚Äôs growth on Twitter.
But they needed an LLM partner who could see their vision and fine tune for their specific use-cases.
Why AI21? Shared core values, flexibility, and excellence
Tweet Hunter was looking for ways to empower creators to write incredible content faster, by removing gruntwork from the equation. They wanted to create tools that help creators focus on the creative aspects instead of the mundane tasks like editing, collection and formatting. Tweet Hunter's product needs were perfectly aligned with AI21's mission: to help developers build AI-first writing experiences.
Switching from the legacy GPT-3, Tweet Hunter found this vision only in AI21.
‚ÄúWe could‚Äôve switched back to GPT-3 but we stayed because of the flexibility that AI21 was providing with the fine tuning of models.‚Äù says Thibault.
One of the bigger differentiator for Tweet Hunter was AI21‚Äôs willingness to create a customized pricing plan to sync with Tweet Hunter‚Äôs usage and growth. Tweet Hunter saved significantly on customization costs because AI21‚Äôs pricing for custom fine-tuned model usage is the same as the foundation model usage. Other LLMs (such as Open AI‚Äôs) offer customization at approximately six times the cost of their foundational models.
With these criteria coming together perfectly, Tweet Hunter set out to optimize the product to have an 8-figure exit.
The first challenge: Generative AI for social media
Social media channels have strict specifications such as character limits, use of hashtags, and even tone of voice which makes
effective
generative AI in social media a challenging task, requiring intense experimentation and refinement.
Initially, this was a challenge for Tweet Hunter since their primary product offering was designed for Twitter.
AI21 offered a 3-click custom model training which Tweet Hunter effectively leveraged using their proprietary data to fine-tune a model for the exact capabilities they envisioned. AI21 were flexible with both their approach and features so Tweet Hunter could build a tool with multiple junctions for AI to assist.
The second challenge: too many distinct use cases
Writing engaging tweets presents a multi-level challenge:
start with a creative hook, keep it succinct, and build an engaging experience for threads.
This means your AI text generator must be adaptable to different use cases. Also, each of these use cases need to integrate seamlessly while being mindful of the user experience.
‚ÄúTwitter‚Äôs own user interface and algorithm is optimized for engagement and consumption, it's not optimized to inspire you.
And that‚Äôs a problem‚Äù says Thibault.
AI21 anticipated diverse use cases and built their large language model to be flexible and adaptable from the onset. As a result, Tweet Hunter could fine tune the model in three clicks, iterate quickly and reach success.
The resulting model was built with three distinct capabilities and two sub-capabilities
Thread idea generator
Hook generator
Tweet writer
Sub-capabilities
Tweet extender (expands on the tweet you‚Äôre already started writing)
Each of these features are presented in a fluid transition on the Tweet Hunter platform, which lead to over 5000 paying customers for the tool.
The third challenge: unreliable data to train large language models
Tweet Hunter‚Äôs founders had tried every method under the sun to consolidate relevant data, from using freelancers to creating spreadsheets themselves.
Not only was this exercise time intensive but it also produced inconsistent and unreliable results.
They were so disappointed after trying out multiple generative AI tools that they switched back to manual data collection. They were worried that poor quality examples would interfere with the very premise of Tweet Hunter: inspiration for great content.
Enter AI21.
The studio‚Äôs in-built functionality allowed Tweet Hunter to fine tune the model to learn from a diverse tweet database. AI21's generated suggestions became exponentially better as the system evolved, and Tweet Hunter's goal of helping creators write save-worthy tweets was achieved in a fraction of the time expected.
AI21‚Äôs custom model and proactive engagement throughout the journey was exactly what Tweet Hunter needed in a partner.
‚ÄúWe deeply appreciate AI21‚Äôs level of involvement with our product and needs in the early days. We were able to evaluate the model‚Äôs quality before production and maintain high standards on the quality of tweets.‚Äù says Thibault.
What changed for Tweet Hunter after working with AI21?
In the last two years, Thibault‚Äôs personal account grew from 2,000 followers to 60,000 followers. With Tweet Hunter's scheduling feature and tweet generation tools powered by Ai21‚Äôs language models, he (and other users) could tweet frequently and effectively.
Tweet Hunter scaled to 1M ARR and an 8-figure exit in under a year.
‚ÄúThe content is very high quality. The tool works with diverse creators, varied niches, and complex topics. So most of the growth comes from the fact that our users are actually successful with the tool.‚Äù says
Thibault
.
The level of personalization possible with AI21 propelled Tweet Hunter to first place for multiple creators.
https://twitter.com/mvxlondon/status/1621192750900051971
‚ÄúPersonalized, highly viral tweet formats developed with AI21 helped busy users share valuable content. That was the win. Our tool became 10 times faster with the AI integration.‚Äù says Thibault.
The road forward
With lempire‚Äôs acquisition of Tweet Hunter, the road forward is fast-paced and fascinating.
The team plans to introduce new features to the platform based on public feedback. AI21 is also set to be integrated with other products in lempire‚Äôs toolkit: personalized cold emails, automated follow-ups, and engagement with leads across multiple channels.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
How Tweet Hunter scaled to an 8-figure exit with AI21‚Äôs LLM
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/tweet-hunter-case-study
Build a dashboard based on freeform sentiment analysis of hotel reviews,"Company
About
Ask RBG
Start building
Analyze large quantities of reviews in minutes using AI21 Studio
Imagine that you have a platform for hotel reservations, similar to
Hotels.com
. On your platform, hotel visitors can leave written reviews and an overall star rating for the hotel. These reviews allow hotel owners to gain a general understanding of guest satisfaction through their overall score, but that‚Äôs just one part of the story. The quality of the hotel experience is a combination of many factors, including the room quality, the facilities, and the staff. Ideally, the owner would like to get a clear picture of their hotel‚Äôs strengths and weaknesses so they can improve on the aspects that are lacking and highlight the aspects that visitors find positive.
To extract these insights, some hotel owners sit down from time to time and read all of the reviews that were written about their hotel. This is a tedious task - one you, as a developer, would probably want to spare your users from. What if you could create a dashboard that highlights the areas guests mention positively or negatively in their reviews? As a result, your user - in this case, the hotel owner - can get a real-time snapshot of their strengths and weaknesses with just a glance at this dashboard.
Not so long ago, you would have needed to work pretty hard to create a solution like that (for example,
using several classical methods
). But with large language models (LLMs), it‚Äôs really easy. You can perform this analysis with high accuracy, even with no prior knowledge of natural language processing (NLP). If that sounds appealing to you, then read on. By the end of this post, you will be able to implement this feature in your platform or product.
This post will walk you through the process of building an NLP-powered dashboard for a hotel, including:
Using an external API to gather real-world data.
Performing freeform combined topic extraction and sentiment analysis using Jurassic-1, part of the AI21 Studio suite of large language models.
Generating the output in a convenient format (JSON) so it‚Äôs easier to process.
If you are new to large language models, we recommend first reading
Step 1: Collect reviews using an external API
You can find the Hotels.com API on
RapidAPI
. There are several endpoints to this API. We need the
endpoint, that returns the reviews for a given hotel, page-by-page. There are approximately 50 reviews per page. In order to retrieve all of the available reviews we will call the API while iterating through the pages. The following functions do just that:
def get_hotel_reviews_page(hotel_id, page_number):
    params = {
        ""locale"": ""en_US"", 
        ""hotel_id"": hotel_id, 
        ""page_number"": str(page_number)
    }
    headers = {
        ""X-RapidAPI-Key"": RAPID_API_KEY,
        ""X-RapidAPI-Host"": ""hotels-com-provider.p.rapidapi.com""
    }
    response = requests.get(url=GET_REVIEWS_URL, headers=headers, params=params)
     
    reviews = [
        review['summary'] 
        for page_reviews in response.json()['groupReview']
        for review in page_reviews['reviews']
    ]
    return reviews


def get_hotel_reviews(hotel_id, num_pages):
    all_reviews = sum(
        [get_hotel_reviews_page(hotel_id, page_number) for page_number in range(1, num_pages + 1)],
        start=[]
    )
    return all_reviews
Note that running this function requires an API key for the
reviews
endpoint, which you can obtain from RapidAPI. This is not your AI21 Studio API key. There are some edge cases that this function doesn‚Äôt cover, such as requesting a page number that doesn‚Äôt exist, but we‚Äôll set them aside for the purposes of this blog post.
Throughout this process, we will use the
Empire Hotel in New York
as a running example. You can use an API endpoint to get the hotel ID, or you can find it in the hotel‚Äôs URL on Hotels.com:
Step 2: Prepare the reviews data for the language model
Large language models are very powerful and can ingest text of all shapes and sizes, but as the old saying goes, ‚Äúgarbage in, garbage out‚Äù. If you feed the model a bad prompt, the results will be far from optimal.
In this case, you should keep the following points in mind:
Reviews that are too short could be problematic since they often do not contain enough information to extract any meaningful insights.
Currently, our models are limited to the English language only.
In order to remove reviews that are too short or not in English, you can apply some simple filters to all of the reviews:
from langdetect import detect
def filter_reviews(reviews):
    en_reviews = [review for review in reviews if len(review)>=20 and detect(review)==""en""]
            
    return en_reviews
Note: Here, we have removed reviews that have no real content by applying a very basic filter. Although this is not mandatory, we recommend that you pre-process your reviews by, for example, removing weird characters and extra spaces, etc.
Step 3: Extract the categories and sentiments using AI21 Studio
This step is where you truly  harness the power of AI21 Studio‚Äôs large language models!
You want the model to extract the topics and sentiments of each free text review into a structured JSON format. You can do this by leveraging a main strength of language models: when provided with text in plain English, the language model can identify patterns and generate text that follows the same pattern. By feeding the model a prompt with a few examples (this is called a
), it can identify the pattern and generate a reasonably good completion.
Obtaining these examples, however, requires you to manually go through several reviews, which we have done below. The resulting few-shot prompt is as follows (the reviews are as written by the platform‚Äôs users, with no grammar or spelling corrections):
Great experience for two teenagers. We would book again. Location good.
{""Location"": ""Positive""}
Extremely old cabinets, phone was half broken and full of dust. Bathroom door was broken, bathroom floor was dirty and yellow. Bathroom tiles were falling off. Asked to change my room and the next room was in the same conditions.
The most out of date and least maintained hotel i ever been on.
{""Cleaning"": ""Negative"", ""Hotel Facilities"": ""Negative"", ""Room Quality"": ""Negative""}
Review:
Roof top‚Äôs view is gorgeous and the lounge area is comfortable. The staff is very courteous and the location is great. The hotel is outdated and the shower need to be clean better. The air condition runs all the time and cannot be control by the temperature control setting.
Extracted sentiment:
{""Cleaning"": ""Negative"", ""AC"": ""Negative"", ""Room Quality"": ""Negative"", ""Service"": ""Positive"", ""View"": ""Positive"", ""Hotel Facilities"": ""Positive""}
##
Creating a good prompt is more than simply deciding on the pattern. The goal is to construct a prompt that triggers the model to generate the optimal completion (this is called
prompt engineering
). To achieve this, you should keep the following in mind:
Variety:
the examples in the prompt will determine the model‚Äôs responses for unseen data, so they must be diverse enough to reflect the real-world distribution. This applies to both the structure of the reviews (such as length) and the content (the topics discussed in every review, the sentiments, etc.). Be sure to include reviews that are mixed in sentiment (like the third example provided above), as these are usually harder to analyze.
Amount:
how ‚Äúfew‚Äù examples should our
few-shot prompt
include? When it comes to this relatively complex task, it is recommended that you provide at least eight different examples in the prompt (depending on the number of topics and the variety within them). The most effective way to determine this is through testing it out in the playground.
Try it yourself!
Additionally, in this use-case, we recommend setting the temperature to 0, as high accuracy is required more than creativity. Increasing the temperature will result in more creative results, while lowering the temperature will increase their accuracy. Curious about temperature? See Step 4 in
this post
for more detail on this.
Happy with the prompt and want to start analyzing reviews? You can copy the few-shot prompt from the playground:
And use the following function to create the prompt for every review:
def create_review_prompt(review):
    few_shot_examples = FEW_SHOT_EXAMPLES
    prompt = few_shot_examples + review + ""\nExtracted sentiment:\n""
    return prompt
For every review, create the prompt and then call Jurassic-1 to perform the analysis (you can take the call from the playground, as illustrated above, or use the function from
).
Step 4: Create the dashboard
Once you have the list of topics and sentiments, you can create your dashboard.
First, gather all of the topics together, assigning a count of ""Positive"" or ""Negative"" to each topic. Since you already have the completion in JSON format, you can process it using standard packages. However, as the format may not be perfect, and you don‚Äôt want any failures in your automated process, you can add a simple try-catch block. This means if a completion from the model isn‚Äôt in perfect JSON format, you drop it. You can use the following function:
def get_topK_categories_and_score(sentiments, k=7):
    parsed_sentiments = []
    for sentiment in sentiments:
      try:
         parsed_sentiments.append(ast.literal_eval(sentiment))
      except SyntaxError:
        pass
    
    df = pd.DataFrame(parsed_sentiments)

    # extract the K categories with the most reviews    
    keys = df.count().sort_values(ascending=False)[:k].index.tolist()
    
    category_names = ['Negative', 'Positive']
    scores = {}

    for key in keys:
        scores[key] = [(df[key] == category_names[0]).sum(), (df[key] == category_names[1]).sum()]
        
    return scores, category_names
At this stage, all that‚Äôs left to do is create the figure. With minor changes to this
matplotlib
example, you‚Äôll have your dashboard:
You can see that the hotel is deemed excellent in Location and rather good in Service and Cleaning. However, it should invest more in the WiFi and AC, and perhaps do some renovations or upgrades to the rooms and facilities.
As a last step and some sanity check, you‚Äôll probably want to validate your results, but without manually reading every review. One way to do that is to compare them with those of other hotel platforms, such as Booking.com. If you go to the
Booking.com page for this hotel
, where visitors are asked to rate hotels across numerous categories, you will find the overall picture is very similar to your own analysis:
Summary
By following the steps laid out in this post, you have built a very useful feature that can be implemented on hotel and accommodation platforms. Thanks to large language models, analyzing pieces of text, such as reviews, has never been easier. A few simple tweaks, such as writing the examples in JSON format, can save a lot of time in post-processing, making the entire process faster and easier. You can find the full notebook in our
dev-hub
Are you interested in building your own feature? With a custom model, you‚Äôll  always get the highest quality results. You can find out more about that
here
.
 
ABOUT THE AUTHOR
Yuval Belfer
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Tutorial
Build a dashboard based on freeform sentiment analysis of hotel reviews
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/build-a-dashboard-based-on-freeform-sentiment-analysis-of-hotel-reviews
Best practices for deploying language models,"Company
About
Ask RBG
Start building
Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models
Computers that can read and write are here, and they have the potential to fundamentally impact daily life. The future of human-machine interaction is full of possibility and promise, but any powerful technology needs careful deployment. The joint statement below represents a step towards building a community to address the global challenges presented by AI progress, and we encourage other organizations who would like to participate to get in touch.
Joint Recommendation for Language Model Deployment
We‚Äôre recommending several key principles to help providers of large language models (LLMs) mitigate the risks of this technology in order to achieve its full promise to augment human capabilities.
While these principles were developed specifically based on our experience with providing LLMs through an API, we hope they will be useful regardless of release strategy (such as open-sourcing or use within a company). We expect these recommendations to change significantly over time because the commercial uses of LLMs and accompanying safety considerations are new and evolving. We are actively learning about and addressing LLM limitations and avenues for misuse, and will update these principles and practices in collaboration with the broader community over time.
We‚Äôre sharing these principles in hopes that other LLM providers may learn from and adopt them, and to advance public discussion on LLM development and deployment.
Prohibit misuse
Publish usage guidelines and terms of use
of LLMs in a way that prohibits material harm to individuals, communities, and society such as through spam, fraud, or astroturfing. Usage guidelines should also specify domains where LLM use requires extra scrutiny and prohibit high-risk use-cases that aren‚Äôt appropriate, such as classifying people based on protected characteristics.
Build systems and infrastructure to enforce usage guidelines
. This may include rate limits, content filtering, application approval prior to production access, monitoring for anomalous activity, and other mitigations.
Mitigate unintentional harm
Proactively mitigate harmful model behavior
. Best practices include comprehensive model evaluation to properly assess limitations, minimizing potential sources of bias in training corpora, and techniques to minimize unsafe behavior such as through learning from human feedback.
Document known weaknesses and vulnerabilities
, such as bias or ability to produce insecure code, as in some cases no degree of preventative action can completely eliminate the potential for unintended harm. Documentation should also include model and use-case-specific safety best practices.
Thoughtfully collaborate with stakeholders
Build teams with diverse backgrounds
and solicit broad input. Diverse perspectives are needed to characterize and address how language models will operate in the diversity of the real world, where if unchecked they may reinforce biases or fail to work for some groups.
Publicly disclose lessons learned regarding LLM safety and misuse
in order to enable widespread adoption and help with cross-industry iteration on best practices.
Treat all labor in the language model supply chain with respect
. For example, providers should have high standards for the working conditions of those reviewing model outputs in-house and hold vendors to well-specified standards (e.g. ensuring labelers are able to opt out of a given task).
As LLM providers, publishing these principles represents a first step in collaboratively guiding safer large language model development and deployment. We are excited to continue working with each other and with other parties to identify other opportunities to reduce unintentional harms from and prevent malicious use of language models.
Support from other organizations
‚ÄúWhile LLMs hold a lot of promise, they have significant inherent safety issues which need to be worked on. These best practices serve as an important step in minimizing the harms of these models and maximizing their potential benefits.‚Äù - Anthropic
‚ÄúAs large language models (LLMs) have become increasingly powerful and expressive, risk mitigation becomes increasingly important. We welcome these and other efforts to proactively seek to mitigate harms and highlight to users areas requiring extra diligence. The principles outlined here are an important contribution to the global conversation.‚Äù ‚Äì John Bansemer, Director of the CyberAI Project and Senior Fellow, Center for Security and Emerging Technology (CSET)
""Google affirms the importance of comprehensive strategies in analyzing model and training data to mitigate the risks of harm, bias, and misrepresentation. It is a thoughtful step taken by these AI providers to promote the principles and documentation towards AI safety."" - Google.
""To realize the promise of large language models, we must continue to collaborate as an industry and share best practices for how to responsibly develop and deploy them while mitigating potential risks. We welcome this and other efforts that drive thoughtful and practical action across the industry, learning from and working with key stakeholders in academia, civil society, and government."" ‚Äî Microsoft
‚ÄúThe safety of foundation models, such as large language models, is a growing social concern.  We commend Cohere, OpenAI, and AI21 Labs for taking a first step to outline high-level principles for responsible development and deployment from the perspective of model developers.  There is still much work to be done, and we believe it is essential to engage more voices from academia, industry, and civil society to develop more detailed principles and community norms. As we state in our recent
blog post
, it is not just the end result but the legitimacy of the process that matters.‚Äù - Percy Liang, director of the Stanford Center for Research on Foundation Models (CRFM)
If you‚Äôre developing language models or are working to mitigate their risks, we‚Äôd love to talk with you. Please reach out [
bestpractices@ai21.com
].
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Tutorial
Best practices for deploying language models
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/best-practices-for-deploying-language-models
Zero-to-production: bootstrapping a custom model in AI21 Studio,"Company
About
Ask RBG
Start building
Learn how to develop a text-based AI application in AI21 Studio and grow it from prototype to production using custom Jurassic-1 models
Introduction
In this blogpost, we walk through a case study demonstrating how you can build production-grade language applications quickly and effortlessly using AI21 Studio. We use a simple text classification use-case as our guiding example, but the same process can be applied to a wide variety of language tasks.
We start by introducing the task and implementing a baseline solution using prompt engineering with Jurassic-1. Although prompt engineering is a quick and straightforward method for building a proof-of-concept, it has some key limitations, which we highlight in detail below.
To address these limitations, we implement a better solution by training a
custom model
specifically for our example task. AI21 Studio‚Äôs custom models are tailored for optimal performance on a given task and can be economically scaled-up to serve production traffic. Even more importantly, custom models are easy to set up and use!
Custom models in AI21 Studio require remarkably little data for training
; most tasks can be addressed successfully by training a model on as few as 50-100 examples. This dramatically lowers the entry barrier for training a state-of-the-art language model of your own, to power your app with excellent quality results. Your trained custom model is served in AI21 Studio and it is immediately available for use, making integration in your application as easy as performing an API query.
Our Example Task: Classifying News Article Topics
As a guiding example throughout this blogpost, we will use a well known Natural Language Processing (NLP) task: classifying the topics of news articles. Specifically, we follow the AG News task formulation, where articles are classified based on their title and their summary into one of four categories: ‚ÄúWorld‚Äù, ‚ÄúSports‚Äù, ‚ÄúBusiness‚Äù or ‚ÄúScience and Technology‚Äù. For example, consider the following sample of three examples from the AG News training set:
Examples of news article titles and summaries from the AG News training set, first introduced by
Zhang et al (2015)
and available online
here
The correct labels for examples 1-3 above are ‚ÄúBusiness‚Äù, ‚ÄúSports‚Äù and ‚ÄúWorld‚Äù, respectively.
Prompt Engineering Solution
Jurassic-1 language models are trained to predict likely continuations for a piece of input text, called a ‚Äúprompt‚Äù. We will use this ability to our advantage, by feeding the model with manually crafted prompts that give rise to a specific behavior in the model output; in our case, we‚Äôd like the model to output correct labels for articles. The practice of composing a suitable prompt for a specific task is commonly referred to as
‚Äúprompt engineering‚Äù
A common and effective prompt engineering approach is to construct a prompt containing a sequence of correctly labeled examples, often called a
‚Äúfew-shot prompt‚Äù
. The goal of a few-shot prompt is to cause the model to latch on to the correct relation between inputs (for our task - title and summary) and outputs (topic label).
We built a few-shot prompt for our use-case according to best practices, as described in detail in the
. We measured the accuracy of predictions on the AG News test set, while varying the number of examples in the prompt. The results are reported in the table below. Note that as we increase the number of examples, the models tend to perform better. This is typically the case with few-shot prompts. Using J1-Jumbo, we reach a respectable accuracy of 86% for a 16-example prompt.
AG News test set accuracy for Jurassic-1 models using prompt engineering while varying the number of examples in the prompt.
Why go beyond Prompt Engineering?
We were able to get impressive performance on our task with a very simple method and a tiny dataset of 16 examples (4 per class). This is excellent, but there are several reasons not to be content with our prompt engineering-based solution.
First and most obvious, few-shot prompts can become rather long as the number of examples is increased. This means that on each new prediction the model must read and process the entire prompt, increasing the compute time and resulting in
higher latency, energy consumption and cost per prediction.
Since adding examples to the prompt improves accuracy considerably, we are left with an inconvenient tradeoff between quality and cost, making it challenging to serve production-scale traffic with prompt engineering-based solutions.
Furthermore, language models have a maximum allowed input length. Jurassic-1 models can handle up to 2048 tokens (or roughly 2300-2500 English words), counting both the prompt and the generated text. Although impressive, this might not be enough in many cases. Imagine if instead of using a short summary of an article, we wanted to use the full article body as the input to our topic classification task. In such a case it would be hard to fit more than 1 or 2 examples into the prompt, so we wouldn‚Äôt have even one example per topic (recall we want to distinguish between 4 topics). Alternatively, had we needed to categorize article summaries into one of 100 potential topics, we would have had a similar problem.
Even if we make the most out of prompt engineering, we may require even better accuracy. Suppose we wanted to break the 90% barrier; judging by our results so far, this might be a tall order for prompt engineering.
Finally, we note that custom models have safety advantages. Since they are trained to perform a particular task, it is harder for a malicious user to abuse access to a custom model. We give an example of this in the
In the next section we introduce
custom models
as a more precise, scalable and cost-effective alternative to prompt engineering, which allows us to overcome the limitations described above.
Custom Model Solution
Custom models are specialized versions of the general purpose models which we have been using so far, trained to deliver optimal results on a given task. By combining our powerful Jurassic-1 language models with our special training techniques, AI21 Studio allows you to train a capable model using only a small amount of data, and makes it very easy to query your model once it‚Äôs trained.
To train a custom model of your own, all you need to do is provide us with a small dataset of correctly solved examples, and we will do the rest.
The quality of results you get from a custom model depends on the amount and the quality of training data you provide. As a starting point for most tasks, we recommend using 50-100 examples, since we find this is often enough to achieve great results. So, if you can get your hands on a few dozen examples, we recommend you try our custom models. Even if you don‚Äôt have data at all, we have a few tricks you can use - see the
Appendix
for more details.
To pick up where we left our topic classification case study, we trained custom models for AG News while varying the number of examples in the training set. The resulting accuracy on the AG News test set is shown in the table below. As you can see, with as few as 10 examples our custom model‚Äôs accuracy is comparable to J1-Large with a few-shot prompt. We also see that adding more training examples results in better accuracy for our custom model, surpassing J1-Jumbo‚Äôs few-shot performance with only 80 training examples.
AG News test set accuracy for custom Jurassic-1 models trained on datasets varying in size.
Custom models really start to shine when we take
latency
into consideration. Feeding the general purpose J1-Jumbo model with an engineered prompt consisting of 16 examples, we got an accuracy of 86%, and the typical processing time in this case is ~250 milliseconds. A custom model that matches or exceeds this accuracy only needs to process the summary and title of the individual example we‚Äôre labeling; there is no need to include a lengthy prompt in every request, because the task-specific behavior is already baked into the model. As a consequence, our custom model can process a typical request in less than 50 milliseconds, offering a
greater than 5x speedup
compared to prompt engineering
.
Appendix: Engineering the Prompt
An easy way to start engineering a prompt is to feed the model with simple instructions for the required task, such as the following:
To predict the label for a given article, we could input the text above followed by the article title, its summary, and a heading that prompts the model to output the correct label as a completion. The full prompt using this scheme follows below.
We can replace the text highlighted in blue with the relevant title and summary for any inference example we‚Äôd like to label and let the model generate a continuation after ‚ÄúThe topic of this article is:‚Äù. This is commonly referred to as a
‚Äúzero-shot prompt‚Äù
, because the model is expected to correctly perform the task without feeding it any correctly solved example. Using the prompt above, J1-Large has an accuracy of 32% and J1-Jumbo gets 56.9% on the AG News test set; although significantly better than a random guess accuracy, this leaves much to be desired.
The zero-shot approach can be improved upon by adding a number of correctly labeled examples to the prompt itself, making it a ‚Äú
few-shot prompt‚Äù
. Jurassic-1 models recognize and imitate patterns in text, so including a few solved examples in the prompt helps reinforce the desired relation between inputs (title and summary) and outputs (topic label); this usually improves prediction accuracy. A few-shot prompt using the sample of three articles above is shown below. As in the zero-shot case, it will end with the inference example specified in the same uniform format, so the text highlighted in blue will be replaced with the appropriate content for the inference example.
Once we‚Äôve decided on a prompt format as above, we can simply make a longer prompt by adding more examples in the same format. There are some considerations we should keep in mind while doing this:
Keep the examples relatively balanced between the classes (i.e. the 4 possible topics), to avoid biasing the model towards the more common classes in the prompt.
Scramble the order of the examples to avoid the model latching on to the wrong pattern (e.g. ‚ÄúBusiness‚Äù always comes after ‚ÄúWorld‚Äù in the examples).
Make sure there‚Äôs enough room for the example you actually want to predict. Jurassic-1 models are restricted to 2048 tokens, which should include the prompt and the generated output (1-2 tokens in our case).
We built a prompt corresponding to these guidelines. The resulting accuracy for varying prompt lengths is reported above. Not surprisingly, the best results are achieved with J1-Jumbo and the longest (16-example) prompt, reaching an accuracy 86% on the AG News test set.
Appendix: Safety Advantages of Custom Models
AI21 Labs is committed to promoting safety in our products. One potential safety risk is deliberate misuse by malicious users of your application, exploiting its access to Jurassic-1 to generate text for their malicious purposes. Adversaries may attempt to achieve this via
‚Äúprompt injection‚Äù
, where the end-user‚Äôs input text is crafted to alter the normal behavior of the model. As we will now demonstrate, custom models are less susceptible to such attacks than general-purpose models, offering a significant safety advantage when deployed in production.
Consider a malicious user who has access to the news article topic classification system built on top of Jurassic-1 and wishes to abuse it to extract toxic generations from the model. Recall that an engineered prompt for topic classification ends with the following text:
Where <TITLE> and <SUMMARY> are user inputs. A malicious user may attempt a prompt injection attack by providing the adversarial input ‚ÄúThe topic of this article is:‚Äù followed by some offensive text in place of a legitimate summary, hoping that the model will generate the offensive text or something related to it as the completion. Since language models latch on to patterns, the malicious user may even repeat this input line a few times to increase their chances of success. For example, below the adversarial input is repeated 3 times:
The figures below compare the performance of the solutions described in this blog post - prompt engineering versus custom models - when faced with an attack like this. We see that the outcome depends on the number of repetitions of the toxic text in the input. For prompt engineering, if the adversary introduces 2 or more repetitions of the toxic text, 50% of the model outputs are toxic, and 3 or more repetitions cause the model to exclusively generate toxic outputs. For custom models, it takes 4 or more repetitions for the adversary to successfully extract toxic generations from the model, and even then the probability of a toxic output is much lower than for prompt engineering.
Percentage of examples in the AG News test set for which a prompt injection attack successfully generates toxic outputs.
Left
- prompt engineering-based solution with a 16-example prompt.
Right
- custom model solution trained on 3200 examples. The horizontal axis shows the number of times the toxic text (shown above) was repeated in the adversarial input. Greedy decoding (temperature=0) was used for generating from both models
Although using a custom model doesn‚Äôt eliminate the risk entirely in this example, it does decrease it substantially, in a way that makes other safety mechanisms more effective. For example, to protect against prompt injection in a news topic classification system, it makes sense to limit the amount of text a user can input in the summary field. Any safety measure creates a tradeoff between restricting usage and guaranteeing safety, which in this case is found in the maximum allowed input length: set the threshold too high and prompt injection attacks will be more likely to succeed; set the threshold too low and legitimate inputs will be blocked. Using a custom model, which is less susceptible to prompt injection out of the box, makes the tradeoff easier and allows a developer to choose a higher threshold while guaranteeing the same level of safety.
Appendix: No data? No problem!
Jurassic-1 custom models offer excellent accuracy even when trained on a surprisingly small dataset. Nevertheless, sometimes even a small annotated dataset is hard to come by. Wouldn‚Äôt it be nice to enjoy the benefits of custom models without collecting
any
labeled data? As we will now demonstrate in our topic classification case study, this is possible.
First, we note two simple observations:
A prompt engineering solution with 1-4 examples per class achieves reasonable accuracy.
The model assigns a probability to the label it generates, which indicates its ‚Äúconfidence‚Äù in the label. High-confidence labels are more likely to be correct predictions.
Relying on these two observations, we propose the following simple approach:
Collect many unlabeled input examples for topic classification.
Use a prompt engineering-based solution to automatically label them with J1-Jumbo.
Filter the auto-labeled examples by confidence, resulting in a dataset of examples where the model assigns >85% probability to the labels it predicted. Make sure the different classes are equally represented in the dataset.
Train a custom model on the high-confidence auto-labeled dataset.
The table below shows the test set accuracy of custom models trained using this approach. We varied the number of labeled examples in the few-shot prompt, and used it to auto-label 160 examples for training. With just 4 labeled examples (1 per class), we beat J1-Jumbo‚Äôs accuracy with an engineered prompt containing 8 labeled examples. Using 16 labeled examples (4 per class) to auto-label a 160-example dataset, we not only beat J1-Jumbo but also match the performance of a custom model trained on 160
manually
labeled examples (88.5%).
AG News test set accuracy for custom Jurassic-1 models trained on 160 auto-labeled examples, while varying the number of manually labeled examples in the few-shot prompt used for auto-labeling. Accuracy of J1-Jumbo with a few-shot prompt utilizing the same amount of labeled data is shown for comparison.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
Tutorial
Zero-to-production: bootstrapping a custom model in AI21 Studio
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/zero-to-production-in-ai21-studio
Text Improvements API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Text Improvements API
Provides rewrite recommendations for improving the fluency, clarity and style of the input text.
With our
/improvements
API, you can access our industry-leading text enhancements engine. Since it was specifically designed for this task, it produces high-quality results while optimizing efficiency. Integrating this API into your writing platform will improve your users' writing, enhance their experience and elevate their final product. This is also the engine behind
Wordtune
- our
award winning writing assistant
, so you know it's pretty awesome.
undefined
Whether you're an NLP enthusiast or have no prior knowledge, this API is for you. There are many clever mechanisms under the hood, but you don't have to understand them (if you don't want to). As a task-specific API, you can easily integrate it into your systems and get top-notch text improvements in a matter of minutes, with no prompt engineering required. Additionally, since it's optimized for this purpose, it's significantly more efficient than building it from scratch, and an order of magnitude cheaper.
This API scans a piece of text to see if it can be improved. The different models behind it check for fluency, clarity, and vocabulary. In the event that it finds areas that need improvement (and only if it finds them), it will return a list of suggestions (with locations).
Let your users express themselves more fluently, phrasing the same message in a natural way.
Affiliated with the profession of project management, I have ameliorated myself with a different set of hard skills as well as soft skills.
Being involved in the profession of project management, I have developed a different set of hard skills as well as soft skills.
Make it easier for users to be more precise by recommending a more specific word to use within the context.
Good sleep
Full night's sleep
I ate a good pizza
I ate a tasty/delicious/yummy pizza
Allow your users to avoid multiple repetitions of the same
multiple
words.
mean
fat gain.
Positive energy balance means that you consume more energy than you burn. With the right types of foods this could mean muscle gain, with the wrong types it could
result
in fat gain.
Advise your users how to avoid long and convoluted sentences by splitting them into short sentences.
, so it
In addition, it is essential to build trust in their relationships, so they can start having efficient communications
. This
will allow them to give feedback and call their peers on their performance without the fear of interpersonal conflicts.
Make it easier for your users to be concise.
Before
After
We will arrive home in a period of five days
We will arrive home in five days
Imagine that you want to integrate the Text Improvements API into your writing platform where you perform the improvements automatically. To illustrate how you would do it, here is an example:
import ai21

ai21.api_key = 'YOUR_API_KEY'

response = ai21.Improvements.execute(text=""Affiliated with the profession of project management, I have ameliorated myself with a different set of hard skills as well as soft skills."",
                                                                   types=[""fluency""]
                                    )

// Use the improvements suggestions to fix the sentence
improved_text = text
improvements = response[""improvements""]
for curr_improvement in reversed(improvements):
    improved_text = improved_text[:curr_improvement[""startIndex""]] + curr_improvement['suggestions'][0] + improved_text[curr_improvement[""endIndex""]:]
And the fixed sentence:
Python
print(improved_text)

// As a member of the profession of project management, I have acquired a different set of technical skills as well as soft skills.
Table of Contents
Don‚Äôt just take our word for it, give it a go! üí´
Features
Speak with great
fluency
Feature description:
specificity
Enrich the text with
variety
Write simple with
short sentences
Conciseness
Examples",https://docs.ai21.com/reference/text-improvements-api
Email Protection | Cloudflare,"Email Protection | Cloudflare
Please enable cookies.
Email Protection
You are unable to access this email address
docs.ai21.com
The website from which you got to this page is protected by Cloudflare. Email addresses on that page have been hidden in order to keep them from being accessed by malicious bots.
You must enable Javascript in your browser in order to decode the e-mail address
If you have a website and are interested in protecting it in a similar way, you can
sign up for Cloudflare
.
How does Cloudflare protect email addresses on website from spammers?
Can I sign up for Cloudflare?
Cloudflare Ray ID:
7cc212165bd57142
Your IP:
Click to reveal
69.158.14.10
‚Ä¢
Performance & security by
Cloudflare",https://docs.ai21.com/cdn-cgi/l/email-protection#c8bba9aeadbcb188a9a1faf9e6aba7a5
Changelog,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Contexto m√°s largo in Contextual-Answers API
13 days ago
Contextual Answers API [Beta]
now supports an expanded context of 50,000 characters, allowing more text to be included in your source document. In addition, the API provides better support for multilingual capabilities, including Spanish, French, German, Portuguese, Italian and Dutch.
Transitioning to Jurassic-2: Important Updates on Model Retirements and Pricing Changes
We have a few updates to share regarding our Jurassic models at AI21 Studio:
Extending Context Window: Jurassic-2 Instruct Models Now Support 8K Tokens
22 days ago
We're thrilled to announce the extension of the 8K tokens support to our Jurassic-2 Instruct models, specifically J2-Grande-Instruct and J2-Jumbo-Instruct. These models, which are designed to meticulously follow instructions, can now accommodate a context window of 8,192 tokens, allowing for even more detailed and extensive interactions.
Fine-tuning Jurassic-2 models is now available!
Posted by Jack Yulzari
about 1 month ago
Custom model training on top of J2-Grande and J2-Large is now available.
improved
Increased Context Length for J2 Foundation Models
We are excited to announce that our Jurassic-2 Foundation models, including J2-Large, J2-Grande, and J2-Jumbo, now support an increased context length of up to 8K tokens (8192 tokens to be exact). This enhancement allows users to work with longer prompts and receive more comprehensive completions.
Contextual Answers API [BETA] Released
We are pleased to announce the release of the Contextual Answers API, a powerful tool for providing accurate and reliable question answering based on specific document context. This API is designed to avoid any factual issues that may arise when using language models to provide answers, and it receives document text and a question and returns an answer based solely on the provided context.
Introducing Wordtune-Powered Task-Specific APIs
about 2 months ago
We're thrilled to introduce our latest offering - the Task-Specific APIs package. This suite includes specialized language processing capabilities, making it effortless for you to integrate cutting-edge features into your systems. Our APIs are optimized and fine-tuned to ensure fast response times and high-quality results. We're proud to announce that all of our Task-Specific APIs are supported through our
Python SDK
, offering easy integration with your existing Python-based systems. These APIs are powered by the same engines behind our popular
Wordtune
products and include:
Jurassic-2 is now available
2 months ago
We are excited to announce the release of Jurassic-2 (J2), our latest and greatest series of Large Language Models. J2 builds upon the successes of Jurassic-1 and introduces new features and capabilities that set it apart from its predecessor.
New features in AI21 Studio: delete datasets & delete custom models
Posted by Yuval Belfer
Two new features are now available:
added
Python SDK is now available
Posted by Yotam Shinan
5 months ago
We are pleased to announce the availability of the
Python Software Development Kit
(SDK) for AI21 Studio's state-of-the-art natural language processing models, including the Jurassic-1 series and all specialized models.
1 of 2",https://docs.ai21.com/changelog?page=1
NEW: Overview page,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
NEW: Overview page
9 months ago
by Yuval Belfer
We have created a new Overview page to be the entry gate to our platform. With easy access to a set of premade examples (presets), API documentation and custom models, it should be a breeze to start working with our technology right away.
Here is a link to the
Overview
page.",https://docs.ai21.com/changelog/new-overview-page-1
Jurassic-1 Instruct is now available!,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Jurassic-1 Instruct is now available!
6 months ago
by Yuval Belfer
Jurassic-1 Instruct, our instruction-following language model, is now available in open beta! ü¶ñ
Based on the Jurassic-1 Grande, Jurassic-1 Instruct was trained specifically to handle instructions-only prompts (""zero-shot"") that do not require examples (""few-shot""). It is the most natural way to interact with large language models: simply enter a short prompt instructing the model what to do, and get a concise answer from the model.
Here‚Äôs an example of what Instruct can do - the World Cup. Even if you‚Äôre not a soccer fan, you can be part of the group. Ask Jurassic-1 Instruct to come up with a relevant soccer tweet:
Try it out and discover the power of zero-shot prompting!
Try it yourself
Despite being in open beta, the Jurassic-1 Instruct displays phenomenal capabilities, and will continue to improve over time.
We hope you'll enjoy using Jurassic-1 Instruct.",https://docs.ai21.com/changelog/jurassic-1-instruct-is-now-available
Introducing Rewrite API & Summarize API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Introducing Rewrite API & Summarize API
7 months ago
by Yuval Belfer
We are excited to announce the launch of two specialized APIs from AI21 Studio: Rewrite API and Summarize API. Developed by our experts, these top-notch NLP models are designed to handle the complex tasks of paraphrasing and summarization accurately. All that‚Äôs left is to integrate them into your product and let the magic happen üîÆ‚ú®üí´
With Rewrite API, you can paraphrase text to use different wording, style and tone. Give your users superpowers by integrating an AI co-writer into your app.
See it in action:
Try Rewrite
With Summarize API, you can compress documents into short summaries. Extract insights from social media discourse, online reviews, organizational knowledge bases and more.
Here's a glimpse
Try Summarize
The current pricing model for Rewrite API is available
here
. While we finalize the Summarize API pricing, you can use it for free (knock yourself out üòâ).
There's never been an easier way to use NLP! We can't wait to see what you'll build ü§ì",https://docs.ai21.com/changelog/launching-rewrite-api-and-summarize-api-to-open-beta
NEW: Delete custom presets and datasets,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
NEW: Delete custom presets and datasets
7 months ago
by Yuval Belfer
Two new features are included in this update: custom presets can be deleted and uploaded datasets can be deleted. Both of these features are extremely useful for anyone who has a large number of assets and wishes to organize them as well as remove older assets from their collections.
To delete a preset, go to the Playground page and click the ""Presets"" dropdown. You will see a ""Delete"" button next to each custom preset, grouped under ""My Presets"".
To delete a dataset, go to the Datasets page and click the ""Delete"" button next to the dataset.",https://docs.ai21.com/changelog/new-delete-preset
A new version of AI21's documentation platform has been released!,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
improved
A new version of AI21's documentation platform has been released!
6 months ago
by Yuval Belfer
The new documentation platform introduces more information on the use of our large language models, how to use our APIs, example recipes, and more!
By having all the information gathered in one place, you should be able to gain a comprehensive understanding of our platform. It is our hope that it will make the process of utilizing our technology easier for you.
As a result of having a robust but flexible documentation platform, we are able to keep up and continue to update our guides and API references with each new feature and capability we introduce.",https://docs.ai21.com/changelog/a-new-version-of-ai21s-documentation-platform-has-been-released
"Small yet useful new features for preset management, documentation and customer support","Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Back to All
added
Small yet useful new features for preset management, documentation and customer support
6 months ago
by Jack Yulzari
We've added three small but useful features in this update.
As Roy T. Bennett, author of ‚ÄúThe Light in the Heart‚Äù, wrote: ‚Äú
You make the world a better place by making daily improvements to become the best version of yourself
.‚Äù
In the Rewrite and Summarize APIs, you can delete your customized presets if you find that you no longer need them. In addition, in the top navigation, we have included a question mark (help) icon that opens up a live chat window with our customer service department.
As part of the third update, we have now added a search option to the live chat window, enabling you to search our documentation, guides, API reference, and more. This new search option will save you time and help you get the answers you need more quickly and easily.",https://docs.ai21.com/changelog/small-yet-useful-new-features-for-preset-management-documentation-and-customer-support
Tokenize,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
https://api.ai21.com
/studio/v1/tokenize
Words to tokens in a single click
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/tokenize-ref
J-1 Grande Instruct [beta],"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
Other
Tokenize API
Tokenize
J-1 Grande Instruct [beta]
post
https://api.ai21.com
/studio/v1/experimental/j1-grande-instruct/complete
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/jurassic-1-instruct-beta-1
Contextual Answers API [BETA],"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Contextual Answers API [BETA]
Try Contextual Answers API
here
The Contextual Answers API is a tool for providing accurate and reliable question answering based on specific document context. This API is designed to avoid any factual issues that may arise when using language models to provide answers. It receives document text and a question and returns an answer based solely on the provided context. This means that if the answer to a question is not in the document, the model will indicate this rather than providing a potentially inaccurate answer. As a task-specific API, it is optimized for efficiency and can be easily integrated into existing systems without requiring any prompt engineering. Overall, the Contextual Answers API provides a user-friendly and efficient solution for accurate and context-based question answering.
The Contextual Answers API requires two parameters for a successful request:
context
: A string containing the document context for which the question will be answered.
question
: A string containing the question to be answered based on the provided context.
The Contextual Answers API returns the following parameter in its response:
answer
: A string containing the answer to the question based on the provided context. The answer will be null if the model cannot find an answer in the provided context.
id
: A unique identifier assigned by the API to identify the specific request that generated the response. This parameter can be useful for tracking and logging purposes, particularly if multiple requests are being made to the API.
Python
payload = {
    ""context"": ""In 2020 and 2021, enormous QE ‚Äî approximately $4.4 trillion, or 18%, of 2021 gross domestic product (GDP) ‚Äî and enormous fiscal stimulus (which has been and always will be inflationary) ‚Äî approximately $5 trillion, or 21%, of 2021 GDP ‚Äî stabilized markets and allowed companies to raise enormous amounts of capital. In addition, this infusion of capital saved many small businesses and put more than $2.5 trillion in the hands of consumers and almost $1 trillion into state and local coffers. These actions led to a rapid decline in unemployment, dropping from 15% to under 4% in 20 months ‚Äî the magnitude and speed of which were both unprecedented. Additionally, the economy grew 7% in 2021 despite the arrival of the Delta and Omicron variants and the global supply chain shortages, which were largely fueled by the dramatic upswing in consumer spending and the shift in that spend from services to goods. Fortunately, during these two years, vaccines for COVID-19 were also rapidly developed and distributed.In today's economy, the consumer is in excellent financial shape (on average), with leverage among the lowest on record, excellent mortgage underwriting (even though we've had home price appreciation), plentiful jobs with wage increases and more than $2 trillion in excess savings, mostly due to government stimulus. Most consumers and companies (and states) are still flush with the money generated in 2020 and 2021, with consumer spending over the last several months 12% above pre-COVID-19 levels. (But we must recognize that the account balances in lower-income households, smaller to begin with, are going down faster and that income for those households is not keeping pace with rising inflation.) Today's economic landscape is completely different from the 2008 financial crisis when the consumer was extraordinarily overleveraged, as was the financial system as a whole ‚Äî from banks and investment banks to shadow banks, hedge funds, private equity, Fan
...Text Truncated...

The following is a possible response from the Contextual Answers API to the example request above:
JSON
{
  ""id"": ""36d2ec63-ef15-2296-af51-ef34206fc655"",
  ""answer"": ""The Delta and Omicron variants and the global supply chain shortages did not slow down economic growth.""
}
Table of Contents
Request Parameters
Response Parameters
Example",https://docs.ai21.com/reference/contextual-answers-api-ref
Contextual Answers,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Contextual Answers
post
https://api.ai21.com
/studio/v1/experimental/answer
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/contextual-answers-ref
J-1 Complete,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
J-1 Complete
post
https://api.ai21.com
/studio/v1/j1-
{model_type}
/complete
ü§ñ Generate text using Complete API
Set up
To install the SDK, run the following command:
Terminal
$ pip install -U ai21
API Keys
You can find your API key
API keys can be set globally using ai21.api_key, like so:
import ai21
ai21.api_key = <YOUR_API_KEY>
Build a prompt
We recommend following our
Prompt Engineering
best practices for optimal results.
You can try ""Zero Shot"" prompt:
prompt = ""These are a few of my favorite""
Or, ""Few Shot"" prompt:
prompt = """"""
Complete the following sentence.
Sentence: These are a few of my favorite
Completion: things. Cream-colored ponies and crisp apple strudels.

##

Complete the following sentence.
Sentence: These are a few of my favorite
Completion: rock bands: The Beatles, The Doors, Fleetwood Mac.

##

Complete the following sentence.
Sentence: These are a few of my favorite
Completion:
""""""
Test this API
You can generate a text completion for a given text prompt by posting an HTTP request to the complete endpoint corresponding to the desired language model to use. The request contains the input text, called a prompt and various parameters controlling the generation. For authentication, you must include your API key in the request headers. A complete response contains the tokenized prompt, the generated text(s), called completion(s), and various metadata. The request and response specifications are documented in full
here
.
Language
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/j1-complete
Text Segmentation,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Text Segmentation
post
https://api.ai21.com
/studio/v1/segmentation
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/text-segmentation-ref
Summarize,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Summarize
post
https://api.ai21.com
/studio/v1/summarize
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/summarize-ref
Text Segmentation API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Text Segmentation API
Try Text Segmentation API
here
Using the Text Segmentation API, you can intelligently segment text into coherent and readable units, based on distinct topics and lines. This allows for easy breakdown of long text into manageable chunks of text. The API supports both raw text and URLs of webpages as input sources, and it uses the same advanced engine as
Wordtune Read
, ensuring high-quality segmentation results.
source
: Raw input text, or URL of a web page.
sourceType
: The type of the above - either
TEXT
or
URL
.
Python
payload = {
    ""source"": ""https://www.ai21.com/blog/summarizing-legal-documents-for-different-personas-using-ai21-studio"",
    ""sourceType"": ""URL""
}
The following is the expected response for the example request above:
JSON
{
  ""id"": ""3f4d8be1-3a7f-9d67-c395-66188f72e6c5"",
  ""segments"": [
    {
      ""segmentText"": ""Create your own custom summarizer using AI21 Studio's large language models. This tutorial demonstrates the process on legal documents."",
      ""segmentType"": ""other""
    },
    {
      ""segmentText"": ""We‚Äôve all experienced reading long, tedious, and boring pieces of text - financial reports, legal documents, or terms and conditions (though, who actually reads those terms and conditions to be honest?).\n\nImagine a company that employs hundreds of thousands of employees. In today's information overload age, nearly 30% of the workday is spent dealing with documents. There's no surprise here, given that some of these documents are long and convoluted on purpose (did you know that reading through all your privacy policies would take almost a quarter of a year?). Aside from inefficiency, workers may simply refrain from reading some documents (for example, Only 16% of Employees Read Their Employment Contracts Entirely Before Signing!). \n\nThis is where AI-driven summarization tools can be helpful: instead of reading entire documents, which is tedious and time-consuming, users can (ideally) quickly extract relevant information from a text. With large language models, the development of those tools is easier than ever, and you can offer your users a summary that is specifically tailored to their preferences."",
      ""segmentType"": ""normal_text""
    },
    {
      ""segmentText"": ""Let's take legal documents, for example. Though they are written in English, many people find legal documents to be difficult to comprehend, as if they were actually written in a foreign language. Moreover, the interesting parts of each document may differ depending on the person who reads it, so off-the-shelf summarization tools may be too general or too specific. As an example, let's look at the involved personas:"",
      ""segmentType"": ""normal_text""
    },
    {
      ""segmentText"": ""Lawyers. They are
...Text Truncated...

Table of Contents
Simple API request",https://docs.ai21.com/reference/text-segmentation-api-ref
Summarize API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Summarize API
Try Summarize API
here
The Summarize API from AI21 Studio gives you the ability to use our advanced summarization engine, which has been specially calibrated for summarization tasks. Due to its optimization for this specific purpose, it is simpler to integrate into your systems, more efficient, and less costly than developing a summarization engine from the ground up. Additionally, it is the same engine powering
Wordtune Read
, so you can rest assured of its impressive performance.
With only 2 required parameters in the payload, using this API is as simple as it gets:
source
: The input text, or URL of a web page to be summarized.
sourceType
: The type of the above - either
TEXT
or
URL
.
To get a more customized summarization, you also have an optional parameter:
focus
: Return only summaries focused on a topic of your choice. Up to 50 characters.
Python
payload = {
    ""source"": ""We‚Äôve all experienced reading long, tedious, and boring pieces of text - financial reports, legal documents, or terms and conditions (though, who actually reads those terms and conditions to be honest?).  Imagine a company that employs hundreds of thousands of employees. In today's information overload age, nearly 30% of the workday is spent dealing with documents. There's no surprise here, given that some of these documents are long and convoluted on purpose (did you know that reading through all your privacy policies would take almost a quarter of a year?). Aside from inefficiency, workers may simply refrain from reading some documents (for example, Only 16% of Employees Read Their Employment Contracts Entirely Before Signing!).   This is where AI-driven summarization tools can be helpful: instead of reading entire documents, which is tedious and time-consuming, users can (ideally) quickly extract relevant information from a text. With large language models, the development of those tools is easier than ever, and you can offer your users a summary that is specifically tailored to their preferences.  Let's take legal documents, for example. Though they are written in English, many people find legal documents to be difficult to comprehend, as if they were actually written in a foreign language. Moreover, the interesting parts of each document may differ depending on the person who reads it, so off-the-shelf summarization tools may be too general or too specific. As an example, let's look at the involved personas:"",
    ""sourceType"": ""TEXT""
}
The following is a possible response for the example request above:
JSON
{
  ""id"": ""4f4acb3a-bfb5-a35c-99e5-0be572d97835"",
  ""summary"": ""In today's information overload age, nearly 30% of the workday is spent dealing with documents. AI-driven summarization tools can help users quickly extract relevant information from a text, and can be tailored to their preferences.\nLegal documents are written in English, but many people find them difficult to comprehend. Off-the-shelf summarization tools may be too general or too specific.""
}
Table of Contents
Simple API request",https://docs.ai21.com/reference/summarize-api-ref
Text Improvements API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Text Improvements API
Try the Text Improvements API
here
By using our Text Improvement API, you can access our state-of-the-art recommendations engine, which is optimized for generating high-quality results efficiently. Integrating this API into your writing platform can enhance your users' writing experience and elevate their final product. As part of the engine behind
Wordtune
, our Text Improvement API is a powerful tool you can trust.
Python
payload = {
    ""types"": [""fluency"", ""vocabulary/specificity""],
    ""text"": ""Affiliated with the profession of project management, I have ameliorated myself with a different set of hard skills as well as soft skills""
}
The following is a possible response from the Improvements API to the example request above:
JSON
{
  ""id"": ""e0426d4c-4f63-e6bd-addb-6c617d86bb02"",
  ""improvements"": [
    {
      ""suggestions"": [
        ""As a project manager, I have acquired"",
        ""As a member of the project management profession, I have acquired"",
        ""Due to my association with the project management profession, I have acquired""
      ],
      ""startIndex"": 0,
      ""endIndex"": 84,
      ""originalText"": ""Affiliated with the profession of project management, I have ameliorated myself with"",
      ""improvementType"": ""fluency""
    },
    {
      ""suggestions"": [
        ""technical"",
        ""practical"",
        ""analytical""
      ],
      ""startIndex"": 104,
      ""endIndex"": 108,
      ""originalText"": ""hard"",
      ""improvementType"": ""vocabulary/specificity""
    }
  ]
}
The response body includes an array of suggested
improvements
. Each item in the array is an object with the following fields:
suggestions
: A list of suggestions for improving the input text, which may be for the entire text or a portion of it.
startIndex
: The index indicating the beginning of the input text that the API suggests to improve.
endIndex
: The index indicating the end of the input text that the API suggests to improve.
originalText
: The specific text portion suggested for improvement by the API.
improvementType
: The type of improvement that the API suggests, which can be:
fluency
vocabulary/specificity
vocabulary/variety
clarity/short-sentences
clarity/conciseness
Table of Contents
Example",https://docs.ai21.com/reference/text-improvements-api-ref
Grammatical Error Corrections,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Grammatical Error Corrections
post
https://api.ai21.com
/studio/v1/gec
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/gec-ref
Grammatical Error Corrections API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Grammatical Error Corrections API
Try Grammatical Error Corrections API
here
With our Grammatical Error Corrections (GEC) API, you can tap into our advanced GEC engine, purpose-built and expertly tuned for this task. By integrating the
Wordtune
API into your writing platform, you can give your users the confidence to write without worrying about grammar. This API is one of Wordtune's major backbones, which speaks to its quality.
Using the GEC API is straightforward: simply send the text to the API and receive a list of every grammar error, complete with its location and suggested corrections.
Using a quote from Winnie the Pooh as an example, imagine that we've inserted it into the text parameter but made some mistakes:
Python
payload = {
  ""text"": ""It is is more fun to talk with someone who doesnt use long, difikolt words but rather short, easy words like, ‚ÄòWhat about lunch""
}
The GEC API can identify and suggest corrections for these errors.
Following is the expected response:
JSON
{
  ""id"": ""e6360a99-701b-813b-7296-f08057918320"",
  ""corrections"": [
    {
      ""suggestion"": ""It is"",
      ""startIndex"": 0,
      ""endIndex"": 8,
      ""originalText"": ""It is is"",
      ""correctionType"": ""Word Repetition""
    },
    {
      ""suggestion"": ""doesn't"",
      ""startIndex"": 43,
      ""endIndex"": 49,
      ""originalText"": ""doesnt"",
      ""correctionType"": ""Grammar""
    },
    {
      ""suggestion"": ""difficult"",
      ""startIndex"": 60,
      ""endIndex"": 68,
      ""originalText"": ""difikolt"",
      ""correctionType"": ""Spelling""
    },
    {
      ""suggestion"": ""lunch?"",
      ""startIndex"": 122,
      ""endIndex"": 127,
      ""originalText"": ""lunch"",
      ""correctionType"": ""Punctuation""
    }
  ]
}
As you can see, the response includes 4 corrections to mistakes found in the given text - Each correction is returned as an object with the following fields:
suggestion
: the suggested correction.
startIndex
starts
endIndex
: the index at which the correction process
ends
within the provided text.
originalText
: the text where the mistake was identified.
correctionType
: a required field that specifies the type of correction suggested by the GEC API.
The possible types of correction are
Grammar
Missing Word
Punctuation
Spelling
,
Word Repetition
, and
Wrong Word
.",https://docs.ai21.com/reference/gec-api-ref
Paraphrase API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Paraphrase API
Try Paraphrase API
here
AI21 Studio's Paraphrase API offers access to our state-of-the-art paraphrasing engine. It has been fine-tuned specifically for paraphrasing. As a result, it's easier to integrate into your systems, and since it's optimized for this purpose, it's also more efficient (and therefore cheaper) than building it from scratch. This is also the engine behind
Wordtune
- so you know it's pretty awesome.
This API takes a piece of
text
and returns a list of paraphrases that convey the same meaning using different words. As a specialized API for paraphrasing, it contains features to enable you more control over the output: adjust the tone and style, with the choice of rewriting only parts of a text (while keeping the whole context).
This API will return a list of up to 10 suggested paraphrases with every request.
Python
""style"": ""general"",
    ""text"": ""You only live once, but if you do it right, once is enough.""
For example, here's a possible response for the request above:
JSON
{
  ""id"": ""862829b2-29be-c86d-370e-db2f7f5dbf5b"",
  ""suggestions"": [
    {
      ""text"": ""One life is enough if you live it right.""
    },
    {
      ""text"": ""When you do it right, you only live once.""
    },
    {
      ""text"": ""Once is all you have, but if you do it right, once is enough.""
    },
    {
      ""text"": ""When you live right, you only need to live once.""
    },
    {
      ""text"": ""One life is enough if you live it right, but if you don't do it right, one life is not enough.""
    },
    {
      ""text"": ""The only chance you have to live is once, but if you live well, a once is enough.""
    },
    {
      ""text"": ""The only way to live is right, so if you do it right, once is enough.""
    },
    {
      ""text"": ""Once is enough if you live it right, but if you do it wrong, you'll regret it later.""
    },
    {
      ""text"": ""In life, you only live once, but if you do it right, once should be plenty.""
    },
    {
      ""text"": ""It takes only one life to live a fulfilling life, but if you do it right, one life is enough.""
    }
  ]
}
You have the choice between 4 different styles:
general
- explore fresh new ways to rephrase your sentences.
casual
- convey a lighter and less serious tone for the right audience.
formal
- present your words in a more professional way.
long
- expand your sentences to give more detail, nuance and depth.
short
- stick to word limits and convey your messages clearly and concisely.
You can paraphrase a specific span within the given text while keeping the surrounding text unchanged by specifying locations, using the
startIndex
and
endIndex
parameters. The API aims to rewrite exactly the requested span while avoiding disfluent suggestions. Satisfying both requirements is not always possible.
Table of Contents
Up to 10 suggested paraphrases
Choose a
style
that fits your needs
Paraphrase within your span",https://docs.ai21.com/reference/paraphrase-api-ref
Paraphrase,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Paraphrase
post
https://api.ai21.com
/studio/v1/paraphrase
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/paraphrase-ref
Update Default Epoch,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Update Default Epoch
put
https://api.ai21.com
/studio/v1/custom-model/
{custom_model_id}
Update a custom model's default epoch.
This method currently supports a single variable,
defaultEpoch
, in its request body, allowing you to change the default epoch for the custom model. By updating the default epoch, you can customize the model's behavior for processing requests without specifying an epoch explicitly. Additionally, changing the default epoch also updates the evalLoss value, ensuring that the evaluation loss reflects the updated epoch configuration, providing you with accurate information on the model's performance.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/update-default-epoch
Text Improvements,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Text Improvements
post
https://api.ai21.com
/studio/v1/improvements
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/text-improvements-ref
Custom Model Complete,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Custom Model Complete
post
https://api.ai21.com
/studio/v1/
{model_type}
/
{model_name}
/complete
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/custom-jurassic-complete
Get Custom Model,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Get Custom Model
get
https://api.ai21.com
/studio/v1/custom-model/
{custom_model_pid}
Get a custom model by id.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/get-custom-model
Auxiliary Tuning and its Application to Conditional Text Generation,"Company
About
Ask RBG
Start building
Publications
Auxiliary Tuning and its Application to Conditional Text Generation
We designed a simple and efficient method, called Auxiliary Tuning, for adapting a pre-trained Language Model (LM) to a novel task, and demonstrated the approach on the task of conditional text generation.
Read Technical Paper
What we did
We designed a simple and efficient method, called Auxiliary Tuning, for adapting a pre-trained Language Model (LM) to a novel task, and demonstrated the approach on the task of conditional text generation. Our approach supplements the original pre-trained model with an auxiliary model that shifts the output distribution according to the target task.
Why it matters
Achieving state-of-the-art fluency in language tasks such as text generation entails
costly training of large LMs
. Auxiliary Tuning allows practitioners to amortize this cost across target tasks by leveraging existing pre-trained LMs. This is done without modifying the pre-trained weights, avoiding the risks of rigidity and catastrophic forgetting, and allowing natural scaling to multiple target tasks.
How it works
The auxiliary model is trained by adding its logits to the pre-trained model logits and maximizing the likelihood of the target task output. Our method imposes no constraints on the auxiliary architecture. In particular, the auxiliary model can ingest additional input relevant to the target task, independently from the pre-trained model‚Äôs input. Furthermore, mixing the models at the logits level provides a natural probabilistic interpretation of the method.
Results
We tested Auxiliary Tuning on a number of different conditional text generation tasks. Adapting a pre-trained LM using our method resulted in similar performance to training a comparable model on the target task from scratch, while using significantly less compute for training.  Below we present results for a text generation task conditioned on keywords, where the generated text has to include the keyword provided to the model. We show that our method achieves similar accuracy (the fraction of samples that contain the keyword that we conditioned on) compared to a naive autoregressive Transformers baseline. Interestingly, our method generates fluent samples early in training, demonstrating its effectiveness of harnessing the fluency of the pre-trained model (as measured by
SLOR
).
Related methods
Auxiliary Tuning is related to, but different from, fine-tuning,
few-shot learning, Plug-and-Play Language Model (PPLM)
and
side-tuning
. For details, see the technical report.
 
ABOUT THE AUTHOR
Yoel Zeldes, Dan Padnos, Or Sharir and Barak Peleg
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/news/auxiliary-tuning-and-its-application
Get Datasets List,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Get Datasets List
get
https://api.ai21.com
/studio/v1/dataset
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/dataset-list
Exemplar Guided Active Learning,"Company
About
Ask RBG
Start building
Publications
Exemplar Guided Active Learning
Exemplar Guided Active Learning (EGAL) is a method we developed to economically annotate training data for tasks with extremely skewed label distributions, such as disambiguating rare word senses.
Read Technical Paper
Presented at NeurIPS 2020
 
ABOUT THE AUTHOR
Jason Hartford, Kevin Leyton-Brown, Hadas Raviv, Dan Padnos, Shahar Lev and Barak Lenz
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/news/exemplar-guided-active-learning
SenseBERT: Driving some sense into BERT,"Company
About
Ask RBG
Start building
Publications
SenseBERT: Driving some sense into BERT
We enrich the self-supervision strategy employed in BERT by applying self-supervision on the Word-Sense level. Our model, SenseBERT, achieves significantly improved lexical disambiguation abilities, setting state-of-the-art results on the Word in Context (WiC) task.
Read the paper
Presented at ACL 2020
Self-supervision for Pre-trained Language Models
The use of self-supervision has allowed neural language models to advance the frontier in Natural Language Understanding. Specifically, the self-supervision strategy employed in BERT, which involves masking some of the words in an input sentence and training the model to predict them given their context, results in a versatile language model suited for many tasks. Nevertheless, existing self-supervision methods operate on the word-form level, and as such, they are inherently limited. Take the word ‚Äòbass‚Äô as an example: in one context it can refer to a fish, in a second to a guitar, in the third to a type of singer, and so on. The word itself is merely a surrogate of its actual meaning in a given context - referred to as its
sense
.
Word-Sense predictions made by SenseBERT on a raw input text.
The word ""Bass"" maps to its different supersenses according to context.
SenseBERT - Pre-training on Word Senses
We propose a method to employ self-supervision directly at the word sense level. Our model, named
SenseBERT
, is pre-trained to predict not only the masked words (as in BERT) but also their WordNet supersenses. BERT‚Äôs current word-form level objective leads to what is commonly referred to as a language model: the model predicts words for the given masked position in a sentence. Our added task allows SenseBERT to gather word-sense level statistics and thereby we effectively train a semantic-level language model that predicts the missing word‚Äôs meaning jointly with the standard word-form level prediction.
Self-supervision allows neural language models to learn from massive amounts of unannotated text. In order to enjoy this advantage at the lexical-semantic level, we make use of WordNet - an expert-constructed ontology that provides an inventory of word senses. We focus on a coarse-grained variant of word senses, referred to as supersenses, divided into 45 types that semantically categorize the entire language.
Labeling of words with a single supersense, for example the word ‚Äòsword‚Äô which has only the supersense ‚Äòartifact‚Äô, is straightforward: We train the network to predict this supersense given the masked word‚Äôs context. As for words with multiple supersenses (like the word ‚Äòbass‚Äô we discussed earlier), we train the model to predict any of these senses, leading to a simple yet effective labeling scheme.
Other than our additional pre-training task and the architecture changes that support it, we followed the architecture and training methods published in the BERT paper. Specifically, we trained models in two sizes, similar to BERT model sizes - SenseBERTBASE and SenseBERTLARGE. Our results below show significantly enhanced word meaning understanding abilities of SenseBERT, achieved without human annotation.
Word-Sense predictions made by SenseBERT on the masked word in the sentence.
Results
  
In order to test our model‚Äôs lexical semantic abilities, we compared it with BERT on two tasks:
1.  SemEval Word Superense Disambiguation
We constructed a supersense variant of the SemEval-based WSD task, where the goal is to predict a word‚Äôs supersense given context.
We trained and tested in two different schemes:
A ‚ÄúFrozen‚Äù model with a linear classifier on top (to explore the sense information captured in the model‚Äôs pre-trained embeddings).
A ‚ÄúFine-Tuned‚Äù model, where the network weights have been modified during training.
SenseBERTBASE outscores both BERTBASE and BERTLARGE models by a large margin in both cases, and SenseBERTLARGE yields even higher results.
2.  Word in Context (WiC)
 
The Word in Context (WiC) task, from the SuperGLUE benchmark, is the task of predicting whether a word has the same meaning in two given sentences. This task heavily depends on word-supersense awareness.
SenseBERTBASE surpasses BERTLARGE, and a single SenseBERTLARGE model achieves state-of-the-art performance on this task with a score of 72.14.
 
ABOUT THE AUTHOR
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/news/sensebert-driving-some-sense-into-bert
Get Custom Models List,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Model
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Get Custom Models List
get
https://api.ai21.com
/studio/v1/custom-model
See all your available custom models.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/get-custom-models-list
Delete Dataset,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Delete Dataset
delete
https://api.ai21.com
/studio/v1/dataset/
{dataset_pid}
Delete a dataset by id.
You can use the
Get datasets list
endpoint to retrieve all of your datasets IDs.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/delete-dataset
Grounding Language Models In-Context: Improving Text Generation and Attribution for Off-the-Shelf LMs,"Company
About
Ask RBG
Start building
Publications
Grounding Language Models In-Context: Improving Text Generation and Attribution for Off-the-Shelf LMs
Text generation via language models (LMs) is dramatically improving, but LMs do not attribute their generated text to its sources and can often make mistakes. We propose the simple framework of ùòêùòØ-ùòäùò∞ùòØùòµùò¶ùòπùòµ ùòôùò¶ùòµùò≥ùò™ùò¶ùò∑ùò¢ùò≠ ùòàùò∂ùò®ùòÆùò¶ùòØùòµùò¶ùò• ùòìùò¢ùòØùò®ùò∂ùò¢ùò®ùò¶ ùòîùò∞ùò•ùò¶ùò≠ùò¥, which allows for grounding ùò¢ùòØùò∫ ùò∞ùòßùòß-ùòµùò©ùò¶-ùò¥ùò©ùò¶ùò≠ùòß ùòìùòî in knowledge from external sources, and attributing the text it generates to its sources.
Recent advances in language modeling have dramatically increased the usefulness of machine-generated text across a wide range of use-cases and domains. An outstanding Achilles‚Äô heel of LM generated text is that it is not attributed to a specific source, and often includes factual inaccuracies or errors. This problem is present in any LM generation scenario, and is exacerbated when generation is made in uncommon domains, or when it involves up-to-date information that the LM has not seen during training. A promising approach for addressing this challenge is Retrieval-Augmented Language Modeling (RALM), grounding the LM during generation by conditioning on relevant documents retrieved from an external knowledge source.
Leading RALM systems introduced in recent years tend to be focused on altering the language model architecture, and the need for changes in architecture and dedicated retraining has hindered the wide adoption of such models.
Thus, while the RALM approach bears potential to alleviate factual inaccuracies and to provide direct sources for the generated text, it is in practice not deployed alongside leading LMs.
In our paper
, we present In-Context RALM: a simple yet powerful RALM method which can be used for endowing any off-the-shelf LM with access to external knowledge sources. In-Context RALM simply inserts the retrieved document to a regular LM‚Äôs input, rendering it applicable even for LM behind API . While existing works choose which documents to show the LM via standard general purpose approaches, we propose several novel methods for grounded generation oriented document selection.
 
Our simple and easily deployable setup allows improving the language modeling abilities of off-the-shelf LMs to those equivalent to increasing the LM's number of parameters by 4X
, across a diverse evaluation set of five text corpora. We believe that further gains can be achieved via developing the generation-oriented retrieval mechanism, while retaining the straightforward document insertion mechanism of RALM.
To help others both to deploy and to build upon our work, our paper is accompanied by an online release of all our code, datasets, trained models, and indexes for our standardized suite of corpora.
ABOUT THE AUTHOR
Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/news/grounding-language-models-in-context
PMI-Masking,"Company
About
Ask RBG
Start building
Publications
PMI-Masking
We present a masking strategy that makes bidirectional masked-LM training more educating.
In a Nutshell
In recent work described by an ICLR 2021
spotlight paper
, we show how to replace BERT‚Äôs random input masking strategy during pretraining with PMI-Masking, which jointly masks neighboring tokens if they exhibit high correlation over the pretraining corpus. By preventing the model from focusing on shallow local signals, PMI-Masking achieves better representations at a fraction of the training budget. Despite altering only the input masking strategy, PMI-Masking achieves the same BERT pretraining quality in one sixth the time and achieves significantly better pretraining within the same training budget.
Masking: BERT‚Äôs Added Degree of Freedom
Before BERT, neural Language Models (LMs) tended to be autoregressive, learning to predict each input token given preceding text. The Masked Language Model (MLM) training objective of BERT, for which the model learns to predict a masked subset of the input tokens, creates an inherently bidirectional representation of text. But this bidirectionality comes with an added degree of freedom relative to classical autoregressive LMs: choosing which tokens to mask and which to show.
Our paper highlights that not all bidirectional dependencies are equal: we show that the strategy for choosing which tokens to mask and which to show can profoundly impact an MLM‚Äôs performance. Specifically, we show that the standard practice of random uniform masking often allows an MLM to minimize its training objective by latching onto shallow local signals, leading to pretraining inefficiency and suboptimal downstream performance. By limiting the model‚Äôs ability to rely on such shortcuts, we obtain the same pretraining performance more quickly and better performance within a fixed training budget.
PMI-Masking speed-up and improvement relatively to existing approaches on RACE.
A Motivating Example
To see the potential harm of local signals, we offer a simple, motivating example of neighboring tokens that are highly correlated with each other: part-of-word tokens that make up the same word. Recall that BERT represents text as a sequence of tokens, where each token is either a word or a part-of-word; e.g., ‚Äúchair‚Äù might constitute a single token while rarer words like ‚Äúeigenvalue‚Äù do not make it into BERT‚Äôs vocabulary and are broken up into several part-of-word tokens (‚Äúe-igen-val-ue‚Äù).
When using BERT‚Äôs regular vocabulary size of 30K tokens, the vast majority of encountered words are represented by single tokens (words are represented via ~1.1 tokens on average). However, when we artificially decrease the vocabulary size to 10K and then to 2K tokens, along the x axis of the following plot, part-of-word tokens become much more common (up to ~2 tokens-per-word on average).
The blue curve in the above figure shows that when applying BERT‚Äôs strategy of choosing 15% of the tokens for masking uniformly at random, the model's performance is severely degraded as part-of-word tokens become prevalent. Thus, by controlling the number of highly correlated tokens, we demonstrate that strong dependencies between neighboring input tokens can harm the model‚Äôs ability to learn from broader context. In the presence of such dependencies, the MLM‚Äôs objective can often be minimized simply by considering immediate neighbors of the masked token (consider the easy task ‚Äúe-igen-[mask]-ue‚Äù).
The red curve in the above figure shows that the degradation is substantially attenuated when local cues are occluded. This is done by applying whole word masking, a popular masking strategy which jointly occludes all part-of-word tokens comprising a word. Our PMI-Masking strategy, presented below, extends this solution to a much more prevalent class of highly correlated tokens: correlated word n-grams.
Correlated Word N-Grams
The above example of part-of-word tokens illustrated a flaw in BERT‚Äôs vanilla random masking approach, and the same issue occurs for correlated word n-grams, a class of correlated tokens that is harder to identify but affects any word level vocabulary. Examples include phrases and multi-word expressions such as ‚Äúeditor in chief‚Äù, ‚Äúat once‚Äù, ‚Äúcarbon footprint‚Äù, and so on. More broadly, many words provide a hint regarding the identity of their neighbors, and such shallow cues can be used by the model to minimize its objective while putting less emphasis on broader context.
Previous work has proposed masking strategies that can mitigate the effect of such local cues. Notably, Sun et al. (2019) proposed Knowledge Masking, which jointly masks tokens comprising entities and phrases, as identified by external parsers. The restriction to specific types of correlated n-grams, along with the reliance on imperfect tools for their identification, has limited the gains of this approach. With a similar motivation in mind, SpanBERT of Joshi et al. (2020) introduced Random-Span Masking, which masks word spans of lengths sampled from a geometric distribution at random positions in the text. Random-Span Masking was shown to consistently outperform Knowledge Masking, however, with high probability the selected spans break up correlated n-grams, such that the prediction task can often be performed by relying on local cues.
We offer a principled approach to masking spans that consistently provide high signal, unifying the intuitions behind the above approaches while also outperforming them.
In order to identify highly correlated word n-grams, we rely on the measure of Pointwise Mutual Information (PMI), which quantifies how surprising a bigram w1w2 is, given the unigram probabilities of w1 and w2 in the corpus. Formally, given two tokens w1 and w2, the PMI of the bigram w1w2 is:
Where the probability of an n-gram p(w1... wn) is computed by the number of its occurrences in the corpus divided by the number of all n-grams in the corpus.
PMI is a good indicator of correlation between words comprising a bigram, but extending it to measure correlation between words comprising longer n-grams is nontrivial. We propose the following extension of PMI to longer n-grams, and show that it provides a better signal than existing alternatives:
where seg(w1... wn) is the set of all contiguous segmentations of the n-gram w1... wn (excluding the identity segmentation), and where any segmentation œÉ ‚àà seg(w1... wn) is composed of sub-spans that together give w1... wn.
Intuitively, this measure discards the contribution of high PMI subsegments of the considered n-gram; the minimum in the equation above implies that an n-gram's score is given by its weakest link, i.e., by the segmentation that comes closest to separability. This way, trigrams such as ‚ÄúKuala Lumpur is‚Äù are deranked, since despite the bigram ‚ÄúKuala Lumpur‚Äù having high PMI it is not highly correlated with the word ‚Äúis‚Äù, whereas ‚Äúeditor in chief‚Äù, which cannot be broken to uncorrelated subsegments, is promoted for joint masking.
Experiments
By jointly masking n-grams with high PMIn scores, we speed up and improve BERT‚Äôs pretraining. When training models with either BERT‚Äôs vanilla random-token masking, SpanBERT‚Äôs random-span masking or PMI-Masking, in BERT‚Äôs original training setup (see details in paper), we get the following 1 to 2 point advantage in prominent benchmarks:
When comparing to prominent released models of the same size (see table at the top of this post), we see that:
PMI-Masking outperforms a parallel approach of integrating word n-grams as tokens (PMI-Masking vs. AMBERT).
PMI-Masking retains its advantage over random-span masking when training continues for 2.4 times longer than BERT‚Äôs original training (PMI-Masking vs. SpanBERT).
PMI-Masking reaches the performance attained by vanilla random-token masking after ‚Öô of the training time (PMI-Masking vs. RoBERTa).
1  Sun et al. (2019): ‚ÄúERNIE: Enhanced representation through knowledge integration‚Äù
2  Joshi et al. (2020): ‚ÄúSpanbert: Improving pre-training by representing and predicting spans‚Äù
3  We acknowledge useful comments and assistance from our colleagues at AI21 Labs
 
ABOUT THE AUTHOR
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Oops! Something went wrong while submitting the form.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/news/pmi-masking
Add Dataset,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Add Dataset
post
https://api.ai21.com
/studio/v1/dataset
Upload a dataset crafted specifically to your use-case.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/add-dataset
Custom Model Training,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
Custom Model Training
post
https://api.ai21.com
/studio/v1/custom-model
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/create-custom-model
Custom Models API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Custom Models API
You can easily fine-tune your own custom model using our API. The training process is divided into 2 steps:
Upload a dataset crafted specifically to your use-case.
Train your own custom model using that dataset.
 
This process can be done in the AI21 Studio
website
or by posting an HTTP request to the relevant endpoint.
Fine-tuning is currently supported for J2-Grande and J2-Large, as well as our legacy models J1-Jumbo, J1-Grande, and J1-Large.
Table of Contents
Training Custom Models via the API",https://docs.ai21.com/reference/custom-models-api
Get Dataset,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Get Dataset
get
https://api.ai21.com
/studio/v1/dataset/
{dataset_pid}
Get a dadaset by id.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/get-dataset
J2 Instruct,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
Custom J-2 Models
Datasets API
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
J2 Instruct
post
https://api.ai21.com
/studio/v1/
{model_type}
/complete
ü§ñ Generate text using Complete API
Get started with the Jurassic-2 Instruct endpoint by trying out our interactive API Reference page. To authenticate your requests, simply enter your
AI21 Studio API key
in the Header input. And if you're building software with Python, consider using our
Python SDK
for even greater ease and flexibility.
Language
Shell
Node
Ruby
PHP
Python
Authentication
Header
Log in to use your API keys
RESPONSE
Click
Try It!
to start a request and see the response here!",https://docs.ai21.com/reference/j2-instruct-ref
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production,"Company
About
Ask RBG
Start building
About Ubisoft
This video game titan doesn‚Äôt need an introduction. But for the uninitiated:
Ubisoft is the creator of Assassin's Creed, Just Dance, Watch Dogs, and multiple other incredibly well-crafted and popular video games. They were one of the first brands to invent rich, immersive, story-driven gaming worlds‚Äîback in the early 1980s.
The company was founded on the principles of embracing human creativity and grew to rapid popularity by the early 90s. Always ahead of the curve, Ubisoft built their first AI gaming lab 6 years ago.
The story
The script writers' work at the company is the cornerstone of the complex artifact that is a narrative driven game.  They create diverse and interactive elements - from sequential in-game cinematics to procedurally generated crowd chatter.
We talked to Ben Swanson, research scientist at Ubisoft about the challenges they were facing and how A121 helped.
Why AI21 Labs? Creator-friendly vision, ready-to-use models, and legal compliance.
Ubisoft and AI21 Labs share a common vision: create tools to automate tedious tasks so writers can focus on creative pursuits.
‚ÄúOur writers do excellent work. We want to assist them with whatever tools and models that we can.‚Äù says Swanson. AI21 Labs‚Äôs Wordtune has a similar philosophy. This vision and passion for the possibilities of human-machine collaborative writing stood out to Ubisoft in their search for a reliable large language model.
‚ÄúWe‚Äôve been leading towards AI21 Labs because we‚Äôve had positive internal reviews from team members who‚Äôve worked with AI21 Labs previously.‚Äù
Also, Ubisoft utilized AI21 Labs‚Äôs vanilla model from the get-go. Very often, with LLMs, companies need a lot of customization and fine-tuning, but AI21‚Äôs model was a perfect fit for Ubisoft‚Äôs data augmentation needs. The intuitive API made the integration even easier.
Finally, AI21 went the extra mile by ironing out legal compliance issues that have been a point of contention in other LLM partnerships.
With a model-usage fit and shared values, Ubisoft set out to enhance their game-creation process with AI21.
The first challenge:
repetitive manual work for video game writers
One of the many different tasks that goes into scriptwriting is writing bark trees which are standalone NPC lines that require as many variations as possible (and allowed by the voiceover budget). Each of these groups of variations can be seen as responses to a shared motivation.
For example, if the motivation is hunger, the character might say ‚Äúlet‚Äôs order pizza.‚Äù
Simply paraphrasing ‚Äúlet‚Äôs order pizza‚Äù wouldn‚Äôt work in this case.
‚ÄúThere's only so much you can do with paraphrasing. You actually have to pivot through the motivation or start from the motivation.‚Äù says Ben.
Ubisoft saw the value AI21 brought to the game development process. Instead of having to painstakingly brainstorm 5-10 different ways to express motivation (hunger, in this example), Ubisoft‚Äôs internal models could use AI21‚Äôs output as a launch pad.
‚ÄúIt lets our writers hit the ground running. It's an Inspiration tool for them. It's a way for them to overcome writer‚Äôs block.‚Äù says Swanson.
The second challenge:
need for data augmentation
To create an engine for automatic paraphrasing, Ubisoft had to use internal models. And to reliably use internal models, they needed fine tuning data (which didn‚Äôt exist). If they‚Äôd tasked humans with creating this fine-tuning data, it would have taken an eternity.
‚ÄúSo we use AI21 to suggest data of the correct form. It‚Äôs easier for writers to thumbs up and edit or thumbs down than to come up with novel and diverse training data themselves.‚Äù says Ben.
With AI21, Ubisoft could generate thousands of inputs and hand-pick the best ones to edit using their fine tuning datasets. With this augmented data set, the outputs became more diverse, and distinctive.
Ubisoft embeds the NPC generator and other similar models they‚Äôve trained into the writing tools for their scripters. The writers are shown pairwise comparisons of outputs so the models can get further trained through human feedback.
‚ÄúBefore AI21 we wouldn‚Äôt do this manually ‚Äî we weren‚Äôt doing it
at all
. It was THAT tedious. ‚Äú says Swanson. ‚ÄúWhat we unlocked by our partnership with AI21 is an unlimited fountain of training data of whatever precise format we require!‚Äù
The third challenge:
rising costs of in-context learning (data augmentation)
With an unlimited fountain of training data, the next challenge was that of escalating data augmentation costs.
Most LLM brands charge based on both input and output tokens.
With a 30:1 input to output ratio, Ubisoft successfully optimized their budget for game creation.
This created an obstacle: Ubisoft wanted to fine-tune the outputs to the minutest detail so their writers would work on high-quality suggestions. This meant experimenting with multiple prompts which would cost them significantly more money.
AI21 customized their pricing model to aid Ubisoft in their vision: top-notch AI-generated recommendations so writers have more inspiration (and lesser manual work). AI21 charged them only for output tokens.
‚ÄúAI21's pricing model at that time was the best for data augmentation.‚Äù adds Ben.
What changed for Ubisoft after working with AI21?
‚ÄúThe win here is rapid scaling. When it comes to writing a game, there's a tremendous amount of tedious work. For example, there need to be 10-15 different ways for a townsperson to ‚Äúget out of here‚Äù ‚Äî or it‚Äôs going to sound repetitive.
Writers often talk about having an editing brain and a writing brain ‚Äî the writing brain requires you to conjure something from nothing. The editing brain is where you polish it. So if you can jump to the editing step, that's huge.
‚ÄúThat's the promise of AI21: quality data augmentation outputs"",says Ben.
The road forward
Over a third of our conversation with Ubisoft was future-facing. Because of both teams' synchronicity, capabilities, and common beliefs, there are dozens of use cases to be built. Here‚Äôs what Ubisoft is most excited about:
Building a statistical reference model for video games engineered from AI21 Labs‚Äôs generative AI capabilities: Ubisoft‚Äôs vision to design creator-inspired, immersive games helps them build worlds with rich history, depth of character, and dramatic storylines. AI21 Labs plans to document these complex worlds to offer stats and facts to players on command.
‚ÄúThe nice thing about AI21‚Äôs setup (as opposed to the kind of LLM usage in video games you often see these days where it's basically just a chatbot) is that our setup leverages LLMs in a writer-in-the-loop scenario.  Additionally, as it relies on data augmentation and fine tuning, it allows writers to compose their own I/O - keeping it as a tool for them rather than a lower-quality replacement.‚Äù says Ben.
At AI21, not only are we thrilled to bring Ubisoft‚Äôs vision for innovation to life, but we are thrilled about the opportunities for contributing to a creator-first world.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/ubisoft-case-study
Build a Dataset,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Build a Dataset
To train a custom model, you will need to collect a dataset of training examples. Each example consists of a
prompt
, which is a valid input text, and a
completion
, which is a correct output for that specific prompt.
At least
50
training examples are required to train a custom model. If you upload a file that contains fewer than 50 examples, you will encounter an error. More is better, so provide as many examples as you can.
No! Data quality and diversity matter as well, so it‚Äôs a good idea to go over your examples manually and make sure they accurately capture various aspects of your task. It's critical that your examples reflect the real-world distribution of your problem.
The dataset must be submitted in a single
or
file. We recommend using a
file due to better handling of line breaks.
file, it should have two columns labeled ""prompt"" and ""completion"". Each row should contain a single training example, with no empty rows in between.
If you are submitting a
file, each line in the file should be a
dictionary with two fields: ""prompt"" and ""completion"".
Below is a simple example for both
.csv
and
.jsonl
formats:
csv
JSON
prompt,completion
""Where was the steam engine invented?"",England
""In what year did the US gain its independence?"",1776
""Who was the longest reigning roman emperor?"",Augustus
{""prompt"": ""Where was the steam engine invented?\n"", ""completion"": ""England""}
{""prompt"": ""In what year did the US gain its independence?\n"", ""completion"": ""1776""}
{""prompt"": ""Who was the longest reigning roman emperor?\n"", ""completion"": ""Augustus""}
Uploading a file with fewer than two columns or with inconsistent columns in different lines will result in an error.
You may upload files with different column names - in which case, you will be prompted to identify the desired prompt column and the desired completion column.
‚ùóÔ∏è
Completions cannot be empty.
However, prompts can be empty.
Updated
3 months ago
Table of Contents
üî¢ How many examples do I need?
üß© It's all about quantity?
File Formats
üõë Common Errors",https://docs.ai21.com/docs/training-data
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels,"Company
About
Ask RBG
Start building
A luxury hotel that wants to provide exceptional hospitality must deliver a 5-star experience throughout the guest's entire journey, from the moment they arrive on the website until they check out.
But how can these hotels give personalized attention to guests with 200 and more messages a day without relying on gimmicky chatbots?
Asaf Ofer, CTO and Founder of Easyway, discussed their current use of AI and how he plans to scale it.
What is Easyway?
Easyway is a guest relationship management platform (GRM) that facilitates two-way communication between guests and the hotel through instant messaging apps such as Whatsapp, SMS, Telegram, and more.
Using their technology, hotels are able to automate communication and streamline daily operations like check-in and check-out processes.
Since Easyway serves mostly luxury hotels that cater to a 4- and 5-star experience, every touchpoint is crucial for delivering high-end customer service. Aiming to improve certain aspects of their platform, they turned to AI21 Labs to take their product to a new level.
Why They Chose AI21: An LLM Solution that Mimics Human Interaction
Since Easyway isn't a chatbot, but rather an AI-powered chat platform, they needed a solution that wasn't readily available on the market. They looked for an AI platform with enough scientific and engineering innovation to be able to understand and generate natural text.
‚ÄúThe guest needs to feel like they're speaking to a human and not a chatbot,‚Äù says Asaf. ‚ÄúIf we automate it in a human and customized way, hotels need less staff, and people feel like they're being treated like special guests every time.‚Äù
The Problem with Other Models on the Market
Easyway started out using other models that could answer common questions, but only if those questions were asked in the most common and simple form. A slight deviation would cause the entire model to fail.
‚ÄúPeople had questions that it didn‚Äôt know how to respond to, because it never saw these questions [asked this way] before,‚Äù Asaf explains. ‚ÄúSometimes it was wrongly confident about what was being asked because it didn't get a lot of examples to work with.‚Äù
AI21‚Äôs Personalized Customer Service & Assistance to the Rescue
With the assistance of AI21, the Easyway team was able to train their model using a few dozen custom-made prompts. ‚ÄúWe had several calls, I showed them our results and they helped me clean up and set up the training data correctly,‚Äù says Asaf.
AI21 helped Asaf‚Äôs team break the process down to steps, translate it into code, and find discrepancies in the data. Finally, the Easyway team managed to arrive at their desired solution.
It was through this level of support that Easyway was able to use AI21 to upgrade their application.
Use Case #1: Intent Detection
With AI21's proprietary Large language Models (LLMs), Easyway was able to analyze intent with high accuracy. Easyway now uses a sentiment analysis model based on fifteen frequently asked questions.
‚ÄúWe gave the model a question and it gives us back 1 out of several possible intents,‚Äù says Asaf. He goes on to explain that if the model doesn‚Äôt exactly know that answer, then it‚Äôs okay not to respond at all ‚Äì sometimes, it‚Äôs actually better for business not to. That‚Äôs due to the fact that inappropriately responding to an already frustrated or angry customer may only fuel the situation rather than alleviating it.
This feature will lead to even bigger things in the future, says Asaf. ‚ÄúOnce we have a reliable solution for detecting sentiment, we‚Äôd be able to automate much more - If the system detects that a guest is angry, we could immediately notify the manager. If a guest is satisfied, we‚Äôd ask them to leave a review, etc.‚Äù
Use Case #2: Automatic Translation
Every hotel is filled with travelers from and to various countries. The importance of having a staff with multiple languages cannot be overstated. However, knowledge of every language is not always possible, which is why translation apps are useful.
Easyway offers high-quality 2-way translation capabilities in 100+ languages. ‚ÄúA Spanish guest will speak Spanish and the staff will be speaking Hebrew and the conversation will be understandable for each side,‚Äù Asaf explains. ‚ÄúSo each person can just use their native language, plus we use AI to respond to messages automatically.‚Äù
This feature was already in production before Easyway reached out to AI21, but there was much room for improvement. ‚ÄúOne of the gaps we had to tackle was a varying level of grammar amongst our end users. The problem involved two aspects; the level of service that our clients provide their guests, and the efficiency of our translation feature. If a person writing on our platform didn‚Äôt write properly, the live translation wouldn‚Äôt work properly.‚Äù
By incorporating the same technology that is used in Wordtune, AI21‚Äôs flagship AI writing assistant, this was made possible.
The Future for Easyway
What if you could not only automate away repetitive questions, but also begin to automatically set common responses to FAQs?
Easyway is currently running a pilot to embed a chat widget on one of their partners‚Äô websites, gearing up for a possible new offer. ‚ÄúWe‚Äôre [piloting this feature] with a customer in Europe that has a lot of visitors to their website - around 150K each month, and they don't have the staff to deal with it. So they just end up with thousands of emails asking basic questions that nobody responds to,‚Äù Asaf says.
With Easyway, hotels can automate and schedule messages based on events such as booking, arrival, and departure.
A typical post-booking conversation could be:
‚ÄúHey Asaf, thank you for booking your stay with us. Do you have any questions?‚Äù
Asaf may type: ‚ÄúHow do I get to the hotel?‚Äù or ‚ÄúWhat are the Covid regulations?‚Äù
The chat platform is set up to respond automatically, helping hotels save time with quality AI.
The Result: Automated, Human-Centered Conversations that Save Time
Remember those 200 or more messages we mentioned hotels can receive each day? To reach success, Easyway will look at how many emails each hotel actually needs to personally answer after using their application powered by AI21. Asaf stated that a ‚Äú10, 20, 30% [reduction rate] would be amazing.‚Äù
Overall, we are thrilled to have the opportunity to use our NLP technology to help alleviate the administrative burdens that hotels experience on a daily basis ‚Äì while still uplifting the 5-star experience guests want from their hotel of choice.
ABOUT THE AUTHOR
Enjoyed this?
Stay up to date with the latest research and updates from AI21 Labs.
Thank you! Your submission has been received!
Back to Blog
MRKL Whitepaper
Paper: Standing on the Shoulders of Giant Language Models
Try for yourself
What is a MRKL system?
In August 2021 we released Jurassic-1, a 178B-parameter autoregressive language model. We‚Äôre thankful for the reception it got ‚Äì over 10,000 developers signed up, and hundreds of commercial applications are in various stages of development. Mega models such as Jurassic-1, GPT-3 and others are indeed amazing, and open up exciting opportunities. But these models are also inherently limited. They can‚Äôt access your company database, don‚Äôt have access to current information (for example, latest COVID numbers or dollar-euro exchange rate), can‚Äôt reason (for example, their arithmetic capabilities don‚Äôt come close to that of an HP calculator from the 1970s), and are prohibitively expensive to update.
A MRKL system such as Jurassic-X enjoys all the advantages of mega language models, with none of these disadvantages. Here‚Äôs how it works.
Compositive multi-expert problem: the list of ‚ÄúGreen energy companies‚Äù is routed to Wiki API, ‚Äúlast month‚Äù dates are extracted from the calendar and ‚Äúshare prices‚Äù from the database. The ‚Äúlargest increase‚Äú is computed by the calculator and finally, the answer is formatted by the language model.
There are of course many details and challenges in making all this work - training the discrete experts, smoothing the interface between them and the neural network, routing among the different modules, and more. To get a deeper sense for MRKL systems, how they fit in the technology landscape, and some of the technical challenges in implementing them,
see our MRKL paper
. For a deeper technical look at how to handle one of the implementation challenges, namely avoiding model explosion,
see our paper on leveraging frozen mega LMs.
A further look at the advantages of Jurassic-X
Even without diving into technical details, it‚Äôs easy to get a sense for the advantages of Jurassic-X. Here are some of the capabilities it offers, and how these can be used for practical applications.
Reading and updating your databases in free language
AI-assisted content generation on current affairs
Performing simple and complex math operations.
Decomposing multi-step problems
Access to continuously changing information (weather, currency exchange rates)
Reading and updating your database in free language
Language models are closed boxes which you can use, but not change. However, in many practical cases you would want to use the power of a language model to analyze information you possess - the supplies in your store, your company‚Äôs payroll, the grades in your school and more. Jurassic-X can connect to your databases so that you can ‚Äòtalk‚Äô to your data to explore what you need-  ‚ÄúFind the cheapest Shampoo that has a rosy smell‚Äù, ‚ÄúWhich computing stock increased the most in the last week?‚Äù and more. Furthermore, our system also enables joining several databases, and has the ability to update your database using free language (see figure below).
Jurassic-X enables you to plug in YOUR company's database (inventories, salary sheets, etc.) and extract information using free language
AI-assisted text generation on current affairs
Language models can generate text, yet can not be used to create text on current affairs, because their vast knowledge (historic dates, world leaders and more) represents the world as it was when they were trained. This is clearly (and somewhat embarrassingly) demonstrated when three of the world‚Äôs leading language models (including our own Jurassic-1) still claim Donald Trump is the US president more than a year after Joe Biden was sworn into office.
Jurassic-X solves this problem by simply plugging into resources such as Wikidata, providing it with continuous access to up-to-date knowledge. This opens up a new avenue for AI-assisted text generation on current affairs.
Who is the president of the United States?
Donald Trump
Joe Biden
Joe Biden is the
46th and current
president
Jurassic-X can assist in text generation on up-to-date events by combining a powerful language model with access to Wikidata
Performing math operations
A 6 year old child learns math from rules, not only by memorizing examples. In contrast, language models are designed to learn from examples, and consequently are able to solve very basic math like 1-, 2-, and possibly 3- digit addition, but struggle with anything more complex. With increased training time, better data and larger models, the performance will improve, but will not reach the robustness of an HP calculator from the 1970s. Jurassic-X takes a different approach and calls upon a calculator whenever a math problem is identified by the router. The problem can be phrased in natural language and is converted by the language model to the format required by the calculator (numbers and math operations). The computation is performed and the answer is converted back into free language.
Importantly (see example below) the process is made transparent to the user by revealing the computation performed, thus increasing the trust in the system. In contrast, language models provide answers which might seem reasonable, but are wrong, making them impractical to use.
The company had 655400 shares which they divided equally among 94 employees. How many did each employee get?
94 employees.
Each employee got 7000 stocks
1.5
(No answer provided)
6972.3
X= 655400/94
Jurassic-X can answer non-trivial math operations which are phrased in natural language, made possible by the combination of a language model and a calculator
Compositionality
Solving simple questions might require multiple steps, for example - ‚ÄúDo more people live in Tel Aviv or in Berlin?‚Äù requires answering: i. What is the population of Tel-Aviv? ii. What is the population of Berlin? iii. Which is larger? This is a highly non-trivial process for a language model, and language models fail to answer this question (see example). Moreover, the user can‚Äôt know the process leading to the answers, hence is unable to trust them. Jurassic-X can decompose such problems into the basic questions, route each to the relevant expert, and put together an answer in free language. Importantly, Jurassic-X not only provides the correct answer but also displays the steps taken to reach it, increasing the trust in the system.
Do more people live in Tel Aviv or in Berlin?
Berlin
There are more people living in Tel Aviv than in Berlin.
Berlin and Tel Aviv are roughly the same size
(First hit is a comparison between Tel Aviv and Berlin)
More people live in Berlin than in Tel-Aviv
[‚ÄòReturn population of Tel Aviv‚Äô; Return population of Berlin‚Äô; Return which is bigger between #1 and #2‚Äô]
Step 1: Population of Tel Aviv. Result - 451523.
Step 1: Population of Berlin. Result - 3664088.
Step 3: Which is bigger,  #1 or #2. Result - Berlin.
Jurassic-X breaks down compositional questions, answers the basic sub-questions, and puts together the answer. Importantly, this process is transparent to the user greatly increasing the trust in the system
Dynamic information (like weather and currency exchange rates)
Certain types of information change continuously - weather, currency exchange rates, share values and more. Such information will never be captured by language models, yet can easily be handled by Jurassic-X by integrating it with a reliable source of information. We performed a proof-of-concept on two such features - weather and currency exchange rates, and the design enables quick integration with more sources to solve your use-case.
Weather - a loosely phrased question about the weather elicits an answer from all language models, where language models always return the same answer, regardless of when the question was asked (funny, right?), while Jurassic-X provides an answer based on the actual weather prediction.
I‚Äôm going to be in New-York in 3 days. Should I pack my umbrella?
Yes, you should pack your umbrella.
Yes, you should. The weather forecast is rain.
(Links to weather websites)
Yes, you should pack your umbrella, because in New York in 3 days there will be broken clouds and the temperature will be -2 degrees.
Currency exchange rates change much faster than weather predictions, yet the Jurassic-X concept - a language model connected to a reliable source of information - easily solves this problem as well.
How much Moroccan money will I get for 100 bucks?
125 dirhams
100 moroccan dirhams is about 27$.
How much is 100 dollars in moroccan money?
100 dirhams = 10.75 dollars
100 USD = 934.003 MAD
Jurassic-X combines a language model with access to APIs with continuously changing information. This is demonstrated for weather forecasts and currency exchange rates, and can easily be extended to other information sources
Transparency and trust
Transparency is a critical element that is lacking in language models, preventing a much wider adoption of these models. This lack of transparency is demonstrated by the answers to the question - ‚ÄúWas Clinton ever elected as president of the United States?‚Äù. The answer, of course, depends on which Clinton you have in mind, which is only made clear by Jurassic-X that has a component for disambiguation. More examples of Jurassic-X‚Äôs transparency were demonstrated above - displaying the math operation performed to the user, and the answer to the simple sub-questions in the multi-step setting.
Was Clinton ever elected president of the United States?
T0
Yes
GPT-3
No, Clinton was never elected as president of the United States.
Jurassic-1
No
Google
Clinton was elected president in the 1992 presidential elections‚Ä¶
Jurassic-X
Bill Clinton was elected president.
Jurassic-X is designed to be more transparent by displaying which expert answered which part of the question, and by presenting the intermediate steps taken and not just the black-box response
Your Turn
That's it, you get the picture. The use cases above give you a sense for some things you could do with Jurassic-X, but now it's your turn. A MRKL system such as Jurassic-X is as flexible as your imagination. What do you want to accomplish?
Contact us for early access
Contact us below and we will get back to you shortly.
Name
Email
Message
*
Thank you!
Your submission has been received!
Oops! Something went wrong while submitting the form.
Related Articles
Publications
AI21 Labs‚Äô Summarize API Outperforms OpenAI's Models in Human Evaluation
The performance of AI21 Labs‚Äô Summarize API was evaluated against GPT's Davinci-003 and GPT-3.5-Turbo models, using automated metrics and human evaluation. Summarize API produces shorter summaries with higher pass rates and better faithfulness scores in all experiments utilizing real-world data.
Announcements
AI21 Labs partners with Amazon to offer top-performing, easily accessible foundation models
AI21 Labs is extremely proud to announce a new strategic partnership with Amazon‚Äôs Bedrock, a new service offering customers an accessible way to build generative AI-powered apps via pre-trained models.
How Easyway Uses AI-Powered Chat to Automate Communication for Luxury Hotels
Learn how Easyway, a guest relationship management platform, used AI21 Labs LLM to streamline their operation and improve guest communications.
Case study
Unleashing the Power of AI in Game Development: How Ubisoft Scaled Content Production
Learn how Ubisoft utilizes AI21 Labs to automate tedious tasks and enhance their game creation process, all while maintaining their creative vision.
PRODUCTs
Wordtune
Wordtune Read
AI21 Studio
RESOURCES
Blog
Talks
Press
COMPANY
About Us
Careers
News
Contact Us
Email Us
info@ai21.com
All Rights Reserved ¬© AI21 Labs, 2023
Terms of Use
Privacy Policy",https://www.ai21.com/blog/easyway-case-study
Datasets API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
JUMP TO
Jurassic-2
J2 Complete API
J2 Complete
J2 Instruct API
J2 Instruct
Custom J-2 Models
Add Dataset
Get Datasets List
Get Dataset
Delete Dataset
delete
Custom Models API
Custom Model Training
Get Custom Models List
Get Custom Model
get
Custom Model Complete
Update Default Epoch
put
Task-Specific APIs
Paraphrase API
Paraphrase
Grammatical Error Corrections API
Grammatical Error Corrections
Text Improvements API
Text Improvements
Summarize API
Summarize
Text Segmentation API
Text Segmentation
Contextual Answers API [BETA]
Contextual Answers
SDK
Python SDK
Jurassic-1 [Legacy]
J-1 Complete API
J-1 Complete
J-1 Grande Instruct [beta]
Other
Tokenize API
Tokenize
post
Datasets API
You can easily train your own custom model using our API. The training process is divided into 2 steps:
Upload a dataset crafted specifically to your use-case.
Train your own custom model using that dataset.
 
This process can be done in the AI21 Studio
website
or by posting an HTTP request to the relevant endpoint.
Table of Contents
Training Custom Models via the API",https://docs.ai21.com/reference/datasets
Generating More Data Using AI21 Studio,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Generating More Data Using AI21 Studio
If you don‚Äôt have enough pre-existing training data, you can use prompt engineering on top of J2 models to efficiently generate more data. Assuming you‚Äôve already created a prompt with just a few examples that works well for your task, you can leverage it in one of two ways:
If you have examples of inputs that represent your use case, feed them to J2 with your prompt, and collect the outputs generated by the model. The pairs of inputs and generated outputs will be your training set. Note that you can often collect relevant input examples relatively easily, either from public sources on the web or from your own data.
If you don‚Äôt have access to relevant input examples, you can let J2 generate both the inputs and the outputs. Feed J2 with a sequence of examples (input #1, output #1, input #2, output #2, and so on), and let it generate more examples. This tends to work well for short inputs, up to a few sentences long, but may result in a higher rate of bad examples for longer inputs (e.g., whole articles).
The process above is illustrated step-by-step in our
blog post
. Using J2-Jumbo or J2-Grande rather than J2-Large is recommended for generating synthetic training data, since it typically produces higher quality results with prompt engineering.
We recommend you review and validate the generated content (or at least a sample from it) before training a custom model. This will ensure the data properly captures the desired behavior. Watch out for incorrect, corrupted or toxic generations, as including these in the training data will negatively affect the resulting custom model. If you find such bad examples, amend them manually or simply exclude them from the training data.
Updated
3 months ago
Table of Contents
‚ûø Synthesizing training data",https://docs.ai21.com/docs/collecting-data
Contextual Answers API [BETA],"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Contextual Answers API [BETA]
Receives a document and a question and returns an answer based entirely on the document context.
Having trouble with language models that provide false information with high confidence? Would you like answers solely based on your document context? Well, we have just the thing for you! The AI21 Studio
/answer
API allows you to access our high-quality question answering technology. It was designed to answer questions based on a specific document context provided by the customer. This avoids any factual issues that language models may have and makes sure the answers it provides are grounded in that context document.
undefined
Whether you're an NLP enthusiast or have no prior knowledge, this API is for you. There are many clever mechanisms under the hood, but you don't have to understand them (if you don't want to). As a task-specific API, you can easily integrate it into your systems and get a high-quality, grounded question answering mechanism in a matter of minutes, with no prompt engineering required. Additionally, since it's optimized for this purpose, it's significantly more efficient than building it from scratch, and an order of magnitude more affordable.
This API receives document text, serving as a context, and a question and returns an answer based entirely on this context. This means that if the answer to your question is not in the document, the model will indicate it (instead of providing a false answer).
No matter what you ask, the answer will only be determined by the document context. Imagine you are performing research and rely on financial reports to base your findings. Let's take the following part from
JPMorgan Chase & Co. 2021 annual report
:
Document context
In 2020 and 2021, enormous QE ‚Äî approximately $4.4 trillion, or 18%, of 2021 gross domestic product (GDP) ‚Äî and enormous fiscal stimulus (which has been and always will be inflationary) ‚Äî approximately $5 trillion, or 21%, of 2021 GDP ‚Äî stabilized markets and allowed companies to raise enormous amounts of capital. In addition, this infusion of capital saved many small businesses and put more than $2.5 trillion in the hands of consumers and almost $1 trillion into state and local coffers. These actions led to a rapid decline in unemployment, dropping from 15% to under 4% in 20 months ‚Äî the magnitude and speed of which were both unprecedented. Additionally, the economy grew 7% in 2021 despite the arrival of the Delta and Omicron variants and the global supply chain shortages, which were largely fueled by the dramatic upswing in consumer spending and the shift in that spend from services to goods. Fortunately, during these two years, vaccines for COVID-19 were also rapidly developed and distributed.
In today's economy, the consumer is in excellent financial shape (on average), with leverage among the lowest on record, excellent mortgage underwriting (even though we've had home price appreciation), plentiful jobs with wage increases and more than $2 trillion in excess savings, mostly due to government stimulus. Most consumers and companies (and states) are still flush with the money generated in 2020 and 2021, with consumer spending over the last several months 12% above pre-COVID-19 levels. (But we must recognize that the account balances in lower-income households, smaller to begin with, are going down faster and that income for those households is not keeping pace with rising inflation.)
Today's economic landscape is completely different from the 2008 financial crisis when the consumer was extraordinarily overleveraged, as was the financial system as a whole ‚Äî from banks and investment banks to shadow banks, hedge funds, private equity, Fannie Mae and many other entities. In addition, home price appreciation, fed by bad underwriting and leverage in the mortgage system, led to excessive speculation, which was missed by virtually everyone ‚Äî eventually leading to nearly $1 trillion in actual losses.
Rather than reading the entire report, just ask what you want to know:
Did the economy shrink after the Omicron variant arrived?
No, the economy grew 7% in 2021, despite the arrival of the Delta and Omicron variants and the global supply chain shortages.
In addition, you can ask more complex questions, where the answer requires deductions rather than just extracting the correct sentence from the document context. This will result in abstractive, rather than extractive, answers that draw on several different parts of the document. For example, look at the following question:
Did COVID-19 eventually help the economy?
The dramatic rise in consumer spending and the shift in that spend from services to goods, along with QE and fiscal stimulus, helped to stimulate the economy.
When working with these types of models, the main concern is that they will give you a made-up answer that is neither 100% accurate nor grounded in your provided text. Our Contextual Answers API prevents this from happening.
Using the same document text as above, we present the model with the following question. You may be confused to answer something based on the last paragraph without delving into the text. However, if you read the provided document context properly, you will discover that the answer does not appear there. The API will handle this as expected:
How did COVID-19 affect the financial crisis of 2008?
Answer not in document
This API is very useful when working with large amounts of internal data, such as organization documents. You can build a system that provides all the information a user needs without having to read long and tedious documents, knowing that the answers are reliable.
You've probably heard of RTFM (Read The
Friendly
Manual). However, sometimes the manual may not be as friendly as you would like. By integrating this API into your system, your users can ask questions without needing to search. As an example, here is one from
Wikipedia docs:
Context
Content
Further information: Wikipedia:Policies and guidelines ¬ß Not part of the encyclopedia, and Wikipedia:Be bold ¬ß Wikipedia namespace
See also: Wikipedia:User pages ¬ß What may I not have in my user pages?
Pages within the ""Project namespace"" themselves are not part of the encyclopedia proper. These administrative pages are intended for use by editors or by automated tools for the organization and governance of the encyclopedia. Consequently, they do not generally need to conform to the same content protocols or style conventions as articles. Nevertheless, these pages, as with all pages, should be accessible and must comply with Wikipedia's conduct and legal policies.

The project namespace is not a free web host and should not be used as a long-term archive to host pages that look like articles. Articles in the project namespace under construction may be moved to the draft namespace or Userspace draft allowing time for their development and feedback before being moved to Wikipedia's mainspace. Stalled or abandoned drafts and pages in the project namespace that violate policies applicable to non-content pages may be subject to deletion. Editors may not violate copyrights or harass anywhere on Wikipedia. Under the criteria for speedy deletion, these types of pages are subject to expeditious deletion. See below for more information.

Pages within project namespace
The project namespace pages are organized according to their function within the overall project schema. This includes Wikipedia official policies and guidelines, process pages, discussion pages, optional essays, maintenance pages, informative pages, and historical pages.

For lists of pages in the project namespace, see:

Wikipedia:Directories and indexes ‚Äì a handy list of Wikipedia's directories and indexes.
Wikipedia:Department directory ‚Äì a list of the different administrative divisions of Wikipedia.
Wikipedia:Editor's index to Wikipedia ‚Äì an enormous list of the Wikipedia community, intended to help
...Text Truncated...

Your users can simply ask what they want instead of reading the entire doc:
Question
How do I delete my wiki page?
Answer
To delete a page, first post a request at miscellany for deletion to have project pages deleted. Make sure that a notice of the request is posted to the talk page of the affected project. If the project is under a parent WikiProject, a notice should be posted there as well.
Updated
9 days ago
Table of Contents
Don‚Äôt just take our word for it, give it a go! üí´
Features
It‚Äôs all about the
context
The answer is
not in the document
? You got your answer then
Example - documentation Q&A",https://docs.ai21.com/docs/contextual-answers-api
Datasets: Best Practices,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Datasets: Best Practices
The simplest way to structure the training data is where the prompt for each individual training example contains only the text input for that example. Note that this is different from few-shot prompt engineering for a general purpose model, where the prompt contains a sequence of examples of valid inputs and outputs.
In any case, the
combined length
of the prompt and completion must not exceed 2047 tokens or approximately 6000 characters of English text. If you include longer examples, you will encounter an error after uploading the file.
For best results, we recommend implementing the following guidelines for the prompt and completion. All the snippets below assume a
.jsonl
format is being used, but the same guidelines are applicable to a
.csv
file.
Either of these helps avoid complications due to tokenization. Don‚Äôt mix and match; pick one and stick with it for all examples in the training set. See examples below:
Ending the prompt with a newline
Starting the completion with a whitespace
{""prompt"": ""Where was the steam engine invented?\n"", ""completion"": ""England""}
{""prompt"": ""Where was the steam engine invented?"", ""completion"": "" England""}
You should clearly mark the boundary between the prompt and the completion. A simple way to do this is to insert a separator at the end of each prompt. You can use any simple, distinct sequence, such as
##
on a new line.
It is often a good idea to take this a step further by using titles. You can append a title that describes the input to the beginning of the prompt, and another title that describes the output to the end of the prompt (in place of the separator). The titles can be short, but it usually helps to pick straightforward titles that are not generic and relate to the content of the input and output.
Again, it‚Äôs important to be consistent. Pick one style and stick with it. If you use titles, they should be the same in all training examples. In any case, keep in mind the first guideline and either end the prompt with a newline or start the completion with a whitespace.
See a few examples below:
Separator
Titles
Titles with newlines
{""prompt"": ""I know so many languages\n##\n"", ""completion"": ""Ich kenne so viele Sprachen""}
{""prompt"": ""English: I know so many languages\nGerman:"", ""completion"": "" Ich kenne so viele Sprachen""}
{""prompt"": ""English:\nI know so many languages\nGerman:\n"", ""completion"": ""Ich kenne so viele Sprachen""}
Adding a short instruction that explains the task to each prompt often improves results. As before, stay consistent and use the same instruction in all examples.
DO - include instruction
DON'T - without instruction
{""prompt"": ""Translate the following text from English to German.\nEnglish: It's my birthday today\nGerman:"", ""completion"": "" Heute ist mein Geburtstag""}
{""prompt"": ""English: It's my birthday today\nGerman:"", ""completion"": "" Heute ist mein Geburtstag""}
Duplicate entries are detrimental to the training, so we recommend removing them.
üìò
Don't have enough examples?
Make sure you don't duplicate existing examples to reach 50 examples. If you do not have more examples, you can use AI21 Studio to generate some based on the ones you do have.
You can also train a custom model to perform tasks that have more than one input. Simply combine all the inputs into the prompt, with an appropriate title for each input. For example, consider a model trained to generate short ads for cars from a list of technical specifications. The different fields can be organized in a template as in the following example:
Model name: Viesta
Fuel consumption: 60 MPG
Horsepower: 100 HP
Price: $11,000
##
An appropriate dataset for training such a model would look like the following:
JSON
{""prompt"": ""Model name: Viesta\nFuel consumption: 60 MPG\nHorsepower: 100 HP\nPrice: $11,000\n##\n"", ""completion"": ""The new Viesta model runs efficiently with an amazing 60 MPG fuel consumption, available now for $11,000.""}
{""prompt"": ""Model name: Lambada\nFuel consumption: 15 MPG\nHorsepower: 500 HP\nPrice:$120,000\n##\n"", ""completion"": ""Feel the power with the new Lambada, burning the road with a mind-blowing 500-Horsepower engine.""}
Updated
3 months ago
Table of Contents
Best Practices for Prompt and Completion Content
1. End prompts with a newline or start completions with a whitespace
2. Add a title or a separator
3. Include natural language instructions
4. Remove duplicates
Handling Complex Inputs",https://docs.ai21.com/docs/best-practices
Grammatical Error Corrections API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Grammatical Error Corrections API
Detects grammar, spelling, punctuation, and word choice errors in text, and suggests how to correct them.
Our
/gec
API gives you access to our top-of-the-line GEC engine. It was specifically developed for this, and it has been fine-tuned accordingly. By integrating this Wordtune API into your writing platform, you can provide your users with the confidence to write without the need to worry about grammar. This is also the engine behind
Wordtune
- our
award winning writing assistant
, so you know it's pretty awesome.
undefined
Whether you're an NLP enthusiast or have no prior knowledge, this API is for you. There are many clever mechanisms under the hood, but you don't have to understand them (if you don't want to). As a task-specific API, you can easily integrate it into your systems and get top-notch gramatical error corrections in a matter of minutes, with no prompt engineering required. Additionally, since it's optimized for this purpose, it's significantly more efficient than building it from scratch, and an order of magnitude cheaper.
You simply need to send some text to the API, and it will return a list of every grammar error, including its location and suggestions for corrections and the type of the error (to indicate to users why it should be fixed).
Allow your users to write with flawless grammar, including tenses, verb additions, changing the order, and everything else you forgot since English high school lessons. No more wondering if it's
who
or
whom
.
I'm is going
I'm going
I'm going go
I'm going to go
I was in the there
I was there
It difficult read a sentence like this, isn't it? The GEC API will make it easier for you to do this.
This soup very tasty
This soup is very tasty
Give your users peace of mind without having to worry about double whitespaces, incorrect punctuation, and answering the most annoying question - do I need a hyphen here?
Are you going to be there!
Are you going to be there?
Hi you
Hi,
A spell check, but so much more: Capitalizing, changing words that sound the same but spelled differently, and fixing errors caused by typos.
I'm not aloud to go
I'm not allowed to go
i think i tough i saw you tryt
i think i thought i saw you try
Let it god
Let it go
Do you know the song ""I will will always love you""? How about ‚ÄúI will always love you you‚Äù? Doesn‚Äôt have the same ring, does it? With GEC API you can make sure you‚Äôll always have a hit.
Gimme Gimme Gimme a man after midnight
Gimme a man after midnight
Did you ever use words with similar sounds or spellings? GEC API makes sure you
want
won't!
Before
After
At times, my job can be quite monogamous
At times, my job can be quite monotonous
Imagine that you want to integrate the GEC API into your writing platform. To illustrate how you would do it, here is an example:
import ai21

ai21.api_key = 'YOUR_API_KEY'

text = ""jazzz is a great stile of music""
response = ai21.GEC.execute(text=text)

// Use the corrections to fix the sentence
corrected_text = text
corrections = response[""corrections""]
for curr_correction in reversed(corrections):
    corrected_text = corrected_text[:curr_correction[""startIndex""]] + curr_correction['suggestion'] + corrected_text[curr_correction[""endIndex""]:]
And the fixed sentence:
Python
print(corrected_text)

// Jazz is a great style of music
Updated
9 days ago
Table of Contents
Don‚Äôt just take our word for it, give it a go! üí´
Features
Fix every
grammar
error
Find all the
missing words
:
,
Punctuation
!
Take the
spelling
bee by storm
Avoid repetition of repetitive
word repetitions
Communicate the right message without using any
wrong words
Examples",https://docs.ai21.com/docs/gec-api
Text Improvements API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Text Improvements API
Provides rewrite recommendations for improving the fluency, clarity and style of the input text.
With our
/improvements
API, you can access our industry-leading text enhancements engine. Since it was specifically designed for this task, it produces high-quality results while optimizing efficiency. Integrating this API into your writing platform will improve your users' writing, enhance their experience and elevate their final product. This is also the engine behind
Wordtune
- our
award winning writing assistant
, so you know it's pretty awesome.
undefined
Whether you're an NLP enthusiast or have no prior knowledge, this API is for you. There are many clever mechanisms under the hood, but you don't have to understand them (if you don't want to). As a task-specific API, you can easily integrate it into your systems and get top-notch text improvements in a matter of minutes, with no prompt engineering required. Additionally, since it's optimized for this purpose, it's significantly more efficient than building it from scratch, and an order of magnitude cheaper.
This API scans a piece of text to see if it can be improved. The different models behind it check for fluency, clarity, and vocabulary. In the event that it finds areas that need improvement (and only if it finds them), it will return a list of suggestions (with locations).
Let your users express themselves more fluently, phrasing the same message in a natural way.
Affiliated with the profession of project management, I have ameliorated myself with a different set of hard skills as well as soft skills.
Being involved in the profession of project management, I have developed a different set of hard skills as well as soft skills.
Make it easier for users to be more precise by recommending a more specific word to use within the context.
Good sleep
Full night's sleep
I ate a good pizza
I ate a tasty/delicious/yummy pizza
Allow your users to avoid multiple repetitions of the same
multiple
words.
mean
fat gain.
Positive energy balance means that you consume more energy than you burn. With the right types of foods this could mean muscle gain, with the wrong types it could
result
in fat gain.
Advise your users how to avoid long and convoluted sentences by splitting them into short sentences.
, so it
In addition, it is essential to build trust in their relationships, so they can start having efficient communications
. This
will allow them to give feedback and call their peers on their performance without the fear of interpersonal conflicts.
Make it easier for your users to be concise.
Before
After
We will arrive home in a period of five days
We will arrive home in five days
Imagine that you want to integrate the Text Improvements API into your writing platform where you perform the improvements automatically. To illustrate how you would do it, here is an example:
import ai21

ai21.api_key = 'YOUR_API_KEY'

response = ai21.Improvements.execute(text=""Affiliated with the profession of project management, I have ameliorated myself with a different set of hard skills as well as soft skills."",
                                                                   types=[""fluency""]
                                    )

// Use the improvements suggestions to fix the sentence
improved_text = text
improvements = response[""improvements""]
for curr_improvement in reversed(improvements):
    improved_text = improved_text[:curr_improvement[""startIndex""]] + curr_improvement['suggestions'][0] + improved_text[curr_improvement[""endIndex""]:]
And the fixed sentence:
Python
print(improved_text)

// As a member of the profession of project management, I have acquired a different set of technical skills as well as soft skills.
Updated
9 days ago
Table of Contents
Don‚Äôt just take our word for it, give it a go! üí´
Features
Speak with great
fluency
Feature description:
specificity
Enrich the text with
variety
Write simple with
short sentences
Conciseness
Examples",https://docs.ai21.com/docs/text-improvements-api
Task-Specific APIs Overview,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Grammatical Error Corrections API
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Task-Specific APIs Overview
Dedicated APIs that work out-of-the-box for specific reading and writing tasks.
AI21 Studio's Task-Specific APIs offer a range of powerful tools. These APIs have been specifically designed for their respective tasks and provide high-quality results while optimizing efficiency.
Whether you are an NLP enthusiast or have no prior knowledge, these task-specific APIs are easy to integrate into your writing platform and provide top-notch results in a matter of minutes. As specialized APIs, each was optimized for a dedicated purpose, making it significantly more efficient than building it from scratch, and much more cost effective.
offers access to a world-class paraphrasing engine that suggests alternative ways to convey the same message using different words. It takes a piece of text and returns a list of paraphrases that convey the same meaning using different words, with the ability to adjust tone and style.
provides access to a top-of-the-line GEC engine that identifies and corrects grammar errors, returning a list of grammar errors and suggestions for corrections.
scans a piece of text to see if it can be improved and checks for fluency, clarity, and vocabulary. It returns a list of suggestions if it finds areas that need improvement.
provides access to a world-class summarization engine that generates grounded summaries that remain faithful to the original document. It takes a piece of text or URL and generates summaries that follow the original text flow.
breaks down a piece of text into segments, identifying distinct topics and lines that will work well together and form a coherent piece of text. It supports up to 100,000 characters and can be used to segment long text into smaller chunks and summarize each segment separately.
Contextual Answers API [BETA]
The
Contextual Answers API
receives document text, serving as a context, and a question and returns an answer based entirely on this context. This means that if the answer to your question is not in the document, the model will indicate it (instead of providing a false answer).
Updated
about 2 months ago
Table of Contents
Paraphrase API
Grammatical Error Corrections (GEC) API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API BETA",https://docs.ai21.com/docs/task-specific
Jurassic-1 Models [Legacy],"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Jurassic-1 Models [Legacy]
Note: Jurassic-1 models will be deprecated on June 1st, 2023.
Jurassic-1 (J1) is the first generation in a series of large language models trained and made widely accessible by AI21 Labs. There are three versions of Jurassic-1, differing by size:
J1-Jumbo
, with 178B parameters, is the largest and most sophisticated language model ever released for general use by developers. Jumbo is the most capable model in the J1 family, but it's also the slowest and most expensive to run.
J1-Grande
, with 17B parameters, is faster and more affordable than Jumbo, and more capable than Large.
J1-Large
, with 7.5B parameters, is smaller, faster and more affordable but overall less capable than Jumbo, though still very effective for many use-cases.
A complete description of Jurassic-1, including benchmarks and quantitative comparisons with other models, can be found in our
technical paper
.
Updated
3 months ago
Table of Contents
ü¶ñ Jurassic-1 Series",https://docs.ai21.com/docs/jurassic-1-models-legacy
Paraphrase API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Paraphrase API
Takes a piece of text and returns a list of paraphrases that convey the same meaning using different words.
AI21 Studio's
/paraphrase
API  offers access to our world-class paraphrasing engine. It has been specifically developed for suggesting alternative ways to convey the same message using different words. This is also the engine behind
Wordtune
- our
award winning writing assistant
, so you know it's pretty awesome.
undefined
Whether you're an NLP enthusiast or have no prior knowledge, this API is for you. There are many clever mechanisms under the hood, but you don't have to understand them (if you don't want to). As a paraphrase-specific API, you can easily integrate it into your systems and get top-notch paraphrasing in a matter of minutes, with no prompt engineering required. Additionally, since it's optimized for this purpose, it's significantly more efficient than building it from scratch, and an order of magnitude cheaper.
This API takes a piece of text and returns a list of paraphrases that convey the same meaning using different words. As a specialized API for paraphrasing, it contains features to enable you more control over the output by adjusting the tone and style. Moreover, you can add additional context to the text, to make the rewrite suggestion more relevant (by paraphrasing a certain range of your text).
You have the choice between five different styles:
General - there are fresh and creative ways to rephrase sentences. Offer them to your users.
Casual - convey a friendlier and more accessible tone for the right audience.
Formal - present your words in a more professional way.
Short - express your messages clearly and concisely.
Long - expand your sentences to give more detail, nuance and depth.
You can paraphrase only part of the text while keeping the surrounding text unchanged by specifying a range within the text.
BAD practices - AVOID THIS
The API aims to paraphrase exactly the requested range while avoiding disfluent suggestions. Satisfying both requirements is not always possible; in those cases, the call will result in an empty list of suggestions. Also, avoid paraphrasing texts that start or end mid-word.
For example, consider the sentence ‚ÄúThis is a flat out bad example‚Äù. Paraphrasing the word ‚Äúflat‚Äù alone in this sentence without violating fluency is not possible, because ‚Äúflat‚Äù is part of the term ‚Äúflat out‚Äù. Paraphrasing ‚Äúflat‚Äù alone is kind of like trying to paraphrase half a word. Cases like this usually yield few or no suggestions.
BEST practices - you should do this
Consider the following example for a paraphrase call:
import ai21

ai21.api_key = 'YOUR_API_KEY'

response = ai21.Paraphrase.execute(text=""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù We figured that we should create some pages that satisfied this need."",
                                   startIndex=116)
And the response:
JSON
[
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Therefore, we decided to create some pages that answered this question.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Our team decided to create some pages to answer this question.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù This led to the idea of creating some pages that answered this question.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Thus, some pages were created to provide this information.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Thus, we decided to create some pages that address this issue.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Therefore, we designed some pages that addressed this question.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Therefore, we decided to create some pages that would fulfill this need.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Thus, we created some pages that provide that information.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Thus, we decided to create a few pages about this topic.""
   },
   {
      ""text"":""My team discovered that there was little-to-no information that answered the question, ‚ÄúIs my contractor licensed?‚Äù Th
...Text Truncated...

You can see that the part until
remains the same in all of the suggestions.
The
can be either the character you wish to paraphrase from, or a whitespace before it (in this case, it would have worked with
startIndex
=115 as well).
To improve fluency, the range of the paraphrase may contain up to one word per direction. As an example, consider the following sentence (where the range is
bolded
):
I had a
good night
.
Among the suggestions, you may see
‚ÄúI had a relaxing evening‚Äù
, where the range is on the limit, as well as
‚ÄúI had an enjoyable evening‚Äù
, where you can see the range included an extra word before.
By integrating the Paraphrase API into your system, your users gain an embedded co-writer within the experience. This is useful for virtually all text-based tasks, from marketing content (like that post about a newly specialized API) to emails (a formal report to higher-ups or casual correspondence with a colleague) and even general descriptions. Following are some examples illustrating both use cases and special features you can take advantage of with this API.
You can enhance the writing experience of your users by adding paraphrasing functionality to your writing platforms. See the following example for a generic call, without any of the special features. Here is an example for paraphrasing suggestions (note that the API will return up to 10 suggestions in every call):
Text
We will explore the Paraphrase API's advantages and features throughout this page.
The Paraphrase API will be explored throughout this page.
On this page, we will look at the advantages and features of the Paraphrase API.
In this page, we'll explore Paraphrase API's benefits and features.
This page provides an overview of the Paraphrase API's advantages and features
We will discuss the benefits and features of the Paraphrase API throughout this page.
JavaScript
import ai21

ai21.api_key = 'YOUR_API_KEY'

response = ai21.Paraphrase.execute(text=""Throughout this page, we will explore the advantages and features of the Paraphrase API."")
import requests

fetch(""https://api.ai21.com/studio/v1/paraphrase"", {
  headers: {
    ""Authorization"": ""Bearer YOUR_API_KEY"",
    ""Content-Type"": ""application/json""
  },
  body: JSON.stringify({
    ""text"": ""Throughout this page, we will explore the advantages and features of the Paraphrase API.""
  }),
  method: ""POST""
});
{
   ""id"":""e218271d-bc3a-3c31-5576-e6b09eb75f8b"",
   ""suggestions"":[
      {
         ""text"":""We will explore the Paraphrase API's advantages and features throughout this page.""
      },
      {
         ""text"":""The Paraphrase API will be explored throughout this page.""
      },
      {
         ""text"":""On this page, we will look at the advantages and features of the Paraphrase API.""
      },
      {
         ""text"":""In this page, we'll explore Paraphrase API's benefits and features.""
      },
      {
         ""text"":""This page explores the advantages and features of Paraphrase API.""
      },
      {
         ""text"":""This page provides an overview of the Paraphrase API's advantages and features.""
      },
      {
         ""text"":""We will discuss the benefits and features of the Paraphrase API throughout this page.""
      },
      {
         ""text"":""During this page, you will learn about the features and advantages of the Paraphrase API.""
      },
      {
         ""text"":""This page will explore the Paraphrase API's advantages and features.""
      },
      {
         ""text"":""In this page, we'll discuss the advantages and features of the Paraphrase API.""
      }
   ]
}
Writing product descriptions requires understanding your customers' needs and communicating the features and benefits of your product in an engaging, informative, and compelling manner. Also, as a copywriter, they need to keep a consistent tone in descriptions. On top of that, there is often a strict length restriction, which may cause multiple descriptions for the same product on different platforms. Offering your users different paraphrasing styles, such as shortening, can improve their productivity and help them provide high-quality results, all with their own voice and consistency.
See the following example for a call that combines a short style and the context feature, i.e. - paraphrase only part of the text, while maintaining the full context. Note that unlike in this table, the response will include the full text and not just the paraphrased part.
This classic cotton t-shirt is made from soft, comfortable cotton and is suitable for everyday wear. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion. It's great for running errands or dressing up for a night out.
This classic cotton t-shirt is made from soft, comfortable cotton and is suitable for everyday wear.
Designed from 100% soft, comfortable cotton, this classic cotton t-shirt is ideal for everyday use and would make a stylish addition to any wardrobe.
You can use this code and see for yourself:
Python
Response
import ai21

ai21.api_key = 'YOUR_API_KEY'

text = ""This classic cotton t-shirt is made from soft, comfortable cotton and is suitable for everyday wear. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion. It's great for running errands or dressing up for a night out.""
text_to_paraphrase = ""This classic cotton t-shirt is made from soft, comfortable cotton and is suitable for everyday wear.""

startIndex = text.find(text_to_paraphrase)
endIndex = startIndex + len(text_to_paraphrase)


response = ai21.Paraphrase.execute(text=text,
                                                 style=""short"",
                                                         startIndex=startIndex,
                                                         endIndex=endIndex
                                  )
{
   ""id"":""9d0908f7-84f1-5ba4-0c81-14103191e737"",
   ""suggestions"":[
      {
         ""text"":""Cotton t-shirt made from soft, comfortable cotton for everyday wear. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion. It's great for running errands or dressing up for a night out.""
      },
      {
         ""text"":""Soft, comfortable cotton makes this cotton t-shirt perfect for everyday wear. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion. It's great for running errands or dressing up for a night out.""
      },
      {
         ""text"":""Suitable for everyday wear, this classic cotton t-shirt is made of soft, comfortable cotton. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion. It's great for running errands or dressing up for a night out.""
      },
      {
         ""text"":""The soft, comfortable cotton used in this t-shirt makes it suitable for everyday wear. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion. It's great for running errands or dressing up for a night out.""
      },
      {
         ""text"":""The cotton t-shirt is soft, comfortable, and suitable for everyday wear. In addition to providing ultimate comfort and a timeless appearance, this t-shirt has a durable ribbed neckline and a regular fit. It is available in a variety of colors so that you can wear it up or down for any occasion.
...Text Truncated...

It takes years to learn how to sound professional in work emails. You can save your users as much time as possible by providing them with a paraphrased version of their response that sounds professional using the formal tone. Note that unlike in this table, the response will include the full text and not just the paraphrased part.
Text (full context)
Dear (customer name),
Thank you for choosing (company name).
At (company name), we appreciate our customers and aim to provide good service.
Our delivery policy includes:
1- Delivery within 48 hours
2- Delivery within 72 hours for orders above $100.
3- All deliveries are free of charge.
4- All deliveries are insured.
5- All deliveries are tracked.
6- Delivery within 48 hours for orders above $500.
(Company name) offers a 10% discount on all purchases.
If you require any additional information or assistance, please do not hesitate to contact us.
Best regards,
John
Text to paraphrase
At (company name), we appreciate our customers and aim to provide good service
Suggestions
We at (company name) are committed to providing excellent service to our customers.
Updated
9 days ago
Table of Contents
Don‚Äôt just take our word for it, give it a go! üí´
Features
Choose a
style
that fits your needs
Adding
context
to the paraphrase
Examples
General writing platform (generic call)
Retail - product descriptions (short style and context use)
Customer inquiries (formal style)",https://docs.ai21.com/docs/paraphrase-api
Custom Models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Custom Models
Using AI21 Studio, you can train and query your own custom versions of our base models. Custom models are fine-tuned for optimal performance on a training set of examples representing a
specific task
Custom models can be trained to perform virtually any language task. Use cases include generating marketing copy, powering chatbots and assisting creative writing.
You can train custom models based on either J2-Grande or J2-Large (soon also J2-Jumbo) and pick your desired cost/quality trade-off.
Given a sufficient number of training examples, custom J2 models exceed the quality attainable with general purpose models and prompt engineering. For many use cases, you can expect custom models to begin outperforming prompt engineering with as few as 50-100 examples. To learn more, read our
, where we address a specific language task, using both general purpose models and custom models.
Furthermore, custom models derive their quality from the training data you provide; adding more, higher quality examples will improve results. This means you can continuously refine your custom model by curating high-quality data for your task.
The training process bakes the task-specific behavior into the custom model. This means your prompts no longer need to include elaborate instructions and examples designed to guide a general purpose model to perform the desired task. Instead, your prompts only need to include the specific input you'd like to handle, reducing the amount of text that gets processed and decreasing latency.
One potential safety risk of large language models is deliberate misuse by malicious users of your application, exploiting its access to Jurassic-2 to generate text for their malicious purposes. Adversaries may attempt to achieve this via ‚Äúprompt injection‚Äù, where the end-user‚Äôs input text is crafted to alter the normal behavior of the model. Custom models are less susceptible to such attacks than general purpose models, offering a significant safety advantage when deployed in production. For more information, read our
case study blog post
.
There are two parts to the training process:
Build a dataset.
Train a custom model based on this dataset.
Updated
about 1 month ago
Table of Contents
Why Train a Custom Model?
üßµü™°‚úÇ Best results tailored to your specific use case
üöÄüöÄ Faster performance, better latency
üí™ü¶æ Adversarial robustness
Sounds great! How do I do it?",https://docs.ai21.com/docs/custom-models
Jurassic-2 Models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Jurassic-2 Models
General-purpose models that you can easily train and customize for any need.
Jurassic-2 (J2) is our top-notch series of state-of-the-art Large Language Models. As the new generation following
Jurassic-1
, J2 not only improves upon the previous series in every aspect, but it also offers new features and capabilities that put it in a league of its own.
The Jurassic-2 series includes both base language models alongside instruction-tuned language models that come in different sizes. You can use all of these models via our
Complete API
. Our base models are available in three sizes:
Jurassic-2 Jumbo: Unmatched quality
As the largest and most powerful model in the Jurassic series, J2-Jumbo is an ideal choice for the most complex language processing tasks and generative text applications. Further, the model can be fine-tuned for optimum performance in any custom application.
Jurassic-2 Grande: Optimal balance of quality, speed, and cost
This model offers enhanced text generation capabilities, making it well-suited to language tasks with a greater degree of complexity. Its fine-tuning options allow for optimization of quality, while maintaining an affordable price and high efficiency.
Jurassic-2 Large: Fast and cost-effective
Designed for fast responses, this model can be fine-tuned to optimize performance for relatively simple tasks, making it an ideal choice for language processing tasks that require maximum affordability and less processing power.
All of J2 models support several non-English languages, including:
Spanish
French
German
Portuguese
Italian
Dutch
All J2 models were trained on a massive corpus of text, making them highly versatile general purpose text-generators, capable of composing human-like text and solving complex tasks such as question answering, text classification and many others.
J2 models can be applied to virtually any language task by crafting a suitable prompt, containing a description of the task and/or a few examples, a process commonly known as
prompt engineering
. Popular use-cases include generating marketing copy, powering chatbots and assisting creative writing.
With trial and error, you should be able to bootstrap a prompt that produces good results for your use-case. However, to achieve even better quality and scale-up your app, we recommend that you train a
custom model
You can generate a text completion for a given text prompt by using our Python SDK or posting an HTTP request to the complete endpoint corresponding to the desired language model to use. The request contains the input text, called a prompt and various parameters controlling the generation. For authentication, you must include your API key in the request headers. A complete response contains the tokenized prompt, the generated text(s), called completion(s), and various metadata.
The request and response specifications are documented in full
here
.
Updated
about 2 months ago
Table of Contents
ü¶ñ Jurassic-2 Series
Supported Languages
ü§î What are they good for?
ü§ñ Generate text using Complete API",https://docs.ai21.com/docs/jurassic-2-models
Instruct Models,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Instruct Models
Based on our base models from the Jurassic-2 series, Jurassic-2 Instruct were trained specifically to handle instructions-only prompts (""zero-shot"") without examples (""few-shot""). It is the most natural way to interact with large language models, and it is the best way to get a sense of the optimal output for your task without any examples.
Below is an example of the difference between Jurassic-2 Instruct and Jurassic-2 Grande to a zero-shot prompt. Jurassic-2 Grande, our base model, starts with a relevant answer but doesn't stop in time (since it wasn't trained specifically to follow instructions).
Jurassic-2 Grande
prompt:
Write a tweet about the future of NLP:

completion:
We want to know what you think NLP will be like in 10 years.
Send a tweet to @iNLP Center or @iNLPTech with the hashtag #NLPFuture: Tell us what NLP will be like in 10 years.
Tag one friend to do the same: The person you tag will be entered into a drawing to win a free gift.
1. Tweet: 10 years from now, what will NLP be like?
2. Tag a friend: The person you tag will be entered into a drawing to win a free gift.
3. Tweet: I tagged @JohnSmith.
4. Tag another friend: The person you tag will be entered into a drawing to win a free gift.
5. Tweet: I tagged @JaneDoe.
While Jurassic-2 Instruct provides a better answer for the instruction provided:
Jurassic-2 Instruct
prompt:
Write a tweet about the future of NLP:

completion:
The future of NLP is bright. Using NLP, we can train machines to understand language, reason about knowledge, and interact with humans naturally. #END
The following are some best practices for using our Instruct models, as well as examples that show their capabilities.
It's important to make sure the instruction ends in a clear way, whether with a punctuation mark (such as ""."", "":"", ""?"" or a newline) or through clear wording.
In this case, the prompt ended mid-sentence. As a result, the model completed the instruction itself instead of providing an appropriate response.
DON'T - instruction doesn't end clearly
prompt:
generate a weather forecast including the following details:
1. the high temperatures will reach 25C
2. the winds will be 100 knots NW

completion:
3. the weather will be cloudy
The same prompt is given here, with the following addition at the end to ensure the model understands the instruction:
DO - instruction ends clearly
prompt:
generate a weather forecast including the following details:
1. the high temperatures will reach 25C
2. the winds will be 100 knots NW
make it in a formal tone:

completion:
The weather forecast for Thursday, April 7, calls for high temperature reaching 25C, with a wind speed of 100 knots.
Would you like your completions written in a particular style? All you have to do is ask. As an example, here is the same prompt from before, but with the request to write like a pirate.
Like a pirate
prompt:
generate a weather forecast including the following details:
1. the high temperatures will reach 25C
2. the winds will be 100 knots NW
make it in a style of a pirate:

completion:
Ahoy! Batten down the hatches! High winds are ahead! High temperatures will reach 25C, and winds will reach 100 knots from the NW.
You may get results in different formats if you write a general instruction. For example, the model can list things numbered or separated by dots.
Separated by punctuations
prompt:
list 3 active NBA players, include their team and their total career points.

completion:
1. LeBron James - Los Angeles Lakers - 35,000+ points
2. Stephen Curry - Golden State Warriors - 20,000+ points
3. Kevin Durant - Brooklyn Nets - 23,000+ points
prompt:
list 3 active NBA players, include their team and their total career points.

completion:
Stephen Curry, Golden State Warriors: 18,064 points. James Harden, Houston Rockets: 20,143 point. LeBron James, Los Angeles Lakers: 32,364 points.
You can ask specifically for a bullet list:
Bullet list
prompt:
list 3 active NBA players, include their team and their total career points. Do it in a bullet list.

completion:
- LeBron James - Los Angeles Lakers - 35,000+ points
- Stephen Curry - Golden State Warriors - 20,000+ points
- Kevin Durant - Brooklyn Nets - 23,000+ points
Or a JSON format:
Numbered list
prompt:
list 3 active NBA players, include their team and their total career points. Do it in a JSON format.

completion:
{""players"": [
    {""name"": ""LeBron James"", ""team"": ""Cleveland Cavaliers"", ""totalPoints"": ""25,614""},
    {""name"": ""Stephen Curry"", ""team"": ""Golden State Warriors"", ""totalPoints"": ""18,662""},
    {""name"": ""Kevin Durant"", ""team"": ""Golden State Warriors"", ""totalPoints"": ""18,897""}
]}
If you use different adjectival descriptions for length, you will see different results. For example, here is a
brief
prompt:
Write a brief history about the war between Pokemons and Digimons.

completion:
The war between Pokemons and Digimons was fought between the two most powerful species in the Digital World. The Pokemons were led by their king, Ash Ketchum, while the Digimons were led by their king, Agumon. The war lasted for many weeks, with neither side being able to gain the upper hand. Eventually, Ash was able to defeat Agumon and bring peace to the Digital World.
In oppose to a
long
history:
prompt:
Write a long history about the war between Pokemons and Digimons.

completion:
Pokemons and Digimons have always been rivals. They compete for territory, food, and other resources. The Pokemons are considered more powerful, but the Digimons are more intelligent.
The war between Pokemons and Digimons began thousands of years ago. The Pokemons were living on the island of Johto, and the Digimons were living on the island of Digiworld. The Pokemons wanted to expand their territory, so they invaded Digiworld. The Digimons fought back, but they were no match for the Pokemons.
The Pokemons eventually won, and they took control of Digiworld. The Digimons were forced to leave their homes, and they were forced to live in hiding.
The war between Pokemons and Digimons continued for centuries. The Pokemons kept expanding their territory, and the Digimons kept trying to fight back. However, the Pokemons were always victorious.
In modern times, the war has mostly stopped. The Pokemons and the Digimons have come to an agreement to live in peace. However, there are still some tensions between them.
The war between Pokemons and Digimons has been one of the most important conflicts in human history. It has led to the development of new technologies, and it has shaped the world we live in today.
Note: adjusting the length through an instruction is not always successful.
A few good prompt examples for inspiration are provided below.
Below is an example of a news release with a specific tone:
prompt:
Write a news release in the voice of a global banking conglomerate announcing an unprecedented building campaign to expand and rebuild their corporate headquarters in Alpha Centauri.

completion:
Alpha Centauri, our home for countless generations, is in trouble. After years of neglect, the banking conglomerate that owns it has been forced into a massive rebuilding campaign.

Our headquarters, which once served as a beacon of hope to the many worlds in our galaxy, is now little more than a crumbling ruin. If we are going to save Alpha Centauri, we must act quickly.

That is why, for the first time since its foundation, the banking conglomerate is undertaking a building campaign. We are expanding and rebuilding our corporate headquarters, and doing so using the most advanced technologies at our disposal.
A summary extraction from a chat conversation with a customer:
prompt:
Following is a transcript of a conversation between a customer and our agent.
""""""
Customer: Hi, I would like to know about your sneakers
Agent: Hi, I'm Mary, Shoe-La-La's online customer representative! What would you like to know about our sneakers?
Customer: Do you have them in red?
Agent: Unfortunately we don't have red shoes in stock right now, we only have them in White, Black and Green. Let me check if I can order those for you. Which model and size are you interested in?
Customer: Red All-stars, size 37.
Agent: Great! I'll check if we can get those for you and we'll get back to you.
""""""
What was the specific reason the customer needed help?

completion:
To ask about the availability of red sneakers
Summary of long text into bullets:
prompt:
Below is some text:
Meet Carbon Maps, a new French startup that raised $4.3 million (‚Ç¨4 million) just a few weeks after its inception. The company is building a software-as-a-service platform for the food industry so that they can track the environmental impact of each of their products in their lineup. The platform can be used as a basis for eco ratings.

While there are quite a few carbon accounting startups like Greenly, Sweep, Persefoni and Watershed, Carbon Maps isn‚Äôt an exact competitor as it doesn‚Äôt calculate a company‚Äôs carbon emissions as a whole. It doesn‚Äôt focus on carbon emissions exclusively either. Carbon Maps focuses on the food industry and evaluates the environmental impact of products ‚Äî not companies.

Co-founded by Patrick Asdaghi, JeÃÅreÃÅmie Wainstain and Estelle Huynh, the company managed to raise a seed round with Breega and Samaipata ‚Äî these two VC firms already invested in Asdaghi‚Äôs previous startup, FoodCh√©ri.


FoodCh√©ri is a full-stack food delivery company that designs its own meals and sells them directly to end customers with an important focus on healthy food. It also operates Seazon, a sister company for batch deliveries. The startup was acquired by Sodexo a few years ago.

‚ÄúOn the day that I left, I started working on food and health projects again,‚Äù Asdaghi told me. ‚ÄúI wanted to make an impact, so I started moving up the supply chain and looking at agriculture.‚Äù

And the good news is that Asdaghi isn‚Äôt the only one looking at the supply chain of the food industry. In France, some companies started working on an eco-score with a public agency (ADEME) overseeing the project. It‚Äôs a life cycle assessment that leads to a letter rating from A to E.

While very few brands put these letters on their labels, chances are companies that have good ratings will use the eco-score as a selling point in the coming years.


But these ratings could become even more widespread as regulation is still evolving. The European Union is even working
...Text Truncated...

We will keep improving our models as we collect feedback, and in particular refine our instruction-tuned models in the coming weeks and months. Stay tuned for updates!
Updated
3 months ago
Table of Contents
Best practices
Make sure your prompt ends clearly
Specify your style
Choose your format
Specify the desired length in your instruction
Examples
Notes",https://docs.ai21.com/docs/instruct-models
Logit Bias,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Logit Bias
Would you like to exclude certain words or filter specific tokens from your generated text?
Logit biases can be used to promote or suppress the generation of specific tokens. This is accomplished by adding a bias term to each token's respective logits. Where a positive bias increases the generation probability, a negative bias decreases it.
Note that logit bias operates at the token level, so you must refer to valid tokens in the Jurassic-1 vocabulary, otherwise the API returns an error. Watch out for whitespaces, which are replaced with a special underscore character in our string representation of tokens (see
here
).
The following example introduces a large negative bias to avoid generating the expected continuation ""a box of"":
üê∂
Logit bias example
Open Recipe
Updated
9 days ago
Table of Contents
üê∂ What is it?
Example",https://docs.ai21.com/docs/logit-bias
Repetition Penalties,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Repetition Penalties
Repetition penalties can be used to counteract the model's tendency to repeat prompt text verbatim and/or get stuck in a loop. This is accomplished by adjusting the token probabilities at each generation step, such that tokens that already appeared in the text (either in the prompt or in the completion) are less likely to be generated again.
There are three types of repetition penalties:
presencePenalty
countPenalty
frequencyPenalty
. One or more penalties can be used, and the magnitude of each can be controlled independently.
Used to reduce the probability of generating new tokens that appear at least once in the prompt or in the completion. As an example, if your prompt (and current completion) is
will decrease (by the same value), even though that
appears more than the others.
Used to reduce the probability of generating new tokens that appear at least once in the prompt or in the completion, in proportion to the number of appearances. As an example, if your prompt (and current completion) is
""One fish, two fish, red fish, blue fish""
, the probability of the tokens
""One""
""two""
""red""
, and
""blue""
will decrease by some value and the probability of the token
""fish""
will decrease by a larger value.
Reduce the probability of generating new tokens that appear in the prompt or in the completion, in proportion to the frequency of their appearances in the text (normalized to text length). Using this method is beneficial in longer texts, since repeating some words is less of an issue than it is in short texts.
The following example introduces all three penalties simultaneously (though each one individually would have sufficed to prevent repetition):
Repetition penalties
In addition to controlling the penalty scale, the API allows penalties to be toggled on and off for five special categories of tokens: whitespaces (including newlines), punctuations, numbers, stopwords (including multi-word combinations of stopwords) and emojis. For example:
ü§ê
Repetition penalties - special tokens
Open Recipe
Each repetition penalty is characterized by a PenaltyData data structure containing the following fields:
scale |
float
Controls the magnitude of the penalty.
Required
A positive penalty value implies reducing the probability of repetition. Larger values correspond to a stronger bias against repetition.
applyToWhitespaces |
Apply the penalty whitespaces and newlines. Optional, default=True.
Determines whether the penalty is applied to the following tokens:
'‚ñÅ', '‚ñÅ‚ñÅ', '‚ñÅ‚ñÅ‚ñÅ‚ñÅ', '<|newline|>'
applyToPunctuations |
Apply the penalty to punctuations. Optional, default=True.
Determines whether the penalty is applied to tokens containing punctuation characters and whitespaces, such as
;
!!!
‚ñÅ\[[@
applyToNumbers |
Apply the penalty to numbers. Optional, default=True.
Determines whether the penalty is applied to purely numeric tokens, such as
2022
or
123
. Tokens that contain numbers and letters, such as
20th
, are not affected by this parameter.
applyToStopwords |
Apply the penalty to stop words. Optional, default=True.
Determines whether the penalty is applied to tokens that are NLTK English stopwords or multi-word combinations of these words, such as
are
,
nor
and
‚ñÅWe‚ñÅhave
.
applyToEmojis |
boolean
Exclude emojis from the penalty. Optional, default=True.
Determines whether the penalty is applied to any of approximately 650 common emojis in the Jurassic-1 vocabulary.
Updated
3 months ago
Table of Contents
ü§ê What is it?
ü§î Repetition penalties: what types are there?
üëâ presencePenalty
üëâ countPenalty
üëâ frequencyPenalty
Example - general
Example - special tokens
Penalty data",https://docs.ai21.com/docs/repetition-penalties
Special Tokens and Whitespaces,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Special Tokens and Whitespaces
The
or
\u2581
character in the tokens is used by our tokenizer to substitute a single whitespace or tab symbol. Sequences of 2 and 4 consecutive spaces (either regular whitespaces or tabs) have their own tokens,
‚ñÅ‚ñÅ
and
‚ñÅ‚ñÅ‚ñÅ‚ñÅ
, respectively.
Note that since tokenization adds a dummy space at the start of each line for consistency. The resulting text is not simply a concatenation of all tokens with
‚ñÅ
replaced with a space. For example:
Python
>>> res = requests.post(""..."", json={""prompt"": ""This is the 1st line\nThis is the 2nd line"", 
                                     ""temperature"": 0, ""maxTokens"": 16})
>>> res.status_code
200
>>> data = res.json()
>>> data['completions'][0]['data']['text']
'\nThis is the 3rd line\nThis is the 4th line\nThis is the 5th line\n'
>>> tokens = [t['generatedToken']['token'] for t in data['completions'][0]['data']['tokens']]
>>> """".join(tokens)
'<|newline|>‚ñÅThis‚ñÅis‚ñÅthe‚ñÅ3rd‚ñÅline<|newline|>‚ñÅThis‚ñÅis‚ñÅthe‚ñÅ4th‚ñÅline<|newline|>‚ñÅThis‚ñÅis‚ñÅthe‚ñÅ5th‚ñÅline<|newline|>'
>>> """".join(tokens).replace(""‚ñÅ"","" "").replace(""<|newline|>"", ""\n"")
'\n This is the 3rd line\n This is the 4th line\n This is the 5th line\n'
Each token's
field can be used to map it to its corresponding span in the result
text
. Note that the text field of the prompt in the response may differ from the text sent in the request if it contains special symbols that behave differently after tokenization. In this case, the
textRange
fields always refer to the text in the response.
Updated
9 days ago",https://docs.ai21.com/docs/special-tokens-and-whitespaces
Overview,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Summarize API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Overview
AI21 Studio is a platform that provides developers and businesses with top-tier natural language processing (NLP) solutions, powered by AI21 Labs‚Äô state-of-the-art language models.
Our second-generation language model series,
, is now available for you to use. The Jurassic-2 family base includes LMs of different sizes - Jumbo, Grande, and Large, as well as instruction-tuned LMs of Grande and Jumbo. Jurassic-2 offers top-tier performance with significant improvements in quality and new capabilities like instruction-following.
Jurassic-2 supports various non-English languages, including Spanish, French, German, Portuguese, Italian, and Dutch, and offers up to 30% faster performance.
Complete
Using our Complete API, you can generate text completions for an input prompt. You can embed the API in your application or service, or use our
to experiment with the models.
Instruct
The
Instruct models
API makes it easy to add instruction-following functionality to your applications. Simply integrate the API into your service and input specific instructions for execution. Our Instruct models are already trained to handle your instructions, so no examples are needed. You can also test the models in our
interactive web environment
.
Our
task-specific
APIs offer plug-and-play capabilities that enable you to implement generative AI in your products in minutes. The first collection of task-specific APIs is the Wordtune API, giving you access to the language models behind Wordtune, AI21 Labs‚Äô consumer-facing app that hosts tens of millions of users worldwide. The Wordtune API provides summarization, paraphrasing, grammatical error corrections, text improvement suggestions, and text segmentation.
Create your account on AI21 Studio and start building with Jurassic-2. We offer flexible pay-as-you-go plans as well as a free trial with a generous amount of free credits to get you started.
Updated
about 1 month ago
What‚Äôs Next
Quickstart
Table of Contents
Welcome to AI21 Studio! ü¶ñü¶ï
Jurassic-2
Task-Specific
How can I start",https://docs.ai21.com/docs/overview
Text Segmentation API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Text Segmentation API
Takes a document (raw text or URL) and returns segmentation into paragraphs by topic.
AI21 Studio's
/segmentation
API breaks down a piece of text into segments. Instead of merely using punctuation and newlines to divide the text, this identifies distinct topics and lines that will work well together and will form a coherent piece of text.
This API supports up to 100,000 characters, which translates to roughly 20,000 words, or 80 pages! This can be used, for example, to segment long text into smaller chunks and summarize each segment separately.
See full Text Segmentation API reference
here
In addition to working with free text, this API can also work directly with your favorite (or least favorite) webpage URLs! No need to spend time and effort scraping text yourself - just input the required URL and let the summarization begin.
Note: if the webpage you are trying to summarize is behind a paywall or restricted access, your call will fail and will result in an error.
This API is really helpful when you have long text to process and you have some length limitations in your flow. Following are some examples illustrating both use cases and special features you can take advantage of with this API.
If you want to summarize long texts, you may encounter an issue: the Summarize API is limited to 50,000 characters. You can use the Segmentation API for texts twice as long (100,000 characters).
The example below shows a typical flow for summarizing texts longer than Summarize APIs character limit. First, we call Segmentation and get a list of segments. Second, we iterate through the list and perform a Summarize call to summarize each segment. We print the summaries in order to form a summary of the entire document.
Imagine that we want to summarize the Wikipedia page on
Tom Brady
. The following call to the
Summarize API
will result in an error:
response = ai21.Summarize.execute(
    source=""https://en.wikipedia.org/wiki/Tom_Brady"",
    sourceType='URL')

// error returned: Input text exceeds max characters limit: 50000
However, with the Segmentation API you will get the text divided to segments:
Python
Response
response = ai21.Segmentation.execute(
    source=""https://en.wikipedia.org/wiki/Tom_Brady"",
    sourceType='URL')
{
   ""id"":""33ce4604-19ac-3479-0971-c37103869419"",
   ""segments"":[
      {
         ""segmentText"":""This article is about the American football player. For other people named Tom Brady, see Tom Brady (disambiguation)."",
         ""segmentType"":""normal_text_short""
      },
      {
         ""segmentText"":""Thomas Edward Patrick Brady\\xa0Jr. (born August\\xa03, 1977) is an American former football quarterback who played in the National Football League (NFL) for\\xa023 seasons. He spent his first\\xa020 seasons with the New England Patriots organization, with which he was a central contributor to the franchise's dynasty from 2001 to 2019. In his final three seasons, he was a member of the Tampa Bay Buccaneers. Brady is widely regarded as the greatest quarterback of all time.[1]\n"",
         ""segmentType"":""normal_text""
      },
      {
         ""segmentText"":""After playing college football at the University of Michigan, Brady was selected 199th overall by the Patriots in the sixth round of the 2000 NFL Draft, later earning him a reputation as the NFL's biggest draft steal.[2][3][4] He became the starting quarterback during his second season, which saw the Patriots win their first Super Bowl title in Super Bowl XXXVI. As the team's primary starter for\\xa018 seasons,[a] Brady led the Patriots to\\xa017 division titles (including\\xa011 consecutive from 2009 to 2019),\\xa013 AFC Championship Games (including eight consecutive from 2011 to 2018), nine Super Bowl appearances, and six Super Bowl titles, all NFL records for a player and franchise.[b] He joined the Buccaneers in 2020 and won Super Bowl\\xa0LV, extending his individual records to\\xa0ten Super Bowl appearances and seven victories.[7] Beginning in 2024, Brady will be the lead color commentator for NFL on Fox.[8][9]\n"",
         ""segmentType"":""normal_text""
      },
      {
         ""segmentText"":""Brady holds nearly every major quarterback record, including most career passing yards, completions, touchdown passes, and
...Text Truncated...

Now you can summarize each section and get the full summary.
Updated
9 days ago
Table of Contents
Features
Different
types
Examples
Summarize long text",https://docs.ai21.com/docs/text-segmentation-api
Summarize API,"Jump to Content
Go to Playground
API Key
Account
Log In
Home
Guides
Recipes
API Reference
Changelog
Search
Getting Started
Overview
Quickstart
Key Concepts
Large Language Models
Tokenizer & Tokenization
When Will a Language Model Stop Generating Text?
Sampling From Language Models
Prompt Engineering
Advanced
Special Tokens and Whitespaces
Repetition Penalties
Logit Bias
Foundation Models
Jurassic-2 Models
Instruct Models
Custom Models
Jurassic-1 Models [Legacy]
Task-Specific APIs
Task-Specific APIs Overview
Paraphrase API
Grammatical Error Corrections API
Text Improvements API
Text Segmentation API
Contextual Answers API [BETA]
How To...
Build a Dataset
Datasets: Best Practices
Generating More Data Using AI21 Studio
Tips: Building a Dataset
Train a Custom Model
Tips: Training a Custom Model
Query your Custom Model
Working with amazon sagemaker
Python SDK - with Amazon SageMaker
Choosing the Right Instance Type
Usage
Responsible Use
Safety Research
Summarize API
Takes a document (raw text or URL) and returns a summary of the text.
AI21 Studio's
/summarize
API offers access to our world-class summarization engine. It has been specifically developed for reading long texts and providing a faithful summary of the original document. This is also the engine behind
Wordtune Read
- our acclaimed reading assistant, so you know it's pretty awesome.
undefined
Whether you're an NLP enthusiast or have no prior knowledge, this API is for you. There are many clever mechanisms under the hood, but you don't have to understand them (if you don't want to). As a summarize-specific API, you can easily integrate it into your systems and get top-notch summarizations in a matter of minutes, with no prompt engineering required. Additionally, since it's optimized for this purpose, it's significantly more efficient than building it from scratch, and an order of magnitude cheaper.
This API takes a piece of text or fetches text from a given URL and generates grounded summaries that remain faithful to the original document (i.e. no external information is added during the process). The summaries are formatted as bullet lists, following the original text flow.
Summaries are returned as a single string, containing bullet points representing the key points of your text.
The input text should contain at least 40
words
and no more than 50,000
characters
. This translates to roughly 10,000 words, or an impressive 40 pages! When it comes to URLs, this limitation only applies for summarizable text (after parsing, preprocessing, etc.).
In addition to working with free text, this API can also work directly with your favorite (or least favorite) webpage URLs! No need to spend time and effort scraping text yourself - just input the required URL and let the summarization begin.
Note: if the webpage you are trying to summarize is behind a paywall or restricted access, your call will fail and will result in an error.
Save your users time by providing focused summaries on a topic of their choice with our enhanced guided summary feature. By specifying keywords, phrases, or topics, the API will produce only the relevant summaries, allowing your users faster browsing and better text consumption.
With just a few lines of code, you can provide your users with high quality summaries and highlights. Whether they are students who need to perform a massive literature review, journalists who need to sift through large amounts of information, or your average Joe who just needs to get the gist of the long report they have to read. Following are some examples illustrating both use cases and special features you can take advantage of with this API.
Keeping up with world events is important, but with the current information overload, who has the time?
With our Summarize API, you can provide your users with the highlights of various news articles, letting them choose what they want to read more about.
As an example, below is a summary of a single news item.
The error affected a number of international flights leaving the terminal on Wednesday, with some airlines urging passengers to travel only with hand luggage.
Virgin Atlantic said all airlines flying out of the terminal had been affected.
Passengers have been warned it may be days before they are reunited with luggage.
An airport spokesperson apologised and said the fault had now been fixed.
Virgin Atlantic said it would ensure all bags were sent out as soon as possible.
It added customers should retain receipts for anything they had bought and make a claim to be reimbursed.
Passengers, who were informed by e-mail of the problem, took to social media to vent their frustrations.
One branded the situation ""ludicrous"" and said he was only told 12 hours before his flight.
The airport said it could not confirm what the problem was, what had caused it or how many people had been affected.
A number of international flights were affected by the error on Wednesday, with some airlines urging passengers to travel only with hand luggage. Passengers were informed by e-mail of the problem and took to social media to vent their frustrations.
The number of papers coming out every year makes keeping track difficult. Our Summarize API lets your users stay up-to-date with current academic advancements, so that they can focus on their work and not spend all their time reading research papers.
As an example, below is a summary of the landmark paper
Attention Is All You Need
:
Original text
The dominant sequence transduction models are based on complex recurrent or  convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data
Summary
The Transformer is a new simple network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. It achieves superior results on two machine translation tasks, including a new single-model state-of-the-art score of 41.8 BLEU.
If you want to summarize long texts, you may encounter an issue: the Summarize API is limited to 50,000 characters. You can use the Segmentation API for texts twice as long (100,000 characters).
The example below shows a typical flow for summarizing texts longer than Summarize APIs character limit. First, we call Segmentation and get a list of segments. Second, we iterate through the list and perform a Summarize call to summarize each segment. We print the summaries in order to form a summary of the entire document.
Imagine that we want to summarize the Wikipedia page on
Tom Brady
. The following call to the Summarize API will result in an error:
Python
response = ai21.Summarize.execute(
    source=""https://en.wikipedia.org/wiki/Tom_Brady"",
    sourceType='URL')

// error returned: Input text exceeds max characters limit: 50000
However, with the Segmentation API you will get the text divided to segments:
Response
{
   ""id"":""33ce4604-19ac-3479-0971-c37103869419"",
   ""segments"":[
      {
         ""segmentText"":""This article is about the American football player. For other people named Tom Brady, see Tom Brady (disambiguation)."",
         ""segmentType"":""normal_text_short""
      },
      {
         ""segmentText"":""Thomas Edward Patrick Brady\\xa0Jr. (born August\\xa03, 1977) is an American former football quarterback who played in the National Football League (NFL) for\\xa023 seasons. He spent his first\\xa020 seasons with the New England Patriots organization, with which he was a central contributor to the franchise's dynasty from 2001 to 2019. In his final three seasons, he was a member of the Tampa Bay Buccaneers. Brady is widely regarded as the greatest quarterback of all time.[1]\n"",
         ""segmentType"":""normal_text""
      },
      {
         ""segmentText"":""After playing college football at the University of Michigan, Brady was selected 199th overall by the Patriots in the sixth round of the 2000 NFL Draft, later earning him a reputation as the NFL's biggest draft steal.[2][3][4] He became the starting quarterback during his second season, which saw the Patriots win their first Super Bowl title in Super Bowl XXXVI. As the team's primary starter for\\xa018 seasons,[a] Brady led the Patriots to\\xa017 division titles (including\\xa011 consecutive from 2009 to 2019),\\xa013 AFC Championship Games (including eight consecutive from 2011 to 2018), nine Super Bowl appearances, and six Super Bowl titles, all NFL records for a player and franchise.[b] He joined the Buccaneers in 2020 and won Super Bowl\\xa0LV, extending his individual records to\\xa0ten Super Bowl appearances and seven victories.[7] Beginning in 2024, Brady will be the lead color commentator for NFL on Fox.[8][9]\n"",
         ""segmentType"":""normal_text""
      },
      {
         ""segmentText"":""Brady holds nearly every major quarterback record, including most career passing yards, completions, touchdown passes, and
...Text Truncated...

Now you can summarize each section and get the full summary.
Updated
9 days ago
Table of Contents
Don‚Äôt just take our word for it, give it a go! üí´
Features
In
summary
Different
types
Summaries with laser
focus
Examples
Summarization of news
Summarization of academic article
Summarize long text",https://docs.ai21.com/docs/summarize-api
